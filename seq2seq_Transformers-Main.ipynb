{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from sklearn import preprocessing as pre\n",
    "#from pathos.pools import ProcessPool as Pool\n",
    "tf.set_random_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "#from xmlrpc import client\n",
    "import xmlrpclib\n",
    "\n",
    "s = xmlrpclib.ServerProxy('http://10.21.230.64:8778')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some hypers\n",
    "GO='<START>'\n",
    "STOP='<END>'\n",
    "PAD='<PAD>'\n",
    "unknown='<UNKNOWN>'\n",
    "BATCH=64\n",
    "BEAM_WIDTH=5\n",
    "EPOCHS=100\n",
    "LAM=0.9\n",
    "embedding_size=512\n",
    "lstm_units=512\n",
    "dropout_keep_prob=0.8\n",
    "PATIENCE=20\n",
    "PATIENCE_MONITOR=True\n",
    "GLOVE=False #if true embedding size will reset to 300\n",
    "CONSTGLOVE=False\n",
    "MAX_LEN=33\n",
    "#new\n",
    "\n",
    "SIN=True\n",
    "NUM_BLOCKS=6\n",
    "NUM_HEADS = 8\n",
    "FEAT_DIM=2048\n",
    "NUM_UNITS=512\n",
    "FRAMES=28\n",
    "LR=0.0001\n",
    "WARMUP=4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile):\n",
    "    print \"Loading Glove Model\"\n",
    "    f = open(gloveFile,'r')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print \"Done.\",len(model),\" words loaded!\"\n",
    "    return model\n",
    "if GLOVE:\n",
    "    embedding_size=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "with open('./captions/token_train.pkl') as f:\n",
    "    trainCaptions=pkl.load(f)\n",
    "with open('./captions/token_dev.pkl') as f:\n",
    "    devCaptions=pkl.load(f)\n",
    "with open('./captions/token_test.pkl') as f:\n",
    "    testCaptions=pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processToken(caps):\n",
    "    nk=[]\n",
    "    \n",
    "    for i in caps:\n",
    "        t=[GO]+list(i[1])+[STOP]\n",
    "        empty=33-len(t)\n",
    "        \n",
    "        #t=t+[pad]*empty\n",
    "        nk.append([i[0],t])\n",
    "    return nk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainCaptions=processToken(trainCaptions)\n",
    "devCaptions=processToken(devCaptions)\n",
    "testCaptions=processToken(testCaptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listofwords(data):\n",
    "    '''takes a list of sentences nd returns vocab'''\n",
    "    a=[]\n",
    "    for i in data:\n",
    "        for j in i[1]:\n",
    "            if j not in a:\n",
    "                a.append(j)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the vocab and size\n",
    "trainVocab=listofwords(trainCaptions+devCaptions)\n",
    "trainVocabSize=len(trainVocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find cap len\n",
    "trainCapLen=[len(i[1]) for i in trainCaptions]\n",
    "devCapLen=[len(i[1]) for i in devCaptions]\n",
    "testCapLen=[len(i[1]) for i in testCaptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoder for output transform\n",
    "pre_op=pre.LabelEncoder()\n",
    "pre_op.fit(trainVocab+[PAD])\n",
    "onehoter=np.identity(len(pre_op.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word to int\n",
    "trainSeq=[pre_op.transform(i[1]) for i in trainCaptions]\n",
    "devSeq=[pre_op.transform(i[1]) for i in devCaptions]\n",
    "trainID=[i[0] for i in trainCaptions]\n",
    "devID=[i[0] for i in devCaptions]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#word to int with pool\n",
    "p=Pool(8)\n",
    "\n",
    "\n",
    "trainSeq=p.map(pre_op.transform,[i[1] for i in trainCaptions])\n",
    "devSeq=p.map(pre_op.transform,[i[1] for i in devCaptions])\n",
    "trainID=[i[0] for i in trainCaptions]\n",
    "devID=[i[0] for i in devCaptions]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appending stops\n",
    "\n",
    "\n",
    "trainSeqReg=[np.pad(i,(0,MAX_LEN-len(i)),'constant',constant_values=pre_op.transform([PAD])) for i in trainSeq]\n",
    "devSeqReg=[np.pad(i,(0,MAX_LEN-len(i)),'constant',constant_values=pre_op.transform([PAD])) for i in devSeq]\n",
    "trainSeqReg=np.array(trainSeqReg)\n",
    "devSeqReg=np.array(devSeqReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading video features\n",
    "videoFeats=np.load(file='./features/consilidated_feats.npy')\n",
    "videoFeatSize=np.array([len(i) for i in videoFeats])\n",
    "#making the shape regular\n",
    "videoFeats=np.array([np.pad(i,mode='constant',pad_width=[(0,28-len(i)),(0,0)]) for i in videoFeats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glove\n",
    "if GLOVE:\n",
    "    gloveModel=loadGloveModel('./glove/glove.6B.300d.txt')\n",
    "    gloveEmbedding=[]\n",
    "    for i in pre_op.classes_:\n",
    "        if gloveModel.has_key(i):\n",
    "            gloveEmbedding.append(gloveModel[i])\n",
    "        else:\n",
    "            gloveEmbedding.append(np.random.normal(size=(300)))\n",
    "    gloveEmbedding=np.array(gloveEmbedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets build the graph\n",
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummys\n",
    "enc_ph = tf.placeholder(tf.float32,(BATCH,FRAMES,2048))\n",
    "enc_len_ph = tf.placeholder(tf.float32,(BATCH))\n",
    "y_ph = tf.placeholder('int32',(BATCH,MAX_LEN))\n",
    "y_len_ph=tf.placeholder('int32',(BATCH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class Transformer:\n",
    "'''\n",
    "    xs: tuple of\n",
    "        x: int32 tensor. (N, T1)\n",
    "        x_seqlens: int32 tensor. (N,)\n",
    "        sents1: str tensor. (N,)\n",
    "    ys: tuple of\n",
    "        decoder_input: int32 tensor. (N, T2)\n",
    "        y: int32 tensor. (N, T2)\n",
    "        y_seqlen: int32 tensor. (N, )\n",
    "        sents2: str tensor. (N,)\n",
    "    training: boolean.\n",
    "    \n",
    "def __init__(self, hp):\n",
    "    #self.hp = hp\n",
    "    #self.token2idx, self.idx2token = load_vocab(hp.vocab)\n",
    "'''\n",
    "embeddings = get_token_embeddings(trainVocabSize, embedding_size, zero_pad=True)\n",
    "\n",
    "def encode(xs, training=True):\n",
    "    '''\n",
    "    Returns\n",
    "    memory: encoder outputs. (N, T1, d_model)\n",
    "    '''\n",
    "    with tf.variable_scope(\"encoder\", reuse=tf.AUTO_REUSE):\n",
    "        x, seqlens  = xs\n",
    "\n",
    "        # embedding\n",
    "        enc = x # (N, T1, d_model)\n",
    "        enc *= FEAT_DIM**0.5 # scale\n",
    "\n",
    "        enc += positional_encoding(enc, FRAMES)\n",
    "        enc = tf.layers.dropout(enc, 1-dropout_keep_prob, training=training)\n",
    "\n",
    "        ## Blocks\n",
    "        for i in range(NUM_BLOCKS):\n",
    "            with tf.variable_scope(\"num_blocks_{}\".format(i), reuse=tf.AUTO_REUSE):\n",
    "                # self-attention\n",
    "                enc = multihead_attention(queries=enc,\n",
    "                                          keys=enc,\n",
    "                                          values=enc,\n",
    "                                          num_heads=NUM_HEADS,\n",
    "                                          dropout_rate=1-dropout_keep_prob,\n",
    "                                          training=training,\n",
    "                                          causality=False)\n",
    "                # feed forward\n",
    "                enc = ff(enc, num_units=[FEAT_DIM, FEAT_DIM])\n",
    "    memory = enc\n",
    "    return memory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(ys, memory, training=True):\n",
    "    '''\n",
    "    memory: encoder outputs. (N, T1, d_model)\n",
    "    Returns\n",
    "    logits: (N, T2, V). float32.\n",
    "    y_hat: (N, T2). int32\n",
    "    y: (N, T2). int32\n",
    "    sents2: (N,). string.\n",
    "    '''\n",
    "    with tf.variable_scope(\"decoder\", reuse=tf.AUTO_REUSE):\n",
    "        decoder_inputs, y, seqlens = ys\n",
    "\n",
    "        # embedding\n",
    "        dec = tf.nn.embedding_lookup(embeddings, decoder_inputs)  # (N, T2, d_model)\n",
    "        dec *= NUM_UNITS ** 0.5  # scale\n",
    "\n",
    "        dec += positional_encoding(dec, MAX_LEN-1)\n",
    "        dec = tf.layers.dropout(dec, 1-dropout_keep_prob, training=training)\n",
    "\n",
    "        # Blocks\n",
    "        for i in range(NUM_BLOCKS):\n",
    "            with tf.variable_scope(\"num_blocks_{}\".format(i), reuse=tf.AUTO_REUSE):\n",
    "                # Masked self-attention (Note that causality is True at this time)\n",
    "                dec = multihead_attention(queries=dec,\n",
    "                                          keys=dec,\n",
    "                                          values=dec,\n",
    "                                          num_heads=NUM_HEADS,\n",
    "                                          dropout_rate=1-dropout_keep_prob,\n",
    "                                          training=training,\n",
    "                                          causality=True,\n",
    "                                          scope=\"self_attention\")\n",
    "\n",
    "                # Vanilla attention\n",
    "                dec = multihead_attention(queries=dec,\n",
    "                                          keys=memory,\n",
    "                                          values=memory,\n",
    "                                          num_heads=NUM_HEADS,\n",
    "                                          dropout_rate=1-dropout_keep_prob,\n",
    "                                          training=training,\n",
    "                                          causality=False,\n",
    "                                          scope=\"vanilla_attention\")\n",
    "                ### Feed Forward\n",
    "                dec = ff(dec, num_units=[NUM_UNITS*4,embedding_size])\n",
    "\n",
    "    # Final linear projection (embedding weights are shared)\n",
    "    weights = tf.transpose(embeddings) # (d_model, vocab_size)\n",
    "    logits = tf.einsum('ntd,dk->ntk', dec, weights) # (N, T2, vocab_size)\n",
    "    y_hat = tf.to_int32(tf.argmax(logits, axis=-1))\n",
    "\n",
    "    return logits, y_hat, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "padID=pre_op.transform([PAD])[0]\n",
    "startID=pre_op.transform([GO])[0]\n",
    "stopID=pre_op.transform([STOP])[0]\n",
    "\n",
    "def train( xs, ys):\n",
    "    '''\n",
    "    Returns\n",
    "    loss: scalar.\n",
    "    train_op: training operation\n",
    "    global_step: scalar.\n",
    "    summaries: training summary node\n",
    "    '''\n",
    "    # forward\n",
    "    memory = encode(xs)\n",
    "    logits, preds, y = decode(ys, memory)\n",
    "\n",
    "    # train scheme\n",
    "    \n",
    "    y_ = label_smoothing(tf.one_hot(y, depth=trainVocabSize))\n",
    "    ce = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y_)\n",
    "    nonpadding = tf.to_float(tf.not_equal(y,padID ))  # 0: <pad>\n",
    "    loss = tf.reduce_sum(ce * nonpadding) / (tf.reduce_sum(nonpadding) + 1e-7)\n",
    "\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    lr = noam_scheme(LR, global_step, WARMUP)\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "    tf.summary.scalar('lr', lr)\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "    tf.summary.scalar(\"global_step\", global_step)\n",
    "\n",
    "    summaries = tf.summary.merge_all()\n",
    "\n",
    "    return loss, train_op, global_step, summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evalr(xs, ys):\n",
    "    '''Predicts autoregressively\n",
    "    At inference, input ys is ignored.\n",
    "    Returns\n",
    "    y_hat: (N, T2)\n",
    "    '''\n",
    "    decoder_inputs, y, y_seqlen = ys\n",
    "\n",
    "    decoder_inputs = tf.ones((tf.shape(xs[0])[0], 1), tf.int32) * startID\n",
    "    ys = (decoder_inputs, y, y_seqlen)\n",
    "\n",
    "    memory = encode(xs, False)\n",
    "\n",
    "    print \"Inference graph is being built. Please be patient.\"\n",
    "    for _ in tqdm(range(MAX_LEN-1)):\n",
    "        logits, y_hat, y = decode(ys, memory, False)\n",
    "        if tf.reduce_sum(y_hat, 1) == padID: break\n",
    "\n",
    "        _decoder_inputs = tf.concat((decoder_inputs, y_hat), 1)\n",
    "        ys = (_decoder_inputs, y, y_seqlen)\n",
    "\n",
    "    # monitor a random sample\n",
    "    '''\n",
    "    n = tf.random_uniform((), 0, tf.shape(y_hat)[0]-1, tf.int32)\n",
    "    sent1 = sents1[n]\n",
    "    pred = convert_idx_to_token_tensor(y_hat[n], self.idx2token)\n",
    "    sent2 = sents2[n]\n",
    "\n",
    "    tf.summary.text(\"sent1\", sent1)\n",
    "    tf.summary.text(\"pred\", pred)\n",
    "    tf.summary.text(\"sent2\", sent2)\n",
    "    summaries = tf.summary.merge_all()\n",
    "    '''\n",
    "    return y_hat#, summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference graph is being built. Please be patient.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [01:04<00:00,  2.12s/it]\n"
     ]
    }
   ],
   "source": [
    "loss, train_op, global_step, summaries= train((enc_ph,enc_len_ph),(y_ph[:,:-1],y_ph[:,1:],y_len_ph))\n",
    "y_hat = evalr((enc_ph,enc_len_ph),(y_ph[:,:-1],y_ph[:,1:],y_len_ph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes training batch\n",
    "\n",
    "SenEmb=np.squeeze(np.load('./LmEmb.npy'))\n",
    "\n",
    "def getTrainBatch(indexs):\n",
    "    sourceBatch=np.array([videoFeats[trainID[i]] for i in indexs])\n",
    "    targetBatch=np.array([trainSeqReg[i] for i in indexs])\n",
    "    sourceBatchLen=np.array([videoFeatSize[trainID[i]] for i in indexs])\n",
    "    targetBatchLen=np.array([trainCapLen[i] for i in indexs])\n",
    "    targetSenEm=np.array([SenEmb[i] for i in indexs])\n",
    "    return sourceBatch,targetBatch,sourceBatchLen,targetBatchLen,targetSenEm\n",
    "\n",
    "#makes dev batch\n",
    "def getDevBatch(indexs):\n",
    "    sourceBatch=np.array([videoFeats[devID[i]] for i in indexs])\n",
    "    targetBatch=np.array([devSeqReg[i] for i in indexs])\n",
    "    sourceBatchLen=np.array([videoFeatSize[devID[i]] for i in indexs])\n",
    "    targetBatchLen=np.array([devCapLen[i] for i in indexs])\n",
    "    return sourceBatch,targetBatch,sourceBatchLen,targetBatchLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calValBleu():\n",
    "    data=videoFeats[1200:1300]\n",
    "    data_len=videoFeatSize[1200:1300]\n",
    "    if BATCH>100:\n",
    "        data=np.concatenate([data,videoFeats[:BATCH-100]])\n",
    "        data_len=np.concatenate([data_len,videoFeatSize[:BATCH-100]])\n",
    "    gen_sum=[]\n",
    "    for i in range(len(data)/BATCH):\n",
    "        start=i*BATCH\n",
    "        stop=(i+1)*BATCH\n",
    "\n",
    "        \n",
    "        y=sess.run(y_hat,feed_dict={enc_ph:data[start:stop],y_ph:np.zeros((BATCH,MAX_LEN)),\n",
    "                                              enc_len_ph:data_len[start:stop],\n",
    "                                                y_len_ph:np.zeros((BATCH))})\n",
    "        \n",
    "        \n",
    "        for t in y:\n",
    "            gen_sum.append(t)\n",
    "\n",
    "    if BATCH<100:        \n",
    "        start=len(data)-BATCH\n",
    "        stop=len(data)\n",
    "        y=sess.run(y_hat,feed_dict={enc_ph:data[start:stop],y_ph:np.zeros((BATCH,MAX_LEN)),\n",
    "                                              enc_len_ph:data_len[start:stop],\n",
    "                                                y_len_ph:np.zeros((BATCH))})\n",
    "                        \n",
    "        \n",
    "\n",
    "        y=y[-(len(data)-len(gen_sum)):]\n",
    "        for t in y:\n",
    "            gen_sum.append(t)\n",
    "    \n",
    "    gen_sum=gen_sum[:100]\n",
    "    #processing summaries\n",
    "    summs=[]\n",
    "    for i in gen_sum:\n",
    "        summ=''\n",
    "        for j in i:\n",
    "            if j==stopID:\n",
    "                break\n",
    "            summ = summ+' '+pre_op.inverse_transform(j)\n",
    "        summs.append(summ[1:])\n",
    "    vdo=1200\n",
    "    with open('gen_dev.txt','w+') as fle:\n",
    "        for i in summs:\n",
    "            fle.write('beam_size_5'+'\\tvid'+str(vdo)+'\\t'+i)\n",
    "            fle.write('\\n')\n",
    "            vdo+=1\n",
    "    with open('gen_dev.txt','r') as fle:\n",
    "        pred=fle.read()\n",
    "    return s.calcScore(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver=tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training starts here\n",
    "bestVal=0\n",
    "patience=PATIENCE\n",
    "\n",
    "print 'starting training'\n",
    "training_losses=[]\n",
    "valid_losses=[]\n",
    "valid_bleu=[]\n",
    "tData=np.arange(len(trainSeqReg))\n",
    "dData=np.arange(len(devSeqReg))\n",
    "for j in range(EPOCHS):\n",
    "    np.random.shuffle(tData) #makes them iid\n",
    "    training_loss=0\n",
    "    for i in range(len(trainSeqReg)/BATCH):\n",
    "        start=i*BATCH\n",
    "        stop=(i+1)*BATCH\n",
    "        sourceBatch,targetBatch,sourceBatchLen,targetBatchLen,senTargetBatch=getTrainBatch(tData[start:stop])\n",
    "        \n",
    "        \n",
    "        _,lost=sess.run([train_op,loss],feed_dict={enc_ph:sourceBatch,y_ph:targetBatch,enc_len_ph:sourceBatchLen,\n",
    "                                                y_len_ph:targetBatchLen})\n",
    "        \n",
    "        training_loss+=lost\n",
    "        #print lost,\n",
    "    #calculate t_loss\n",
    "    training_losses.append(training_loss/(len(trainSeqReg)/BATCH))\n",
    "    \n",
    "    #calculate v_loss\n",
    "    #disabled\n",
    "    '''\n",
    "    validation_loss=0\n",
    "    for k in range(len(devSeqReg)/BATCH):\n",
    "        start=k*BATCH\n",
    "        stop=(k+1)*BATCH\n",
    "        sourceBatch,targetBatch,sourceBatchLen,targetBatchLen=getDevBatch(dData[start:stop])\n",
    "        lost=sess.run(loss,feed_dict={enc_ph:sourceBatch,y_ph:targetBatch,enc_len_ph:sourceBatchLen,\n",
    "                                                y_len_ph:targetBatchLen})\n",
    "        validation_loss += lost\n",
    "    \n",
    "    \n",
    "    valid_losses.append(validation_loss/len(devSeqReg))\n",
    "    '''\n",
    "    \n",
    "    valBleu=calValBleu()\n",
    "    valid_bleu.append(valBleu[0])\n",
    "    \n",
    "    \n",
    "    if(valid_bleu[-1]>bestVal) and PATIENCE_MONITOR==True:\n",
    "        bestVal=valid_bleu[-1]\n",
    "        saver.save(sess, \"transModels/best.ckpt\")\n",
    "        print \"saving model best\"\n",
    "        patience=PATIENCE\n",
    "    \n",
    "    print \"Epoch:%d training loss:%.4f: valid loss:%.4f valid bleu:%.4f\"% (j,training_losses[-1],0.0,valid_bleu[-1])\n",
    "    patience-=1\n",
    "    if patience==0 and PATIENCE_MONITOR==True:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=sess.run(y_hat,feed_dict={enc_ph:sourceBatch,y_ph:targetBatch,enc_len_ph:sourceBatchLen,\n",
    "                                                y_len_ph:targetBatchLen})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_op.inverse_transform(tmp[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#restore model\n",
    "saver.restore(sess, \"BestModel/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "saver.save(sess, \"BestTrans/resume.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from transModels/best.ckpt\n"
     ]
    }
   ],
   "source": [
    "if PATIENCE_MONITOR:\n",
    "    saver.restore(sess, \"transModels/best.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=videoFeats[1300:]\n",
    "data_len=videoFeatSize[1300:]\n",
    "if BATCH==1024:\n",
    "    data=np.concatenate([data,data[:354]])\n",
    "    data_len=np.concatenate([data_len,data_len[:354]])\n",
    "gen_sum=[]\n",
    "for i in range(len(data)/BATCH):\n",
    "    start=i*BATCH\n",
    "    stop=(i+1)*BATCH\n",
    "    \n",
    "    y=sess.run(y_hat,feed_dict={enc_ph:data[start:stop],y_ph:np.zeros((BATCH,MAX_LEN)),\n",
    "                                              enc_len_ph:data_len[start:stop],\n",
    "                                                y_len_ph:np.zeros((BATCH))})\n",
    "        \n",
    "    \n",
    "    for t in y:\n",
    "        gen_sum.append(t)\n",
    "\n",
    "if BATCH<1024:        \n",
    "    start=len(data)-BATCH\n",
    "    stop=len(data)\n",
    "    y=sess.run(y_hat,feed_dict={enc_ph:data[start:stop],y_ph:np.zeros((BATCH,MAX_LEN)),\n",
    "                                              enc_len_ph:data_len[start:stop],\n",
    "                                                y_len_ph:np.zeros((BATCH))})\n",
    "    \n",
    "    y=y[-(len(data)-len(gen_sum)):]\n",
    "    for t in y:\n",
    "        gen_sum.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_sum=gen_sum[:670]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data=videoFeats[1300:1364]\n",
    "data_len=videoFeatSize[1300:1364]\n",
    "gen_sum=[]\n",
    "for i in range(len(data)/BATCH):\n",
    "    start=i*BATCH\n",
    "    stop=(i+1)*BATCH\n",
    "    load_trs=trs\n",
    "    y=sess.run(load_trs,feed_dict={source_seq:data[start:stop],\n",
    "                                               source_seq_len:data_len[start:stop],\n",
    "                                              batch_size:BATCH,\n",
    "                                                keep_prob:1.0\n",
    "                                                })\n",
    "    for t in y:\n",
    "        gen_sum.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing summaries\n",
    "summs=[]\n",
    "for i in gen_sum:\n",
    "    summ=''\n",
    "    for j in i:\n",
    "        if j==stopID:\n",
    "            break\n",
    "        summ = summ+' '+pre_op.inverse_transform(j)\n",
    "    summs.append(summ[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(len(summs)):\n",
    "    print i,summs[i],vops[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vops=np.load('../MSVD/clip_index/testIndex.npy')[:64]\n",
    "ref_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#real shit\n",
    "with open('ref_dev.txt','w+') as fle:\n",
    "    for i in devCaptions:\n",
    "        fle.write('vid'+str(i[0])+'\\t'+' '.join(i[1][1:-1]))\n",
    "        fle.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdo=1300\n",
    "with open('genTrans.txt','w+') as fle:\n",
    "    for i in summs:\n",
    "        fle.write('beam_size_1'+'\\tvid'+str(vdo)+'\\t'+i+'.')\n",
    "        fle.write('\\n')\n",
    "        vdo+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "37013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
