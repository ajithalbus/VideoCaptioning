{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from sklearn import preprocessing as pre\n",
    "#from pathos.pools import ProcessPool as Pool\n",
    "tf.set_random_seed(1234)\n",
    "np.random.seed(1234)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some hypers\n",
    "GO='<START>'\n",
    "STOP='<END>'\n",
    "pad='<PAD>'\n",
    "unknown='<UNKNOWN>'\n",
    "BATCH=64\n",
    "EPOCHS=50\n",
    "embedding_size=512\n",
    "lstm_units=1024\n",
    "dropout_keep_prob=0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "with open('./lingua.pkl') as f:\n",
    "    trainCaptions=pkl.load(f)\n",
    "trainCaptions=trainCaptions[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processToken(caps):\n",
    "    nk=[]\n",
    "    \n",
    "    for i in caps:\n",
    "        t=[GO]+list(i)+[STOP]\n",
    "        nk.append(t)\n",
    "    return nk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainCaptions=processToken(trainCaptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listofwords(data):\n",
    "    '''takes a list of sentences nd returns vocab'''\n",
    "    a=[]\n",
    "    for i in data:\n",
    "        for j in i:\n",
    "            if j not in a:\n",
    "                a.append(j)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "#with open('./vocab.pkl') as f:\n",
    "#    trainVocab=pkl.load(f)\n",
    "\n",
    "trainVocab=listofwords(trainCaptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoder for output transform\n",
    "pre_op=pre.LabelEncoder()\n",
    "pre_op.fit(trainVocab)\n",
    "onehoter=np.identity(len(pre_op.classes_),dtype=np.bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e5aa2b4bbe46bdb48eb9928f55a45f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=100000), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#word to int\n",
    "from tqdm import tqdm_notebook\n",
    "trainSeq=[]\n",
    "for i in tqdm_notebook(range(len(trainCaptions))):\n",
    "    trainSeq.append(pre_op.transform(trainCaptions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397931348f5249d987ab4efb491f42de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=100000), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainSeqLen=[len(i) for i in tqdm_notebook(trainSeq)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('./vocab.pkl','w+') as f:\n",
    "    pkl.dump(obj=trainVocab,file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf00d482f9fc4337b3f98c45e41fadb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=100000), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#aeppending stops\n",
    "\n",
    "MAX_LEN=max(trainSeqLen)\n",
    "trainSeqReg=[np.pad(i,(0,MAX_LEN-len(i)),'constant',constant_values=pre_op.transform([STOP])) for i in tqdm_notebook(trainSeq)]\n",
    "trainSeqReg=np.array(trainSeqReg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets build the graph\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_seq = tf.placeholder(shape=(None,None),dtype=tf.int32)\n",
    "source_seq_len = tf.placeholder(shape=(None,), dtype=tf.int32)\n",
    "no_start_target_seq = tf.placeholder(shape=(None,None),dtype=tf.int32)\n",
    "real_target_seq_len= tf.placeholder(shape=(None,), dtype=tf.int32)\n",
    "batch_size = tf.placeholder(shape=(None),dtype=tf.int32)\n",
    "keep_prob= tf.placeholder(dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output embeddings\n",
    "embedding_matrix_encode = tf.get_variable(\n",
    "    name=\"embedding_matrix_en\",\n",
    "    shape=[len(trainVocab), embedding_size],\n",
    "    dtype=tf.float32)\n",
    "decoder_input_embedded = tf.nn.embedding_lookup(embedding_matrix_encode, source_seq) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#output embeddings\n",
    "embedding_matrix_decode = tf.Variable(initial_value=tf.random_normal(shape=[trainVocabSize, embedding_size],dtype=tf.float32))\n",
    "decoder_input_embedded = tf.nn.embedding_lookup(embedding_matrix_decode, target_seq) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder\n",
    "encoderCell=tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.BasicLSTMCell(lstm_units),input_keep_prob=keep_prob,\n",
    "                                          output_keep_prob=keep_prob)\n",
    "#encoder_outputs,encoder_final_state=tf.nn.dynamic_rnn(cell=encoderCell,inputs=source_seq,sequence_length=source_seq_len,\n",
    "#                dtype=tf.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training helper and decoder\n",
    "output_layer = tf.layers.Dense(len(trainVocab))\n",
    "helper = tf.contrib.seq2seq.TrainingHelper(decoder_input_embedded,source_seq_len)\n",
    "decoder = tf.contrib.seq2seq.BasicDecoder(encoderCell, helper,encoderCell.zero_state(BATCH,dtype=tf.float32),output_layer=output_layer)#,output_layer=projection_layer)\n",
    "outputs, state, seq_len = tf.contrib.seq2seq.dynamic_decode(decoder)\n",
    "logits = outputs.rnn_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss and optimizer\n",
    "\n",
    "#loss1\n",
    "cross_entropy=tf.nn.sparse_softmax_cross_entropy_with_logits(labels=no_start_target_seq,logits=logits)\n",
    "\n",
    "target_weights = tf.sequence_mask(real_target_seq_len, source_seq_len[0], dtype=logits.dtype)\n",
    "\n",
    "loss=tf.reduce_sum(cross_entropy*target_weights)\n",
    "\n",
    "#train = tf.train.AdamOptimizer().minimize(total_loss)\n",
    "\n",
    "#gradient clipping stackoverflow\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "gradients, variables = zip(*optimizer.compute_gradients(loss))\n",
    "gradients, _ = tf.clip_by_global_norm(gradients, 10.0)\n",
    "train = optimizer.apply_gradients(zip(gradients, variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont touch\n",
    "maxtlen=max(trainSeqLen)\n",
    "t_newlen=[maxtlen-1 for i in range(len(trainSeqLen))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver=tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes training batch\n",
    "def getTrainBatch(indexs):\n",
    "    targetBatch=np.array([trainSeqReg[i] for i in indexs])\n",
    "    targetBatchLen=np.array([trainSeqLen[i] for i in indexs])\n",
    "    return targetBatch,targetBatchLen\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#restore model\n",
    "saver.restore(sess, \"BestModel/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n"
     ]
    }
   ],
   "source": [
    "#training starts here\n",
    "\n",
    "print 'starting training'\n",
    "training_losses=[]\n",
    "valid_losses=[]\n",
    "tData=np.arange(len(trainSeqReg))\n",
    "for j in range(EPOCHS):\n",
    "    np.random.shuffle(tData) #makes them iid\n",
    "    training_loss=0\n",
    "    for i in range(len(trainSeqReg)/BATCH):\n",
    "        start=i*BATCH\n",
    "        stop=(i+1)*BATCH\n",
    "        targetBatch,targetBatchLen=getTrainBatch(tData[start:stop])\n",
    "        _,lost=sess.run([train,loss],feed_dict={source_seq:targetBatch,\n",
    "                                                \n",
    "                                              source_seq_len:t_newlen[start:stop],\n",
    "                                                real_target_seq_len:targetBatchLen,\n",
    "                                                no_start_target_seq:np.array(targetBatch)[:,1:],\n",
    "                                                batch_size:BATCH,keep_prob:dropout_keep_prob\n",
    "                                                })\n",
    "        \n",
    "        training_loss+=lost\n",
    "        #print lost,\n",
    "    #calculate t_loss\n",
    "    training_losses.append(training_loss/len(trainSeqReg))\n",
    "    \n",
    "    print \"Epoch:%d training loss:%.4f\"% (j,training_losses[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PATIENCE_MONITOR:\n",
    "    saver.restore(sess, \"model/bestModel.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "saver.save(sess, \"model/continue.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=videoFeats[1300:]\n",
    "data_len=videoFeatSize[1300:]\n",
    "if BATCH==1024:\n",
    "    data=np.concatenate([data,data[:354]])\n",
    "    data_len=np.concatenate([data_len,data_len[:354]])\n",
    "gen_sum=[]\n",
    "for i in range(len(data)/BATCH):\n",
    "    start=i*BATCH\n",
    "    stop=(i+1)*BATCH\n",
    "    \n",
    "    load_trs=trs_beam\n",
    "    y=sess.run(load_trs,feed_dict={source_seq:data[start:stop],\n",
    "                                               source_seq_len:data_len[start:stop],\n",
    "                                              batch_size:BATCH,keep_prob:1.0\n",
    "                                                })\n",
    "    y=y[:,:,0]\n",
    "    \n",
    "    for t in y:\n",
    "        gen_sum.append(t)\n",
    "\n",
    "'''        \n",
    "start=len(data)-BATCH\n",
    "stop=len(data)\n",
    "y=sess.run(trs_beam,feed_dict={source_seq:data[start:stop],\n",
    "                                               source_seq_len:data_len[start:stop],\n",
    "                                              batch_size:BATCH,keep_prob:1.0\n",
    "                                                })\n",
    "y=y[:,:,0]\n",
    "\n",
    "y=y[-(len(data)-len(gen_sum)):]\n",
    "for t in y:\n",
    "    gen_sum.append(t)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_sum=gen_sum[:670]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data=videoFeats[1300:1364]\n",
    "data_len=videoFeatSize[1300:1364]\n",
    "gen_sum=[]\n",
    "for i in range(len(data)/BATCH):\n",
    "    start=i*BATCH\n",
    "    stop=(i+1)*BATCH\n",
    "    load_trs=trs\n",
    "    y=sess.run(load_trs,feed_dict={source_seq:data[start:stop],\n",
    "                                               source_seq_len:data_len[start:stop],\n",
    "                                              batch_size:BATCH,\n",
    "                                                keep_prob:1.0\n",
    "                                                })\n",
    "    for t in y:\n",
    "        gen_sum.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing summaries\n",
    "summs=[]\n",
    "for i in gen_sum:\n",
    "    summ=''\n",
    "    for j in i:\n",
    "        \n",
    "        if j!=58:\n",
    "            summ = summ+' '+pre_op.inverse_transform(j)\n",
    "    summs.append(summ[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(len(summs)):\n",
    "    print i,summs[i],vops[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vops=np.load('../MSVD/clip_index/testIndex.npy')[:64]\n",
    "ref_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#real shit\n",
    "with open('ref_dev.txt','w+') as fle:\n",
    "    for i in devCaptions:\n",
    "        fle.write('vid'+str(i[0])+'\\t'+' '.join(i[1][1:-1]))\n",
    "        fle.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdo=1300\n",
    "with open('gen.txt','w+') as fle:\n",
    "    for i in summs:\n",
    "        fle.write('beam_size_5'+'\\tvid'+str(vdo)+'\\t'+i)\n",
    "        fle.write('\\n')\n",
    "        vdo+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
