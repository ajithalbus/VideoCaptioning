{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from sklearn import preprocessing as pre\n",
    "#from pathos.pools import ProcessPool as Pool\n",
    "tf.set_random_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "import xmlrpclib\n",
    "\n",
    "s = xmlrpclib.ServerProxy('http://10.21.230.64:8778')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some hypers\n",
    "GO='<START>'\n",
    "STOP='<END>'\n",
    "pad='<PAD>'\n",
    "unknown='<UNKNOWN>'\n",
    "BATCH=1024\n",
    "BEAM_WIDTH=5\n",
    "EPOCHS=100\n",
    "LAM=0.9\n",
    "embedding_size=512\n",
    "lstm_units=1024\n",
    "dropout_keep_prob=0.5\n",
    "PATIENCE=50\n",
    "PATIENCE_MONITOR=True\n",
    "GLOVE=True #if true embedding size will reset to 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile):\n",
    "    print \"Loading Glove Model\"\n",
    "    f = open(gloveFile,'r')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print \"Done.\",len(model),\" words loaded!\"\n",
    "    return model\n",
    "if GLOVE:\n",
    "    embedding_size=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "with open('./captions/token_train.pkl') as f:\n",
    "    trainCaptions=pkl.load(f)\n",
    "with open('./captions/token_dev.pkl') as f:\n",
    "    devCaptions=pkl.load(f)\n",
    "with open('./captions/token_test.pkl') as f:\n",
    "    testCaptions=pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processToken(caps):\n",
    "    nk=[]\n",
    "    \n",
    "    for i in caps:\n",
    "        t=[GO]+list(i[1])+[STOP]\n",
    "        empty=33-len(t)\n",
    "        \n",
    "        #t=t+[pad]*empty\n",
    "        nk.append([i[0],t])\n",
    "    return nk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainCaptions=processToken(trainCaptions)\n",
    "devCaptions=processToken(devCaptions)\n",
    "testCaptions=processToken(testCaptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listofwords(data):\n",
    "    '''takes a list of sentences nd returns vocab'''\n",
    "    a=[]\n",
    "    for i in data:\n",
    "        for j in i[1]:\n",
    "            if j not in a:\n",
    "                a.append(j)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the vocab and size\n",
    "trainVocab=listofwords(trainCaptions+devCaptions)\n",
    "trainVocabSize=len(trainVocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find cap len\n",
    "trainCapLen=[len(i[1]) for i in trainCaptions]\n",
    "devCapLen=[len(i[1]) for i in devCaptions]\n",
    "testCapLen=[len(i[1]) for i in testCaptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoder for output transform\n",
    "pre_op=pre.LabelEncoder()\n",
    "pre_op.fit(trainVocab)\n",
    "onehoter=np.identity(len(pre_op.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word to int\n",
    "trainSeq=[pre_op.transform(i[1]) for i in trainCaptions]\n",
    "devSeq=[pre_op.transform(i[1]) for i in devCaptions]\n",
    "trainID=[i[0] for i in trainCaptions]\n",
    "devID=[i[0] for i in devCaptions]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#word to int with pool\n",
    "p=Pool(8)\n",
    "\n",
    "\n",
    "trainSeq=p.map(pre_op.transform,[i[1] for i in trainCaptions])\n",
    "devSeq=p.map(pre_op.transform,[i[1] for i in devCaptions])\n",
    "trainID=[i[0] for i in trainCaptions]\n",
    "devID=[i[0] for i in devCaptions]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appending stops\n",
    "\n",
    "MAX_LEN=33\n",
    "trainSeqReg=[np.pad(i,(0,MAX_LEN-len(i)),'constant',constant_values=pre_op.transform([STOP])) for i in trainSeq]\n",
    "devSeqReg=[np.pad(i,(0,MAX_LEN-len(i)),'constant',constant_values=pre_op.transform([STOP])) for i in devSeq]\n",
    "trainSeqReg=np.array(trainSeqReg)\n",
    "devSeqReg=np.array(devSeqReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading video features\n",
    "videoFeats=np.load(file='./features/consilidated_feats.npy')\n",
    "videoFeatSize=np.array([len(i) for i in videoFeats])\n",
    "#making the shape regular\n",
    "videoFeats=np.array([np.pad(i,mode='constant',pad_width=[(0,28-len(i)),(0,0)]) for i in videoFeats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "#glove\n",
    "if GLOVE:\n",
    "    gloveModel=loadGloveModel('./glove/glove.6B.300d.txt')\n",
    "    gloveEmbedding=[]\n",
    "    for i in pre_op.classes_:\n",
    "        if gloveModel.has_key(i):\n",
    "            gloveEmbedding.append(gloveModel[i])\n",
    "        else:\n",
    "            gloveEmbedding.append(np.random.normal(size=(300)))\n",
    "    gloveEmbedding=np.array(gloveEmbedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets build the graph\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_seq = tf.placeholder(shape=(None,28,2048),dtype=tf.float32)\n",
    "target_seq = tf.placeholder(shape=(None,33),dtype=tf.int32)\n",
    "source_seq_len = tf.placeholder(shape=(None,), dtype=tf.int32)\n",
    "target_seq_len = tf.placeholder(shape=(None,), dtype=tf.int32)\n",
    "no_start_target_seq = tf.placeholder(shape=(None,32),dtype=tf.int32)\n",
    "batch_size = tf.placeholder(shape=(None),dtype=tf.int32)\n",
    "real_target_seq_len= tf.placeholder(shape=(None,), dtype=tf.int32)\n",
    "keep_prob= tf.placeholder(dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output embeddings\n",
    "if GLOVE:\n",
    "    embedding_matrix_decode = tf.Variable(initial_value=gloveEmbedding,\n",
    "    name=\"embedding_matrix_de\",\n",
    "    expected_shape=[trainVocabSize, embedding_size],\n",
    "    dtype=tf.float32)\n",
    "else:\n",
    "    embedding_matrix_decode = tf.get_variable(\n",
    "    name=\"embedding_matrix_de\",\n",
    "    expected_shape=[trainVocabSize, embedding_size],\n",
    "    dtype=tf.float32)\n",
    "decoder_input_embedded = tf.nn.embedding_lookup(embedding_matrix_decode, target_seq) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#output embeddings\n",
    "embedding_matrix_decode = tf.Variable(initial_value=tf.random_normal(shape=[trainVocabSize, embedding_size],dtype=tf.float32))\n",
    "decoder_input_embedded = tf.nn.embedding_lookup(embedding_matrix_decode, target_seq) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder\n",
    "encoderCell=tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.BasicLSTMCell(lstm_units),input_keep_prob=keep_prob,\n",
    "                                          output_keep_prob=keep_prob)\n",
    "encoder_outputs,encoder_final_state=tf.nn.dynamic_rnn(cell=encoderCell,inputs=source_seq,sequence_length=source_seq_len,\n",
    "                 dtype=tf.float32)\n",
    "\n",
    "#expri\n",
    "#encoder_outputs_tiled=tf.contrib.seq2seq.tile_batch(encoder_outputs,multiplier=BEAM_WIDTH)\n",
    "#encoder ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#exp\n",
    "tiled_encoder_outputs = tf.contrib.seq2seq.tile_batch(\n",
    "    encoder_outputs, multiplier=BEAM_WIDTH)\n",
    "tiled_encoder_final_state = tf.contrib.seq2seq.tile_batch(\n",
    "    encoder_final_state, multiplier=BEAM_WIDTH)\n",
    "tiled_sequence_length = tf.contrib.seq2seq.tile_batch(\n",
    "    source_seq_len, multiplier=BEAM_WIDTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#exp\n",
    "attention_mechanism = tf.contrib.seq2seq.LuongAttention(lstm_units,encoder_outputs,memory_sequence_length=tiled_sequence_length)\n",
    "attention_cell = tf.contrib.seq2seq.AttentionWrapper(tf.contrib.rnn.LSTMCell(lstm_units), attention_mechanism,attention_layer_size=lstm_units)\n",
    "decoder_initial_state = attention_cell.zero_state(\n",
    "    dtype=tf.float32, batch_size=BATCH * BEAM_WIDTH)\n",
    "decoder_initial_state = decoder_initial_state.clone(\n",
    "    cell_state=tiled_encoder_final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attention\n",
    "with tf.variable_scope(\"myScope\"):\n",
    "    attention_mechanism_train = tf.contrib.seq2seq.LuongAttention(lstm_units,encoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attention\n",
    "#expri\n",
    "with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "    tiled_encoder_outputs = tf.contrib.seq2seq.tile_batch(\n",
    "        encoder_outputs, multiplier=BEAM_WIDTH)\n",
    "\n",
    "    attention_mechanism_infer = tf.contrib.seq2seq.LuongAttention(lstm_units,tiled_encoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Projection layer and decoder cell\n",
    "with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "    output_layer = tf.layers.Dense(trainVocabSize)\n",
    "\n",
    "    decoder_cell=tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.BasicLSTMCell(lstm_units),input_keep_prob=keep_prob,\n",
    "                                          output_keep_prob=keep_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_initial_state=encoder_final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder Attention wrapper\n",
    "#expri\n",
    "with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "    decoder_cell_train = tf.contrib.seq2seq.AttentionWrapper(\n",
    "            decoder_cell, attention_mechanism_train,\n",
    "            attention_layer_size=lstm_units,alignment_history=False)\n",
    "    decoder_initial_state_train = decoder_cell_train.zero_state(BATCH, tf.float32).clone(cell_state=decoder_initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training helper and decoder\n",
    "with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "    helper = tf.contrib.seq2seq.TrainingHelper(decoder_input_embedded,target_seq_len)\n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell_train, helper, initial_state=decoder_initial_state_train,output_layer=output_layer)#,output_layer=projection_layer)\n",
    "    outputs, state, seq_len = tf.contrib.seq2seq.dynamic_decode(decoder)\n",
    "    logits = outputs.rnn_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cheap trick\n",
    "emd_copy=tf.Variable(tf.zeros(shape=embedding_matrix_decode.shape))\n",
    "emd_copier=emd_copy.assign(embedding_matrix_decode)\n",
    "mask58=np.ones(shape=emd_copier.shape)\n",
    "mask58[58]=0\n",
    "mask58=tf.constant(mask58,dtype=tf.float32)\n",
    "emd58=emd_copier*mask58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding sentence embeddings\n",
    "sentence_ids=outputs.sample_id\n",
    "decoder_output_embedded=tf.nn.embedding_lookup(emd58,sentence_ids)\n",
    "maskMeter=seq_len\n",
    "sentence_embedding=tf.reduce_mean(decoder_output_embedded,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_embedding=tf.concat([decoder_initial_state.c,decoder_initial_state.h],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Inference helper(greedy) and decoder\n",
    "helper2 = tf.contrib.seq2seq.GreedyEmbeddingHelper(embedding_matrix_decode,tf.fill([batch_size],\n",
    "                                                    np.int32(pre_op.transform([GO])[0])),\n",
    "                                                   np.int32(pre_op.transform([STOP])[0]))\n",
    "\n",
    "\n",
    "decoder2 = tf.contrib.seq2seq.BasicDecoder(decoder_cell, helper2, decoder_initial_state,output_layer=output_layer)#,output_layer=projection_layer)\n",
    "\n",
    "outputs, state, seq_len = tf.contrib.seq2seq.dynamic_decode(decoder2,maximum_iterations=32+10)\n",
    "\n",
    "translations_logits = outputs.rnn_output\n",
    "trs=outputs.sample_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expri\n",
    "#decoder Attention wrapper\n",
    "with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "    decoder_cell_infer = tf.contrib.seq2seq.AttentionWrapper(\n",
    "            decoder_cell, attention_mechanism_infer,\n",
    "            attention_layer_size=lstm_units,alignment_history=False)\n",
    "    decoder_initial_state_infer = decoder_cell_infer.zero_state(BATCH, tf.float32).clone(cell_state=decoder_initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Beam Search decoder\n",
    "with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "    decoder_initial_state_tiled = tf.contrib.seq2seq.tile_batch(\n",
    "        decoder_initial_state_infer[0], multiplier=BEAM_WIDTH)\n",
    "\n",
    "    decoder_initial_state_tiled=decoder_cell_infer.zero_state(batch_size=BATCH*BEAM_WIDTH,dtype=tf.float32).clone(cell_state=decoder_initial_state_tiled)\n",
    "\n",
    "\n",
    "    # Define a beam-search decoder\n",
    "    decoder3 = tf.contrib.seq2seq.BeamSearchDecoder(\n",
    "            cell=decoder_cell_infer,\n",
    "            embedding=embedding_matrix_decode,\n",
    "            start_tokens=tf.fill([batch_size],np.int32(pre_op.transform([GO])[0])),\n",
    "            end_token=np.int32(pre_op.transform([STOP])[0]),\n",
    "            initial_state=decoder_initial_state_tiled,\n",
    "            beam_width=BEAM_WIDTH,\n",
    "            output_layer=output_layer,\n",
    "            length_penalty_weight=0.0)\n",
    "    outputs, state, seq_len = tf.contrib.seq2seq.dynamic_decode(decoder3,maximum_iterations=32+10)\n",
    "\n",
    "\n",
    "    trs_beam=outputs.predicted_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss and optimizer\n",
    "\n",
    "#loss1\n",
    "cross_entropy=tf.nn.sparse_softmax_cross_entropy_with_logits(labels=no_start_target_seq,logits=logits)\n",
    "\n",
    "target_weights = tf.sequence_mask(real_target_seq_len, target_seq_len[0], dtype=logits.dtype)\n",
    "\n",
    "loss1=tf.reduce_sum(cross_entropy*target_weights)\n",
    "\n",
    "#loss2\n",
    "sentence_on_video_space=tf.layers.dense(inputs=sentence_embedding,units=2*lstm_units)\n",
    "\n",
    "loss2=tf.reduce_sum(tf.nn.l2_loss(sentence_on_video_space- video_embedding))\n",
    "\n",
    "total_loss = LAM * loss1 + (1-LAM) *loss2\n",
    "#train = tf.train.AdamOptimizer().minimize(total_loss)\n",
    "\n",
    "#gradient clipping stackoverflow\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "gradients, variables = zip(*optimizer.compute_gradients(total_loss))\n",
    "gradients, _ = tf.clip_by_global_norm(gradients, 10.0)\n",
    "train = optimizer.apply_gradients(zip(gradients, variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont touch\n",
    "maxtlen=max(trainCapLen)\n",
    "maxvlen=max(devCapLen)\n",
    "t_newlen=[maxtlen-1 for i in range(len(trainCapLen))]\n",
    "v_newlen=[maxtlen-1 for i in range(len(devCapLen))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver=tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes training batch\n",
    "def getTrainBatch(indexs):\n",
    "    sourceBatch=np.array([videoFeats[trainID[i]] for i in indexs])\n",
    "    targetBatch=np.array([trainSeqReg[i] for i in indexs])\n",
    "    sourceBatchLen=np.array([videoFeatSize[trainID[i]] for i in indexs])\n",
    "    targetBatchLen=np.array([trainCapLen[i] for i in indexs])\n",
    "    return sourceBatch,targetBatch,sourceBatchLen,targetBatchLen\n",
    "\n",
    "#makes dev batch\n",
    "def getDevBatch(indexs):\n",
    "    sourceBatch=np.array([videoFeats[devID[i]] for i in indexs])\n",
    "    targetBatch=np.array([devSeqReg[i] for i in indexs])\n",
    "    sourceBatchLen=np.array([videoFeatSize[devID[i]] for i in indexs])\n",
    "    targetBatchLen=np.array([devCapLen[i] for i in indexs])\n",
    "    return sourceBatch,targetBatch,sourceBatchLen,targetBatchLen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#restore model\n",
    "saver.restore(sess, \"BestModel/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calValBleu():\n",
    "    data=videoFeats[1200:1300]\n",
    "    data_len=videoFeatSize[1200:1300]\n",
    "    if BATCH>100:\n",
    "        data=np.concatenate([data,videoFeats[:BATCH-100]])\n",
    "        data_len=np.concatenate([data_len,videoFeatSize[:BATCH-100]])\n",
    "    gen_sum=[]\n",
    "    for i in range(len(data)/BATCH):\n",
    "        start=i*BATCH\n",
    "        stop=(i+1)*BATCH\n",
    "\n",
    "        load_trs=trs_beam\n",
    "        y=sess.run(load_trs,feed_dict={source_seq:data[start:stop],\n",
    "                                                   source_seq_len:data_len[start:stop],\n",
    "                                                  batch_size:BATCH,keep_prob:1.0\n",
    "                                                    })\n",
    "        y=y[:,:,0]\n",
    "\n",
    "        for t in y:\n",
    "            gen_sum.append(t)\n",
    "\n",
    "    if BATCH<100:        \n",
    "        start=len(data)-BATCH\n",
    "        stop=len(data)\n",
    "        y=sess.run(trs_beam,feed_dict={source_seq:data[start:stop],\n",
    "                                                       source_seq_len:data_len[start:stop],\n",
    "                                                      batch_size:BATCH,keep_prob:1.0\n",
    "                                                        })\n",
    "        y=y[:,:,0]\n",
    "\n",
    "        y=y[-(len(data)-len(gen_sum)):]\n",
    "        for t in y:\n",
    "            gen_sum.append(t)\n",
    "    \n",
    "    gen_sum=gen_sum[:100]\n",
    "    #processing summaries\n",
    "    summs=[]\n",
    "    for i in gen_sum:\n",
    "        summ=''\n",
    "        for j in i:\n",
    "\n",
    "            if j!=58:\n",
    "                summ = summ+' '+pre_op.inverse_transform(j)\n",
    "        summs.append(summ[1:])\n",
    "    vdo=1200\n",
    "    with open('gen_dev.txt','w+') as fle:\n",
    "        for i in summs:\n",
    "            fle.write('beam_size_5'+'\\tvid'+str(vdo)+'\\t'+i)\n",
    "            fle.write('\\n')\n",
    "            vdo+=1\n",
    "    with open('gen_dev.txt','r') as fle:\n",
    "        pred=fle.read()\n",
    "    return s.calcScore(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n",
      "saving model best\n",
      "Epoch:0 training loss:40.5945: valid loss:24.1349 valid blue:0.2440\n",
      "Epoch:1 training loss:28.6342: valid loss:21.9241 valid blue:0.2073\n",
      "saving model best\n",
      "Epoch:2 training loss:25.7554: valid loss:20.7448 valid blue:0.2461\n",
      "saving model best\n",
      "Epoch:3 training loss:23.3277: valid loss:19.7748 valid blue:0.2526\n",
      "saving model best\n",
      "Epoch:4 training loss:21.3067: valid loss:19.3014 valid blue:0.2663\n",
      "saving model best\n",
      "Epoch:5 training loss:19.8009: valid loss:19.1443 valid blue:0.2819\n",
      "saving model best\n",
      "Epoch:6 training loss:18.5889: valid loss:19.0879 valid blue:0.2885\n",
      "Epoch:7 training loss:17.5992: valid loss:19.0181 valid blue:0.2849\n",
      "saving model best\n",
      "Epoch:8 training loss:16.7231: valid loss:18.9906 valid blue:0.3178\n",
      "Epoch:9 training loss:16.0198: valid loss:19.0069 valid blue:0.2980\n",
      "Epoch:10 training loss:15.3950: valid loss:18.8839 valid blue:0.3175\n",
      "saving model best\n",
      "Epoch:11 training loss:14.8891: valid loss:19.0417 valid blue:0.3179\n",
      "Epoch:12 training loss:14.4412: valid loss:18.9031 valid blue:0.3086\n",
      "Epoch:13 training loss:14.0542: valid loss:19.0497 valid blue:0.3113\n",
      "Epoch:14 training loss:13.7588: valid loss:18.9846 valid blue:0.3085\n",
      "saving model best\n",
      "Epoch:15 training loss:13.4499: valid loss:19.1567 valid blue:0.3181\n",
      "saving model best\n",
      "Epoch:16 training loss:13.1532: valid loss:19.1734 valid blue:0.3315\n",
      "Epoch:17 training loss:12.8803: valid loss:19.0395 valid blue:0.3266\n",
      "Epoch:18 training loss:12.6894: valid loss:19.1213 valid blue:0.3174\n",
      "Epoch:19 training loss:12.5054: valid loss:19.2311 valid blue:0.3170\n",
      "Epoch:20 training loss:12.2937: valid loss:19.1230 valid blue:0.3255\n",
      "Epoch:21 training loss:12.0885: valid loss:19.3229 valid blue:0.3266\n",
      "Epoch:22 training loss:11.9089: valid loss:19.2561 valid blue:0.3265\n",
      "Epoch:23 training loss:11.7728: valid loss:19.1667 valid blue:0.3257\n",
      "saving model best\n",
      "Epoch:24 training loss:11.6086: valid loss:19.1985 valid blue:0.3465\n",
      "Epoch:25 training loss:11.4803: valid loss:19.2546 valid blue:0.3279\n",
      "Epoch:26 training loss:11.3201: valid loss:19.2216 valid blue:0.3396\n",
      "Epoch:27 training loss:11.2014: valid loss:19.2782 valid blue:0.3281\n",
      "Epoch:28 training loss:11.0838: valid loss:19.2557 valid blue:0.3318\n",
      "Epoch:29 training loss:10.9619: valid loss:19.4215 valid blue:0.3345\n",
      "Epoch:30 training loss:10.8363: valid loss:19.2727 valid blue:0.3333\n",
      "Epoch:31 training loss:10.7375: valid loss:19.4260 valid blue:0.3241\n",
      "Epoch:32 training loss:10.6365: valid loss:19.4083 valid blue:0.3327\n",
      "Epoch:33 training loss:10.5325: valid loss:19.3956 valid blue:0.3193\n",
      "Epoch:34 training loss:10.4503: valid loss:19.5214 valid blue:0.3247\n",
      "Epoch:35 training loss:10.3377: valid loss:19.4992 valid blue:0.3356\n",
      "Epoch:36 training loss:10.2670: valid loss:19.3870 valid blue:0.3310\n",
      "Epoch:37 training loss:10.1787: valid loss:19.5989 valid blue:0.3268\n",
      "Epoch:38 training loss:10.0857: valid loss:19.5592 valid blue:0.3271\n",
      "Epoch:39 training loss:10.0272: valid loss:19.6348 valid blue:0.3252\n",
      "Epoch:40 training loss:9.9301: valid loss:19.5505 valid blue:0.3321\n",
      "Epoch:41 training loss:9.8599: valid loss:19.6797 valid blue:0.3225\n",
      "Epoch:42 training loss:9.7907: valid loss:19.6053 valid blue:0.3318\n",
      "Epoch:43 training loss:9.7084: valid loss:19.5083 valid blue:0.3164\n",
      "Epoch:44 training loss:9.6643: valid loss:19.5575 valid blue:0.3281\n",
      "Epoch:45 training loss:9.5864: valid loss:19.7061 valid blue:0.3274\n",
      "Epoch:46 training loss:9.5414: valid loss:19.7376 valid blue:0.3294\n",
      "Epoch:47 training loss:9.4479: valid loss:19.7617 valid blue:0.3371\n",
      "Epoch:48 training loss:9.4042: valid loss:19.7426 valid blue:0.3258\n",
      "Epoch:49 training loss:9.3495: valid loss:19.9327 valid blue:0.3383\n",
      "Epoch:50 training loss:9.3073: valid loss:19.7693 valid blue:0.3244\n",
      "Epoch:51 training loss:9.2326: valid loss:19.9449 valid blue:0.3385\n",
      "Epoch:52 training loss:9.1666: valid loss:19.9646 valid blue:0.3320\n",
      "Epoch:53 training loss:9.1384: valid loss:19.7956 valid blue:0.3397\n",
      "Epoch:54 training loss:9.0943: valid loss:19.8828 valid blue:0.3242\n",
      "Epoch:55 training loss:9.0274: valid loss:20.0637 valid blue:0.3209\n",
      "Epoch:56 training loss:8.9794: valid loss:19.8476 valid blue:0.3297\n",
      "Epoch:57 training loss:8.9506: valid loss:20.0042 valid blue:0.3207\n",
      "Epoch:58 training loss:8.8710: valid loss:20.1099 valid blue:0.3332\n",
      "Epoch:59 training loss:8.8414: valid loss:20.0970 valid blue:0.3264\n",
      "Epoch:60 training loss:8.7997: valid loss:20.1114 valid blue:0.3277\n",
      "Epoch:61 training loss:8.7471: valid loss:20.0398 valid blue:0.3179\n",
      "Epoch:62 training loss:8.6994: valid loss:20.0952 valid blue:0.3301\n",
      "Epoch:63 training loss:8.6528: valid loss:20.0135 valid blue:0.3239\n",
      "Epoch:64 training loss:8.6204: valid loss:20.1912 valid blue:0.3255\n",
      "Epoch:65 training loss:8.5958: valid loss:20.1693 valid blue:0.3264\n",
      "Epoch:66 training loss:8.5313: valid loss:20.2958 valid blue:0.3277\n",
      "Epoch:67 training loss:8.5157: valid loss:20.2252 valid blue:0.3288\n",
      "Epoch:68 training loss:8.4874: valid loss:20.2759 valid blue:0.3204\n"
     ]
    }
   ],
   "source": [
    "#training starts here\n",
    "bestVal=0\n",
    "patience=PATIENCE\n",
    "\n",
    "print 'starting training'\n",
    "training_losses=[]\n",
    "valid_losses=[]\n",
    "valid_bleu=[]\n",
    "tData=np.arange(len(trainSeqReg))\n",
    "dData=np.arange(len(devSeqReg))\n",
    "for j in range(EPOCHS):\n",
    "    np.random.shuffle(tData) #makes them iid\n",
    "    training_loss=0\n",
    "    for i in range(len(trainSeqReg)/BATCH):\n",
    "        start=i*BATCH\n",
    "        stop=(i+1)*BATCH\n",
    "        sourceBatch,targetBatch,sourceBatchLen,targetBatchLen=getTrainBatch(tData[start:stop])\n",
    "        _,lost=sess.run([train,total_loss],feed_dict={source_seq:sourceBatch,\n",
    "                                                target_seq:targetBatch,\n",
    "                                              source_seq_len:sourceBatchLen,\n",
    "                                                target_seq_len:t_newlen[start:stop],\n",
    "                                                real_target_seq_len:targetBatchLen,\n",
    "                                                no_start_target_seq:np.array(targetBatch)[:,1:],\n",
    "                                                batch_size:BATCH,keep_prob:dropout_keep_prob\n",
    "                                                })\n",
    "        \n",
    "        training_loss+=lost\n",
    "        #print lost,\n",
    "    #calculate t_loss\n",
    "    training_losses.append(training_loss/len(trainSeqReg))\n",
    "    \n",
    "    #calculate v_loss\n",
    "    validation_loss=0\n",
    "    for k in range(len(devSeqReg)/BATCH):\n",
    "        start=k*BATCH\n",
    "        stop=(k+1)*BATCH\n",
    "        sourceBatch,targetBatch,sourceBatchLen,targetBatchLen=getDevBatch(dData[start:stop])\n",
    "        lost=sess.run(total_loss,feed_dict={source_seq:sourceBatch,\n",
    "                                                target_seq:targetBatch,\n",
    "                                              source_seq_len:sourceBatchLen,\n",
    "                                                target_seq_len:t_newlen[start:stop],\n",
    "                                                real_target_seq_len:targetBatchLen,\n",
    "                                                no_start_target_seq:np.array(targetBatch)[:,1:],\n",
    "                                                batch_size:BATCH,keep_prob:1.0\n",
    "                                                })\n",
    "        validation_loss += lost\n",
    "    valBleu=calValBleu()\n",
    "    valid_bleu.append(valBleu[-1])\n",
    "    valid_losses.append(validation_loss/len(devSeqReg))\n",
    "    \n",
    "    if(valid_bleu[-1]>bestVal) and PATIENCE_MONITOR==True:\n",
    "        bestVal=valid_bleu[-1]\n",
    "        saver.save(sess, \"model/bestModel.ckpt\")\n",
    "        print \"saving model best\"\n",
    "        patience=PATIENCE\n",
    "    print \"Epoch:%d training loss:%.4f: valid loss:%.4f valid blue:%.4f\"% (j,training_losses[-1],valid_losses[-1],valid_bleu[-1])\n",
    "    patience-=1\n",
    "    if patience==0 and PATIENCE_MONITOR==True:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/bestModel.ckpt\n"
     ]
    }
   ],
   "source": [
    "if PATIENCE_MONITOR:\n",
    "    saver.restore(sess, \"model/bestModel.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model/continue.ckpt'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "saver.save(sess, \"model/continue.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'        \\nstart=len(data)-BATCH\\nstop=len(data)\\ny=sess.run(trs_beam,feed_dict={source_seq:data[start:stop],\\n                                               source_seq_len:data_len[start:stop],\\n                                              batch_size:BATCH,keep_prob:1.0\\n                                                })\\ny=y[:,:,0]\\n\\ny=y[-(len(data)-len(gen_sum)):]\\nfor t in y:\\n    gen_sum.append(t)\\n'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=videoFeats[1300:]\n",
    "data_len=videoFeatSize[1300:]\n",
    "if BATCH==1024:\n",
    "    data=np.concatenate([data,data[:354]])\n",
    "    data_len=np.concatenate([data_len,data_len[:354]])\n",
    "gen_sum=[]\n",
    "for i in range(len(data)/BATCH):\n",
    "    start=i*BATCH\n",
    "    stop=(i+1)*BATCH\n",
    "    \n",
    "    load_trs=trs_beam\n",
    "    y=sess.run(load_trs,feed_dict={source_seq:data[start:stop],\n",
    "                                               source_seq_len:data_len[start:stop],\n",
    "                                              batch_size:BATCH,keep_prob:1.0\n",
    "                                                })\n",
    "    y=y[:,:,0]\n",
    "    \n",
    "    for t in y:\n",
    "        gen_sum.append(t)\n",
    "\n",
    "'''        \n",
    "start=len(data)-BATCH\n",
    "stop=len(data)\n",
    "y=sess.run(trs_beam,feed_dict={source_seq:data[start:stop],\n",
    "                                               source_seq_len:data_len[start:stop],\n",
    "                                              batch_size:BATCH,keep_prob:1.0\n",
    "                                                })\n",
    "y=y[:,:,0]\n",
    "\n",
    "y=y[-(len(data)-len(gen_sum)):]\n",
    "for t in y:\n",
    "    gen_sum.append(t)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_sum=gen_sum[:670]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data=videoFeats[1300:1364]\n",
    "data_len=videoFeatSize[1300:1364]\n",
    "gen_sum=[]\n",
    "for i in range(len(data)/BATCH):\n",
    "    start=i*BATCH\n",
    "    stop=(i+1)*BATCH\n",
    "    load_trs=trs\n",
    "    y=sess.run(load_trs,feed_dict={source_seq:data[start:stop],\n",
    "                                               source_seq_len:data_len[start:stop],\n",
    "                                              batch_size:BATCH,\n",
    "                                                keep_prob:1.0\n",
    "                                                })\n",
    "    for t in y:\n",
    "        gen_sum.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing summaries\n",
    "summs=[]\n",
    "for i in gen_sum:\n",
    "    summ=''\n",
    "    for j in i:\n",
    "        \n",
    "        if j!=58:\n",
    "            summ = summ+' '+pre_op.inverse_transform(j)\n",
    "    summs.append(summ[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(len(summs)):\n",
    "    print i,summs[i],vops[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vops=np.load('../MSVD/clip_index/testIndex.npy')[:64]\n",
    "ref_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#real shit\n",
    "with open('ref_dev.txt','w+') as fle:\n",
    "    for i in devCaptions:\n",
    "        fle.write('vid'+str(i[0])+'\\t'+' '.join(i[1][1:-1]))\n",
    "        fle.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdo=1300\n",
    "with open('gen.txt','w+') as fle:\n",
    "    for i in summs:\n",
    "        fle.write('beam_size_5'+'\\tvid'+str(vdo)+'\\t'+i)\n",
    "        fle.write('\\n')\n",
    "        vdo+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
