{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/scipy/sparse/lil.py:19: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _csparsetools\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/sparse/csgraph/__init__.py:165: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._shortest_path import shortest_path, floyd_warshall, dijkstra,\\\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/sparse/csgraph/_validation.py:5: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._tools import csgraph_to_dense, csgraph_from_dense,\\\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/sparse/csgraph/__init__.py:167: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._traversal import breadth_first_order, depth_first_order, \\\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/sparse/csgraph/__init__.py:169: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._min_spanning_tree import minimum_spanning_tree\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/sparse/csgraph/__init__.py:170: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._reordering import reverse_cuthill_mckee, maximum_bipartite_matching, \\\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/linalg/basic.py:17: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._solve_toeplitz import levinson\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/linalg/__init__.py:207: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._decomp_update import *\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/special/__init__.py:640: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._ufuncs import *\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/special/_ellip_harm.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._ellip_harm_2 import _ellipsoid, _ellipsoid_norm\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/interpolate/_bsplines.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _bspl\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/spatial/__init__.py:95: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .ckdtree import *\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/spatial/__init__.py:96: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .qhull import *\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/spatial/_spherical_voronoi.py:18: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _voronoi\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/spatial/distance.py:122: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _hausdorff\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/ndimage/measurements.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _ni_label\n"
     ]
    }
   ],
   "source": [
    "#LM #LANGUAGE MODEL STUFFS\n",
    "#http://abay.tech/blog/2018/04/11/how-to-use-googles-pre-trained-language-model/\n",
    "from lm1b import LoadModel\n",
    "# From lm_1b\n",
    "import language_model.lm_1b.data_utils as data_utils\n",
    "import pickle as pkl\n",
    "from six.moves       import xrange\n",
    "from google.protobuf import text_format\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recovering Graph language_model/data/graph-2016-09-10.pbtxt\n"
     ]
    }
   ],
   "source": [
    "# File Paths\n",
    "vocab_file = \"language_model/data/vocab-2016-09-10.txt\"\n",
    "save_dir   = \"language_model/output\"\n",
    "pbtxt      = \"language_model/data/graph-2016-09-10.pbtxt\"\n",
    "ckpt       = \"language_model/data/ckpt-*\"\n",
    "\n",
    "sess2, t,tgd = LoadModel(pbtxt, ckpt)\n",
    "\n",
    "# For saving demo resources, use batch size 1 and step 1.\n",
    "BATCH_SIZE = 1\n",
    "NUM_TIMESTEPS = 1\n",
    "MAX_WORD_LEN = 50\n",
    "\n",
    "#Vocabulary containing character-level information.\n",
    "vocab = data_utils.CharsVocabulary(vocab_file, MAX_WORD_LEN)\n",
    "\n",
    "targets  = np.zeros([BATCH_SIZE, NUM_TIMESTEPS], np.int32)\n",
    "weights  = np.ones([BATCH_SIZE, NUM_TIMESTEPS], np.float32)\n",
    "inputs   = np.zeros([BATCH_SIZE, NUM_TIMESTEPS], np.int32)\n",
    "char_ids_inputs = np.zeros([BATCH_SIZE, NUM_TIMESTEPS, vocab.max_word_length], np.int32)\n",
    "\n",
    "# Recovers the model from protobuf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def forward(sentence):\n",
    "    sess2.run(t['states_init'])\n",
    "    \n",
    "    if sentence.find('<S>') != 0:\n",
    "        sentence = '<S> ' + sentence\n",
    "\n",
    "    char_ids = [vocab.word_to_char_ids(w) for w in sentence.split()]\n",
    "    #print len(char_ids)\n",
    "    for i in xrange(len(char_ids)):\n",
    "        char_ids_inputs[0, 0, :] = char_ids[i]\n",
    "        lstm_emb = sess2.run(t['lstm/lstm_1/control_dependency'],\n",
    "                        feed_dict={t['char_inputs_in']: char_ids_inputs,\n",
    "                                  })\n",
    "    return lstm_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSenTargetBatch(batchSample):\n",
    "    senEmbSet=np.array([forward(' '.join(i[1])) for i in tqdm(batchSample)])\n",
    "    return senEmbSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./captions/token_train.pkl') as f:\n",
    "    trainCaptions=pkl.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49246/49246 [9:50:23<00:00,  1.39it/s]  \n"
     ]
    }
   ],
   "source": [
    "yp=getSenTargetBatch(trainCaptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
