{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from sklearn import preprocessing as pre\n",
    "#from pathos.pools import ProcessPool as Pool\n",
    "tf.set_random_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "#import xmlrpclib\n",
    "\n",
    "#s = xmlrpclib.ServerProxy('http://10.21.230.64:8778')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some hypers\n",
    "GO='<START>'\n",
    "STOP='<END>'\n",
    "pad='<PAD>'\n",
    "unknown='<UNKNOWN>'\n",
    "BATCH=32\n",
    "BEAM_WIDTH=5\n",
    "EPOCHS=10\n",
    "LAM=0.9\n",
    "embedding_size=256\n",
    "lstm_units=512\n",
    "dropout_keep_prob=0.8\n",
    "PATIENCE=50\n",
    "PATIENCE_MONITOR=False\n",
    "GLOVE=False #if true embedding size will reset to 300\n",
    "CONSTGLOVE=False\n",
    "MAX_LEN=33\n",
    "#new\n",
    "\n",
    "SIN=True\n",
    "NUM_BLOCKS=6\n",
    "NUM_HEADS = 8\n",
    "FEAT_DIM=2048\n",
    "NUM_UNITS= 256\n",
    "FRAMES=28\n",
    "LR=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile):\n",
    "    print \"Loading Glove Model\"\n",
    "    f = open(gloveFile,'r')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print \"Done.\",len(model),\" words loaded!\"\n",
    "    return model\n",
    "if GLOVE:\n",
    "    embedding_size=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "with open('./captions/token_train.pkl') as f:\n",
    "    trainCaptions=pkl.load(f)\n",
    "with open('./captions/token_dev.pkl') as f:\n",
    "    devCaptions=pkl.load(f)\n",
    "with open('./captions/token_test.pkl') as f:\n",
    "    testCaptions=pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processToken(caps):\n",
    "    nk=[]\n",
    "    \n",
    "    for i in caps:\n",
    "        t=[GO]+list(i[1])+[STOP]\n",
    "        empty=33-len(t)\n",
    "        \n",
    "        #t=t+[pad]*empty\n",
    "        nk.append([i[0],t])\n",
    "    return nk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainCaptions=processToken(trainCaptions)\n",
    "devCaptions=processToken(devCaptions)\n",
    "testCaptions=processToken(testCaptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listofwords(data):\n",
    "    '''takes a list of sentences nd returns vocab'''\n",
    "    a=[]\n",
    "    for i in data:\n",
    "        for j in i[1]:\n",
    "            if j not in a:\n",
    "                a.append(j)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the vocab and size\n",
    "trainVocab=listofwords(trainCaptions+devCaptions)\n",
    "trainVocabSize=len(trainVocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find cap len\n",
    "trainCapLen=[len(i[1]) for i in trainCaptions]\n",
    "devCapLen=[len(i[1]) for i in devCaptions]\n",
    "testCapLen=[len(i[1]) for i in testCaptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoder for output transform\n",
    "pre_op=pre.LabelEncoder()\n",
    "pre_op.fit(trainVocab)\n",
    "onehoter=np.identity(len(pre_op.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word to int\n",
    "trainSeq=[pre_op.transform(i[1]) for i in trainCaptions]\n",
    "devSeq=[pre_op.transform(i[1]) for i in devCaptions]\n",
    "trainID=[i[0] for i in trainCaptions]\n",
    "devID=[i[0] for i in devCaptions]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#word to int with pool\n",
    "p=Pool(8)\n",
    "\n",
    "\n",
    "trainSeq=p.map(pre_op.transform,[i[1] for i in trainCaptions])\n",
    "devSeq=p.map(pre_op.transform,[i[1] for i in devCaptions])\n",
    "trainID=[i[0] for i in trainCaptions]\n",
    "devID=[i[0] for i in devCaptions]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appending stops\n",
    "\n",
    "\n",
    "trainSeqReg=[np.pad(i,(0,MAX_LEN-len(i)),'constant',constant_values=pre_op.transform([STOP])) for i in trainSeq]\n",
    "devSeqReg=[np.pad(i,(0,MAX_LEN-len(i)),'constant',constant_values=pre_op.transform([STOP])) for i in devSeq]\n",
    "trainSeqReg=np.array(trainSeqReg)\n",
    "devSeqReg=np.array(devSeqReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading video features\n",
    "videoFeats=np.load(file='./features/consilidated_feats.npy')\n",
    "videoFeatSize=np.array([len(i) for i in videoFeats])\n",
    "#making the shape regular\n",
    "videoFeats=np.array([np.pad(i,mode='constant',pad_width=[(0,28-len(i)),(0,0)]) for i in videoFeats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glove\n",
    "if GLOVE:\n",
    "    gloveModel=loadGloveModel('./glove/glove.6B.300d.txt')\n",
    "    gloveEmbedding=[]\n",
    "    for i in pre_op.classes_:\n",
    "        if gloveModel.has_key(i):\n",
    "            gloveEmbedding.append(gloveModel[i])\n",
    "        else:\n",
    "            gloveEmbedding.append(np.random.normal(size=(300)))\n",
    "    gloveEmbedding=np.array(gloveEmbedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets build the graph\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummys\n",
    "is_training=tf.placeholder(dtype='bool')\n",
    "enc_ph = tf.placeholder(tf.float32,(BATCH,FRAMES,2048))\n",
    "y_ph = tf.placeholder('int32',(BATCH,MAX_LEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"encoder\"):\n",
    "    \n",
    "    key_masks = tf.expand_dims(tf.sign(tf.reduce_sum(tf.abs(enc_ph), axis=-1)), -1)\n",
    "## Positional Encoding\n",
    "    if SIN:\n",
    "        enc = enc_ph+positional_encoding_e(enc_ph,\n",
    "                          num_units=FEAT_DIM, \n",
    "                          zero_pad=False, \n",
    "                          scale=False,\n",
    "                          scope=\"enc_pe\")\n",
    "    else:\n",
    "        enc = enc_ph + embedding(tf.tile(tf.expand_dims(tf.range(tf.shape(enc_ph)[1]), 0), [tf.shape(enc_ph)[0], 1]),\n",
    "                          vocab_size=MAX_LEN, \n",
    "                          num_units=FEAT_DIM, \n",
    "                          zero_pad=False, \n",
    "                          scale=False,\n",
    "                          scope=\"enc_pe\")\n",
    "\n",
    "\n",
    "\n",
    "    enc *= key_masks\n",
    "\n",
    "\n",
    "    ## Dropout\n",
    "    enc = tf.layers.dropout(enc, \n",
    "                                rate=1-dropout_keep_prob, \n",
    "                                training=tf.convert_to_tensor(is_training))\n",
    "\n",
    "    ## Blocks\n",
    "    for i in range(NUM_BLOCKS):\n",
    "        with tf.variable_scope(\"num_blocks_{}\".format(i)):\n",
    "            ### Multihead Attention\n",
    "            enc = multihead_attention(queries=enc, \n",
    "                                            keys=enc, \n",
    "                                            num_units=FEAT_DIM, \n",
    "                                            num_heads=NUM_HEADS, \n",
    "                                            dropout_rate=1-dropout_keep_prob,\n",
    "                                            is_training=is_training,\n",
    "                                            causality=False)\n",
    "\n",
    "            ### Feed Forward\n",
    "            enc = feedforward(enc, num_units=[4*FEAT_DIM, FEAT_DIM])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-21-ee340f771370>:61: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "WARNING:tensorflow:From <ipython-input-21-ee340f771370>:68: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"decoder\"):\n",
    "    ## Embedding\n",
    "    y = tf.concat((tf.ones_like(y_ph[:, :1])*2, y_ph[:, :-1]), -1)\n",
    "    dec = embedding(y, \n",
    "                          vocab_size=trainVocabSize, \n",
    "                          num_units=embedding_size,\n",
    "                          scale=True, \n",
    "                          scope=\"dec_embed\")\n",
    "    \n",
    "    key_masks = tf.expand_dims(tf.sign(tf.reduce_sum(tf.abs(dec), axis=-1)), -1)\n",
    "\n",
    "    ## Positional Encoding\n",
    "    if SIN:\n",
    "        dec += positional_encoding(y,\n",
    "                          num_units=embedding_size, \n",
    "                          zero_pad=False, \n",
    "                          scale=False,\n",
    "                          scope=\"dec_pe\")\n",
    "    else:\n",
    "        dec += embedding(tf.tile(tf.expand_dims(tf.range(tf.shape(y)[1]), 0), [tf.shape(y)[0], 1]),\n",
    "                          vocab_size=trainVocabSize, \n",
    "                          num_units=embedding_size, \n",
    "                          zero_pad=False, \n",
    "                          scale=False,\n",
    "                          scope=\"dec_pe\")\n",
    "    dec *= key_masks\n",
    "    \n",
    "    ## Dropout\n",
    "    dec = tf.layers.dropout(dec, \n",
    "                                rate=1-dropout_keep_prob, \n",
    "                                training=tf.convert_to_tensor(is_training))\n",
    "\n",
    "    ## Blocks\n",
    "    for i in range(NUM_BLOCKS):\n",
    "        with tf.variable_scope(\"num_blocks_{}\".format(i)):\n",
    "            ## Multihead Attention ( self-attention)\n",
    "            dec = multihead_attention(queries=dec, \n",
    "                                            keys=dec, \n",
    "                                            num_units=NUM_UNITS, \n",
    "                                            num_heads=NUM_HEADS, \n",
    "                                            dropout_rate=1-dropout_keep_prob,\n",
    "                                            is_training=is_training,\n",
    "                                            causality=True, \n",
    "                                            scope=\"self_attention\")\n",
    "\n",
    "            ## Multihead Attention ( vanilla attention)\n",
    "            dec = multihead_attention(queries=dec, \n",
    "                                            keys=enc, \n",
    "                                            num_units=NUM_UNITS, \n",
    "                                            num_heads=NUM_HEADS,\n",
    "                                            dropout_rate=1-dropout_keep_prob,\n",
    "                                            is_training=is_training, \n",
    "                                            causality=False,\n",
    "                                            scope=\"vanilla_attention\")\n",
    "\n",
    "            ## Feed Forward\n",
    "            dec = feedforward(dec, num_units=[4*NUM_UNITS, NUM_UNITS])\n",
    "\n",
    "# Final linear projection\n",
    "logits = tf.layers.dense(dec, trainVocabSize)\n",
    "preds = tf.to_int32(tf.arg_max(logits, dimension=-1))\n",
    "istarget = tf.to_float(tf.not_equal(y, 0))\n",
    "acc = tf.reduce_sum(tf.to_float(tf.equal(preds, y))*istarget)/ (tf.reduce_sum(istarget))\n",
    "tf.summary.scalar('acc', acc)\n",
    "\n",
    "# Loss\n",
    "y_smoothed = label_smoothing(tf.one_hot(y, depth=trainVocabSize))\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_smoothed)\n",
    "mean_loss = tf.reduce_sum(loss*istarget) / (tf.reduce_sum(istarget))\n",
    "\n",
    "# Training Scheme\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=LR, beta1=0.9, beta2=0.98, epsilon=1e-8)\n",
    "train_op = optimizer.minimize(mean_loss, global_step=global_step)\n",
    "\n",
    "# Summary \n",
    "tf.summary.scalar('mean_loss', mean_loss)\n",
    "merged = tf.summary.merge_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes training batch\n",
    "\n",
    "SenEmb=np.squeeze(np.load('./LmEmb.npy'))\n",
    "\n",
    "def getTrainBatch(indexs):\n",
    "    sourceBatch=np.array([videoFeats[trainID[i]] for i in indexs])\n",
    "    targetBatch=np.array([trainSeqReg[i] for i in indexs])\n",
    "    sourceBatchLen=np.array([videoFeatSize[trainID[i]] for i in indexs])\n",
    "    targetBatchLen=np.array([trainCapLen[i] for i in indexs])\n",
    "    targetSenEm=np.array([SenEmb[i] for i in indexs])\n",
    "    return sourceBatch,targetBatch,sourceBatchLen,targetBatchLen,targetSenEm\n",
    "\n",
    "#makes dev batch\n",
    "def getDevBatch(indexs):\n",
    "    sourceBatch=np.array([videoFeats[devID[i]] for i in indexs])\n",
    "    targetBatch=np.array([devSeqReg[i] for i in indexs])\n",
    "    sourceBatchLen=np.array([videoFeatSize[devID[i]] for i in indexs])\n",
    "    targetBatchLen=np.array([devCapLen[i] for i in indexs])\n",
    "    return sourceBatch,targetBatch,sourceBatchLen,targetBatchLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training starts here\n",
    "bestVal=0\n",
    "patience=PATIENCE\n",
    "\n",
    "print 'starting training'\n",
    "training_losses=[]\n",
    "valid_losses=[]\n",
    "valid_bleu=[]\n",
    "tData=np.arange(len(trainSeqReg))\n",
    "dData=np.arange(len(devSeqReg))\n",
    "for j in range(EPOCHS):\n",
    "    np.random.shuffle(tData) #makes them iid\n",
    "    training_loss=0\n",
    "    for i in range(len(trainSeqReg)/BATCH):\n",
    "        start=i*BATCH\n",
    "        stop=(i+1)*BATCH\n",
    "        sourceBatch,targetBatch,sourceBatchLen,targetBatchLen,senTargetBatch=getTrainBatch(tData[start:stop])\n",
    "        \n",
    "        \n",
    "        _,lost=sess.run([train_op,mean_loss],feed_dict={enc_ph:sourceBatch,y_ph:targetBatch,is_training:True\n",
    "                                                })\n",
    "        \n",
    "        training_loss+=lost\n",
    "        #print lost,\n",
    "    #calculate t_loss\n",
    "    training_losses.append(training_loss/len(trainSeqReg))\n",
    "    \n",
    "    #calculate v_loss\n",
    "    #disabled\n",
    "    '''validation_loss=0\n",
    "    for k in range(len(devSeqReg)/BATCH):\n",
    "        start=k*BATCH\n",
    "        stop=(k+1)*BATCH\n",
    "        sourceBatch,targetBatch,sourceBatchLen,targetBatchLen=getDevBatch(dData[start:stop])\n",
    "        lost=sess.run(total_loss,feed_dict={source_seq:sourceBatch,\n",
    "                                                target_seq:targetBatch,\n",
    "                                              source_seq_len:sourceBatchLen,\n",
    "                                                target_seq_len:t_newlen[start:stop],\n",
    "                                                real_target_seq_len:targetBatchLen,\n",
    "                                                no_start_target_seq:np.array(targetBatch)[:,1:],\n",
    "                                                batch_size:BATCH,keep_prob:1.0\n",
    "                                                })\n",
    "        validation_loss += lost\n",
    "    \n",
    "    valBleu=calValBleu()\n",
    "    valid_bleu.append(valBleu[1])\n",
    "    #valid_losses.append(validation_loss/len(devSeqReg))\n",
    "    \n",
    "    if(valid_bleu[-1]>bestVal) and PATIENCE_MONITOR==True:\n",
    "        bestVal=valid_bleu[-1]\n",
    "        saver.save(sess, \"model/bestModel.ckpt\")\n",
    "        print \"saving model best\"\n",
    "        patience=PATIENCE\n",
    "    '''\n",
    "    print \"Epoch:%d training loss:%.4f: valid loss:%.4f valid bleu:%.4f\"% (j,training_losses[-1],0.0,0.0)#valid_bleu[-1])\n",
    "    patience-=1\n",
    "    if patience==0 and PATIENCE_MONITOR==True:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1']\n",
      "['100' '100' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1']\n",
      "['100' '100' '100' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1']\n",
      "['100' '100' '100' '100' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1']\n",
      "['100' '100' '100' '100' '100' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1']\n",
      "['100' '100' '100' '100' '100' '100' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '100' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '100' '100' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '100' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '100' '100' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '100' '100' '100' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '100' '100' '100' '100' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '100' '100' '100' '100' '100' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '100' '100' '100' '100' '100' '100' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '100' '100' '100' '100' '100' '100' '100' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '1' '1' '1' '1' '1' '1' '1' '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '1' '1' '1' '1' '1' '1' '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '100' '1' '1' '1' '1' '1' '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '100' '100' '1' '1' '1' '1' '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '100' '100' '100' '1' '1' '1' '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '100' '100' '100' '100' '1' '1' '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '100' '100' '100' '100' '100' '1' '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '100' '100' '100' '100' '100' '100' '1']\n",
      "['100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100' '100'\n",
      " '100' '100' '100' '100' '100' '100' '100' '100' '100']\n"
     ]
    }
   ],
   "source": [
    "preds = np.zeros((BATCH, MAX_LEN), np.int32)\n",
    "for j in range(MAX_LEN):\n",
    "    _preds = sess.run(logits, {enc_ph: sourceBatch,y_ph: preds, is_training:False})\n",
    "    _preds = np.argmax(_preds,axis=-1)\n",
    "    preds[:, j] = _preds[:, j]\n",
    "    print pre_op.inverse_transform(preds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['100', '100', '100', '100', '100', '100', '100', '100', '100',\n",
       "       '100', '100', '100', '100', '100', '100', '100', '100', '100',\n",
       "       '100', '100', '100', '100', '100', '100', '100', '100', '100',\n",
       "       '100', '100', '100', '100', '100', '100'], dtype='|S31')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_op.inverse_transform(preds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets build the graph\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_seq = tf.placeholder(shape=(None,28,2048),dtype=tf.float32)\n",
    "target_seq = tf.placeholder(shape=(None,33),dtype=tf.int32)\n",
    "source_seq_len = tf.placeholder(shape=(None,), dtype=tf.int32)\n",
    "target_seq_len = tf.placeholder(shape=(None,), dtype=tf.int32)\n",
    "no_start_target_seq = tf.placeholder(shape=(None,32),dtype=tf.int32)\n",
    "batch_size = tf.placeholder(shape=(None),dtype=tf.int32)\n",
    "real_target_seq_len= tf.placeholder(shape=(None,), dtype=tf.int32)\n",
    "keep_prob= tf.placeholder(dtype=tf.float32)\n",
    "end_sentence_emb= tf.placeholder(shape=(None,1024),dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output embeddings\n",
    "if GLOVE:\n",
    "    if not CONSTGLOVE:\n",
    "        embedding_matrix_decode = tf.Variable(initial_value=gloveEmbedding,\n",
    "        name=\"embedding_matrix_de\",\n",
    "        expected_shape=[trainVocabSize, embedding_size],\n",
    "        dtype=tf.float32)\n",
    "    else:\n",
    "        embedding_matrix_decode = tf.constant(value=gloveEmbedding,\n",
    "        name=\"embedding_matrix_de\",\n",
    "        shape=[trainVocabSize, embedding_size],\n",
    "        dtype=tf.float32)\n",
    "        print 'const glove enabled'\n",
    "else:\n",
    "    embedding_matrix_decode = tf.get_variable(\n",
    "    name=\"embedding_matrix_de\",\n",
    "    shape=[trainVocabSize, embedding_size],\n",
    "    dtype=tf.float32)\n",
    "decoder_input_embedded = tf.nn.embedding_lookup(embedding_matrix_decode, target_seq) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#output embeddings\n",
    "embedding_matrix_decode = tf.Variable(initial_value=tf.random_normal(shape=[trainVocabSize, embedding_size],dtype=tf.float32))\n",
    "decoder_input_embedded = tf.nn.embedding_lookup(embedding_matrix_decode, target_seq) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder\n",
    "encoderCell=tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.BasicLSTMCell(lstm_units),input_keep_prob=keep_prob,\n",
    "                                          output_keep_prob=keep_prob)\n",
    "encoder_outputs,encoder_final_state=tf.nn.dynamic_rnn(cell=encoderCell,inputs=source_seq,sequence_length=source_seq_len,\n",
    "                 dtype=tf.float32)\n",
    "\n",
    "#expri\n",
    "#encoder_outputs_tiled=tf.contrib.seq2seq.tile_batch(encoder_outputs,multiplier=BEAM_WIDTH)\n",
    "#encoder ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#exp\n",
    "tiled_encoder_outputs = tf.contrib.seq2seq.tile_batch(\n",
    "    encoder_outputs, multiplier=BEAM_WIDTH)\n",
    "tiled_encoder_final_state = tf.contrib.seq2seq.tile_batch(\n",
    "    encoder_final_state, multiplier=BEAM_WIDTH)\n",
    "tiled_sequence_length = tf.contrib.seq2seq.tile_batch(\n",
    "    source_seq_len, multiplier=BEAM_WIDTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#exp\n",
    "attention_mechanism = tf.contrib.seq2seq.LuongAttention(lstm_units,encoder_outputs,memory_sequence_length=tiled_sequence_length)\n",
    "attention_cell = tf.contrib.seq2seq.AttentionWrapper(tf.contrib.rnn.LSTMCell(lstm_units), attention_mechanism,attention_layer_size=lstm_units)\n",
    "decoder_initial_state = attention_cell.zero_state(\n",
    "    dtype=tf.float32, batch_size=BATCH * BEAM_WIDTH)\n",
    "decoder_initial_state = decoder_initial_state.clone(\n",
    "    cell_state=tiled_encoder_final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attention\n",
    "with tf.variable_scope(\"myScope\"):\n",
    "    attention_mechanism_train = tf.contrib.seq2seq.LuongAttention(lstm_units,encoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attention\n",
    "#expri\n",
    "with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "    tiled_encoder_outputs = tf.contrib.seq2seq.tile_batch(\n",
    "        encoder_outputs, multiplier=BEAM_WIDTH)\n",
    "\n",
    "    attention_mechanism_infer = tf.contrib.seq2seq.LuongAttention(lstm_units,tiled_encoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Projection layer and decoder cell\n",
    "with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "    output_layer = tf.layers.Dense(trainVocabSize)\n",
    "\n",
    "    decoder_cell=tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.BasicLSTMCell(lstm_units),input_keep_prob=keep_prob,\n",
    "                                          output_keep_prob=keep_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_initial_state=encoder_final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder Attention wrapper\n",
    "#expri\n",
    "with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "    decoder_cell_train = tf.contrib.seq2seq.AttentionWrapper(\n",
    "            decoder_cell, attention_mechanism_train,\n",
    "            attention_layer_size=lstm_units,alignment_history=False)\n",
    "    decoder_initial_state_train = decoder_cell_train.zero_state(BATCH, tf.float32).clone(cell_state=decoder_initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training helper and decoder\n",
    "with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "    helper = tf.contrib.seq2seq.TrainingHelper(decoder_input_embedded,target_seq_len)\n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell_train, helper, initial_state=decoder_initial_state_train,output_layer=output_layer)#,output_layer=projection_layer)\n",
    "    outputs, state, seq_len = tf.contrib.seq2seq.dynamic_decode(decoder)\n",
    "    logits = outputs.rnn_output\n",
    "    sample_ids = outputs.sample_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cheap trick\n",
    "emd_copy=tf.Variable(tf.zeros(shape=embedding_matrix_decode.shape))\n",
    "emd_copier=emd_copy.assign(embedding_matrix_decode)\n",
    "mask58=np.ones(shape=emd_copier.shape)\n",
    "mask58[58]=0\n",
    "mask58=tf.constant(mask58,dtype=tf.float32)\n",
    "emd58=emd_copier*mask58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding sentence embeddings\n",
    "sentence_ids=outputs.sample_id\n",
    "decoder_output_embedded=tf.nn.embedding_lookup(emd58,sentence_ids)\n",
    "maskMeter=seq_len\n",
    "sentence_embedding=tf.reduce_mean(decoder_output_embedded,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_embedding=tf.concat([decoder_initial_state.c,decoder_initial_state.h],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Inference helper(greedy) and decoder\n",
    "helper2 = tf.contrib.seq2seq.GreedyEmbeddingHelper(embedding_matrix_decode,tf.fill([batch_size],\n",
    "                                                    np.int32(pre_op.transform([GO])[0])),\n",
    "                                                   np.int32(pre_op.transform([STOP])[0]))\n",
    "\n",
    "\n",
    "decoder2 = tf.contrib.seq2seq.BasicDecoder(decoder_cell, helper2, decoder_initial_state,output_layer=output_layer)#,output_layer=projection_layer)\n",
    "\n",
    "outputs, state, seq_len = tf.contrib.seq2seq.dynamic_decode(decoder2,maximum_iterations=32+10)\n",
    "\n",
    "translations_logits = outputs.rnn_output\n",
    "trs=outputs.sample_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expri\n",
    "#decoder Attention wrapper\n",
    "with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "    decoder_cell_infer = tf.contrib.seq2seq.AttentionWrapper(\n",
    "            decoder_cell, attention_mechanism_infer,\n",
    "            attention_layer_size=lstm_units,alignment_history=False)\n",
    "    decoder_initial_state_infer = decoder_cell_infer.zero_state(BATCH, tf.float32).clone(cell_state=decoder_initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Beam Search decoder\n",
    "with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "    decoder_initial_state_tiled = tf.contrib.seq2seq.tile_batch(\n",
    "        decoder_initial_state_infer[0], multiplier=BEAM_WIDTH)\n",
    "\n",
    "    decoder_initial_state_tiled=decoder_cell_infer.zero_state(batch_size=BATCH*BEAM_WIDTH,dtype=tf.float32).clone(cell_state=decoder_initial_state_tiled)\n",
    "\n",
    "\n",
    "    # Define a beam-search decoder\n",
    "    decoder3 = tf.contrib.seq2seq.BeamSearchDecoder(\n",
    "            cell=decoder_cell_infer,\n",
    "            embedding=embedding_matrix_decode,\n",
    "            start_tokens=tf.fill([batch_size],np.int32(pre_op.transform([GO])[0])),\n",
    "            end_token=np.int32(pre_op.transform([STOP])[0]),\n",
    "            initial_state=decoder_initial_state_tiled,\n",
    "            beam_width=BEAM_WIDTH,\n",
    "            output_layer=output_layer,\n",
    "            length_penalty_weight=0.0)\n",
    "    outputs, state, seq_len = tf.contrib.seq2seq.dynamic_decode(decoder3,maximum_iterations=32+10)\n",
    "\n",
    "\n",
    "    trs_beam=outputs.predicted_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jointEmb=tf.concat([sentence_embedding,end_sentence_emb],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss and optimizer\n",
    "\n",
    "#loss1\n",
    "cross_entropy=tf.nn.sparse_softmax_cross_entropy_with_logits(labels=no_start_target_seq,logits=logits)\n",
    "\n",
    "target_weights = tf.sequence_mask(real_target_seq_len, target_seq_len[0], dtype=logits.dtype)\n",
    "\n",
    "loss1=tf.reduce_sum(cross_entropy*target_weights)\n",
    "\n",
    "#loss2\n",
    "sentence_on_video_space=end_sentence_emb#tf.layers.dense(inputs=jointEmb,units=2*lstm_units)\n",
    "\n",
    "loss2=tf.reduce_sum(tf.nn.l2_loss(sentence_on_video_space- video_embedding))\n",
    "\n",
    "total_loss = LAM * loss1 + (1-LAM) *loss2\n",
    "train = tf.train.AdamOptimizer().minimize(total_loss)\n",
    "\n",
    "#gradient clipping stackoverflow\n",
    "'''\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "gradients, variables = zip(*optimizer.compute_gradients(total_loss))\n",
    "gradients, _ = tf.clip_by_global_norm(gradients, 10.0)\n",
    "train = optimizer.apply_gradients(zip(gradients, variables))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont touch\n",
    "maxtlen=max(trainCapLen)\n",
    "maxvlen=max(devCapLen)\n",
    "t_newlen=[maxtlen-1 for i in range(len(trainCapLen))]\n",
    "v_newlen=[maxtlen-1 for i in range(len(devCapLen))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver=tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SenEmb=np.squeeze(np.load('./LmEmb.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(SenEmb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes training batch\n",
    "\n",
    "\n",
    "\n",
    "def getTrainBatch(indexs):\n",
    "    sourceBatch=np.array([videoFeats[trainID[i]] for i in indexs])\n",
    "    targetBatch=np.array([trainSeqReg[i] for i in indexs])\n",
    "    sourceBatchLen=np.array([videoFeatSize[trainID[i]] for i in indexs])\n",
    "    targetBatchLen=np.array([trainCapLen[i] for i in indexs])\n",
    "    targetSenEm=np.array([SenEmb[i] for i in indexs])\n",
    "    return sourceBatch,targetBatch,sourceBatchLen,targetBatchLen,targetSenEm\n",
    "\n",
    "#makes dev batch\n",
    "def getDevBatch(indexs):\n",
    "    sourceBatch=np.array([videoFeats[devID[i]] for i in indexs])\n",
    "    targetBatch=np.array([devSeqReg[i] for i in indexs])\n",
    "    sourceBatchLen=np.array([videoFeatSize[devID[i]] for i in indexs])\n",
    "    targetBatchLen=np.array([devCapLen[i] for i in indexs])\n",
    "    return sourceBatch,targetBatch,sourceBatchLen,targetBatchLen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#restore model\n",
    "saver.restore(sess, \"BestModel/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calValBleu():\n",
    "    data=videoFeats[1200:1300]\n",
    "    data_len=videoFeatSize[1200:1300]\n",
    "    if BATCH>100:\n",
    "        data=np.concatenate([data,videoFeats[:BATCH-100]])\n",
    "        data_len=np.concatenate([data_len,videoFeatSize[:BATCH-100]])\n",
    "    gen_sum=[]\n",
    "    for i in range(len(data)/BATCH):\n",
    "        start=i*BATCH\n",
    "        stop=(i+1)*BATCH\n",
    "\n",
    "        load_trs=trs_beam\n",
    "        y=sess.run(load_trs,feed_dict={source_seq:data[start:stop],\n",
    "                                                   source_seq_len:data_len[start:stop],\n",
    "                                                  batch_size:BATCH,keep_prob:1.0\n",
    "                                                    })\n",
    "        y=y[:,:,0]\n",
    "\n",
    "        for t in y:\n",
    "            gen_sum.append(t)\n",
    "\n",
    "    if BATCH<100:        \n",
    "        start=len(data)-BATCH\n",
    "        stop=len(data)\n",
    "        y=sess.run(trs_beam,feed_dict={source_seq:data[start:stop],\n",
    "                                                       source_seq_len:data_len[start:stop],\n",
    "                                                      batch_size:BATCH,keep_prob:1.0\n",
    "                                                        })\n",
    "        y=y[:,:,0]\n",
    "\n",
    "        y=y[-(len(data)-len(gen_sum)):]\n",
    "        for t in y:\n",
    "            gen_sum.append(t)\n",
    "    \n",
    "    gen_sum=gen_sum[:100]\n",
    "    #processing summaries\n",
    "    summs=[]\n",
    "    for i in gen_sum:\n",
    "        summ=''\n",
    "        for j in i:\n",
    "\n",
    "            if j!=58:\n",
    "                summ = summ+' '+pre_op.inverse_transform(j)\n",
    "        summs.append(summ[1:])\n",
    "    vdo=1200\n",
    "    with open('gen_dev.txt','w+') as fle:\n",
    "        for i in summs:\n",
    "            fle.write('beam_size_5'+'\\tvid'+str(vdo)+'\\t'+i)\n",
    "            fle.write('\\n')\n",
    "            vdo+=1\n",
    "    with open('gen_dev.txt','r') as fle:\n",
    "        pred=fle.read()\n",
    "    return s.calcScore(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training starts here\n",
    "bestVal=0\n",
    "patience=PATIENCE\n",
    "\n",
    "print 'starting training'\n",
    "training_losses=[]\n",
    "valid_losses=[]\n",
    "valid_bleu=[]\n",
    "tData=np.arange(len(trainSeqReg))\n",
    "dData=np.arange(len(devSeqReg))\n",
    "for j in range(EPOCHS):\n",
    "    np.random.shuffle(tData) #makes them iid\n",
    "    training_loss=0\n",
    "    for i in range(len(trainSeqReg)/BATCH):\n",
    "        start=i*BATCH\n",
    "        stop=(i+1)*BATCH\n",
    "        sourceBatch,targetBatch,sourceBatchLen,targetBatchLen,senTargetBatch=getTrainBatch(tData[start:stop])\n",
    "        \n",
    "        \n",
    "        _,lost=sess.run([train,total_loss],feed_dict={source_seq:sourceBatch,\n",
    "                                                target_seq:targetBatch,\n",
    "                                              source_seq_len:sourceBatchLen,\n",
    "                                                target_seq_len:t_newlen[start:stop],\n",
    "                                                real_target_seq_len:targetBatchLen,\n",
    "                                                no_start_target_seq:np.array(targetBatch)[:,1:],\n",
    "                                                batch_size:BATCH,keep_prob:dropout_keep_prob,\n",
    "                                                end_sentence_emb:senTargetBatch\n",
    "                                                })\n",
    "        \n",
    "        training_loss+=lost\n",
    "        #print lost,\n",
    "    #calculate t_loss\n",
    "    training_losses.append(training_loss/len(trainSeqReg))\n",
    "    \n",
    "    #calculate v_loss\n",
    "    #disabled\n",
    "    '''validation_loss=0\n",
    "    for k in range(len(devSeqReg)/BATCH):\n",
    "        start=k*BATCH\n",
    "        stop=(k+1)*BATCH\n",
    "        sourceBatch,targetBatch,sourceBatchLen,targetBatchLen=getDevBatch(dData[start:stop])\n",
    "        lost=sess.run(total_loss,feed_dict={source_seq:sourceBatch,\n",
    "                                                target_seq:targetBatch,\n",
    "                                              source_seq_len:sourceBatchLen,\n",
    "                                                target_seq_len:t_newlen[start:stop],\n",
    "                                                real_target_seq_len:targetBatchLen,\n",
    "                                                no_start_target_seq:np.array(targetBatch)[:,1:],\n",
    "                                                batch_size:BATCH,keep_prob:1.0\n",
    "                                                })\n",
    "        validation_loss += lost\n",
    "    '''\n",
    "    valBleu=calValBleu()\n",
    "    valid_bleu.append(valBleu[1])\n",
    "    #valid_losses.append(validation_loss/len(devSeqReg))\n",
    "    \n",
    "    if(valid_bleu[-1]>bestVal) and PATIENCE_MONITOR==True:\n",
    "        bestVal=valid_bleu[-1]\n",
    "        saver.save(sess, \"model/bestModel.ckpt\")\n",
    "        print \"saving model best\"\n",
    "        patience=PATIENCE\n",
    "    print \"Epoch:%d training loss:%.4f: valid loss:%.4f valid bleu:%.4f\"% (j,training_losses[-1],0.0,valid_bleu[-1])\n",
    "    patience-=1\n",
    "    if patience==0 and PATIENCE_MONITOR==True:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "saver.save(sess, \"BestLM-new/best.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PATIENCE_MONITOR:\n",
    "    saver.restore(sess, \"model/bestModel.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=videoFeats[1300:]\n",
    "data_len=videoFeatSize[1300:]\n",
    "if BATCH==1024:\n",
    "    data=np.concatenate([data,data[:354]])\n",
    "    data_len=np.concatenate([data_len,data_len[:354]])\n",
    "gen_sum=[]\n",
    "for i in range(len(data)/BATCH):\n",
    "    start=i*BATCH\n",
    "    stop=(i+1)*BATCH\n",
    "    \n",
    "    load_trs=trs_beam\n",
    "    y=sess.run(load_trs,feed_dict={source_seq:data[start:stop],\n",
    "                                               source_seq_len:data_len[start:stop],\n",
    "                                              batch_size:BATCH,keep_prob:1.0\n",
    "                                                })\n",
    "    y=y[:,:,0]\n",
    "    \n",
    "    for t in y:\n",
    "        gen_sum.append(t)\n",
    "\n",
    "if BATCH<1024:        \n",
    "    start=len(data)-BATCH\n",
    "    stop=len(data)\n",
    "    y=sess.run(trs_beam,feed_dict={source_seq:data[start:stop],\n",
    "                                                   source_seq_len:data_len[start:stop],\n",
    "                                                  batch_size:BATCH,keep_prob:1.0\n",
    "                                                    })\n",
    "    y=y[:,:,0]\n",
    "\n",
    "    y=y[-(len(data)-len(gen_sum)):]\n",
    "    for t in y:\n",
    "        gen_sum.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_sum=gen_sum[:670]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data=videoFeats[1300:1364]\n",
    "data_len=videoFeatSize[1300:1364]\n",
    "gen_sum=[]\n",
    "for i in range(len(data)/BATCH):\n",
    "    start=i*BATCH\n",
    "    stop=(i+1)*BATCH\n",
    "    load_trs=trs\n",
    "    y=sess.run(load_trs,feed_dict={source_seq:data[start:stop],\n",
    "                                               source_seq_len:data_len[start:stop],\n",
    "                                              batch_size:BATCH,\n",
    "                                                keep_prob:1.0\n",
    "                                                })\n",
    "    for t in y:\n",
    "        gen_sum.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing summaries\n",
    "summs=[]\n",
    "for i in gen_sum:\n",
    "    summ=''\n",
    "    for j in i:\n",
    "        \n",
    "        if j!=58:\n",
    "            summ = summ+' '+pre_op.inverse_transform(j)\n",
    "    summs.append(summ[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(len(summs)):\n",
    "    print i,summs[i],vops[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vops=np.load('../MSVD/clip_index/testIndex.npy')[:64]\n",
    "ref_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#real shit\n",
    "with open('ref_dev.txt','w+') as fle:\n",
    "    for i in devCaptions:\n",
    "        fle.write('vid'+str(i[0])+'\\t'+' '.join(i[1][1:-1]))\n",
    "        fle.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdo=1300\n",
    "with open('gen.txt','w+') as fle:\n",
    "    for i in summs:\n",
    "        fle.write('beam_size_5'+'\\tvid'+str(vdo)+'\\t'+i)\n",
    "        fle.write('\\n')\n",
    "        vdo+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gen_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
