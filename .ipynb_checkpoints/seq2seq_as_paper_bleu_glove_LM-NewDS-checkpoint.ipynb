{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from sklearn import preprocessing as pre\n",
    "#from pathos.pools import ProcessPool as Pool\n",
    "tf.set_random_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "#import xmlrpclib\n",
    "NEWDS=1\n",
    "#s = xmlrpclib.ServerProxy('http://10.21.230.64:8778')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some hypers\n",
    "GO='<START>'\n",
    "STOP='<END>'\n",
    "PAD='<PAD>'\n",
    "UNKNOWN='<UNKNOWN>'\n",
    "BATCH=1024\n",
    "BEAM_WIDTH=5\n",
    "EPOCHS=100\n",
    "LAM=0.9\n",
    "embedding_size=256\n",
    "lstm_units=512\n",
    "dropout_keep_prob=0.5\n",
    "PATIENCE=50\n",
    "PATIENCE_MONITOR=True\n",
    "GLOVE=False #if true embedding size will reset to 300\n",
    "CONSTGLOVE=False\n",
    "MAX_LEN=33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile):\n",
    "    print \"Loading Glove Model\"\n",
    "    f = open(gloveFile,'r')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print \"Done.\",len(model),\" words loaded!\"\n",
    "    return model\n",
    "if GLOVE:\n",
    "    embedding_size=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "with open('./crt_split/token_train.pkl') as f:\n",
    "    trainCaptions=pkl.load(f)\n",
    "with open('./crt_split/token_dev.pkl') as f:\n",
    "    devCaptions=pkl.load(f)\n",
    "with open('./crt_split/token_test.pkl') as f:\n",
    "    testCaptions=pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processToken(caps):\n",
    "    nk=[]\n",
    "    \n",
    "    for i in caps:\n",
    "        t=[GO]+list(i[1])+[STOP]\n",
    "        empty=33-len(t)\n",
    "        \n",
    "        #t=t+[pad]*empty\n",
    "        nk.append([i[0],t])\n",
    "    return nk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainCaptions=processToken(trainCaptions)\n",
    "devCaptions=processToken(devCaptions)\n",
    "testCaptions=processToken(testCaptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listofwords(data):\n",
    "    '''takes a list of sentences nd returns vocab'''\n",
    "    a=[]\n",
    "    for i in data:\n",
    "        for j in i[1]:\n",
    "            if j not in a:\n",
    "                a.append(j)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the vocab and size\n",
    "trainVocab=listofwords(trainCaptions+devCaptions)\n",
    "trainVocabSize=len(trainVocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find cap len\n",
    "trainCapLen=[len(i[1]) for i in trainCaptions]\n",
    "devCapLen=[len(i[1]) for i in devCaptions]\n",
    "testCapLen=[len(i[1]) for i in testCaptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoder for output transform\n",
    "pre_op=pre.LabelEncoder()\n",
    "pre_op.fit(trainVocab+[PAD])\n",
    "onehoter=np.identity(len(pre_op.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word to int\n",
    "trainSeq=[pre_op.transform(i[1]) for i in trainCaptions]\n",
    "devSeq=[pre_op.transform(i[1]) for i in devCaptions]\n",
    "trainID=[i[0] for i in trainCaptions]\n",
    "devID=[i[0] for i in devCaptions]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#word to int with pool\n",
    "p=Pool(8)\n",
    "\n",
    "\n",
    "trainSeq=p.map(pre_op.transform,[i[1] for i in trainCaptions])\n",
    "devSeq=p.map(pre_op.transform,[i[1] for i in devCaptions])\n",
    "trainID=[i[0] for i in trainCaptions]\n",
    "devID=[i[0] for i in devCaptions]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appending stops\n",
    "\n",
    "\n",
    "trainSeqReg=[np.pad(i,(0,MAX_LEN-len(i)),'constant',constant_values=pre_op.transform([PAD])) for i in trainSeq]\n",
    "devSeqReg=[np.pad(i,(0,MAX_LEN-len(i)),'constant',constant_values=pre_op.transform([PAD])) for i in devSeq]\n",
    "trainSeqReg=np.array(trainSeqReg)\n",
    "devSeqReg=np.array(devSeqReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading video features\n",
    "videoFeats=np.load(file='./crt_split/consilidated_feats.npy')\n",
    "videoFeatSize=np.array([len(i) for i in videoFeats])\n",
    "#making the shape regular\n",
    "videoFeats=np.array([np.pad(i,mode='constant',pad_width=[(0,28-len(i)),(0,0)]) for i in videoFeats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glove\n",
    "if GLOVE:\n",
    "    gloveModel=loadGloveModel('./glove/glove.6B.300d.txt')\n",
    "    gloveEmbedding=[]\n",
    "    for i in pre_op.classes_:\n",
    "        if gloveModel.has_key(i):\n",
    "            gloveEmbedding.append(gloveModel[i])\n",
    "        else:\n",
    "            gloveEmbedding.append(np.random.normal(size=(300)))\n",
    "    gloveEmbedding=np.array(gloveEmbedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets build the graph\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_seq = tf.placeholder(shape=(None,28,2048),dtype=tf.float32)\n",
    "target_seq = tf.placeholder(shape=(None,33),dtype=tf.int32)\n",
    "source_seq_len = tf.placeholder(shape=(None,), dtype=tf.int32)\n",
    "target_seq_len = tf.placeholder(shape=(None,), dtype=tf.int32)\n",
    "no_start_target_seq = tf.placeholder(shape=(None,32),dtype=tf.int32)\n",
    "batch_size = tf.placeholder(shape=(None),dtype=tf.int32)\n",
    "real_target_seq_len= tf.placeholder(shape=(None,), dtype=tf.int32)\n",
    "keep_prob= tf.placeholder(dtype=tf.float32)\n",
    "end_sentence_emb= tf.placeholder(shape=(None,1024),dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output embeddings\n",
    "if GLOVE:\n",
    "    if not CONSTGLOVE:\n",
    "        embedding_matrix_decode = tf.Variable(initial_value=gloveEmbedding,\n",
    "        name=\"embedding_matrix_de\",\n",
    "        expected_shape=[trainVocabSize, embedding_size],\n",
    "        dtype=tf.float32)\n",
    "    else:\n",
    "        embedding_matrix_decode = tf.constant(value=gloveEmbedding,\n",
    "        name=\"embedding_matrix_de\",\n",
    "        shape=[trainVocabSize, embedding_size],\n",
    "        dtype=tf.float32)\n",
    "        print 'const glove enabled'\n",
    "else:\n",
    "    embedding_matrix_decode = tf.get_variable(\n",
    "    name=\"embedding_matrix_de\",\n",
    "    shape=[trainVocabSize, embedding_size],\n",
    "    dtype=tf.float32)\n",
    "decoder_input_embedded = tf.nn.embedding_lookup(embedding_matrix_decode, target_seq) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#output embeddings\n",
    "embedding_matrix_decode = tf.Variable(initial_value=tf.random_normal(shape=[trainVocabSize, embedding_size],dtype=tf.float32))\n",
    "decoder_input_embedded = tf.nn.embedding_lookup(embedding_matrix_decode, target_seq) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder\n",
    "encoderCell=tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.BasicLSTMCell(lstm_units),input_keep_prob=keep_prob,\n",
    "                                          output_keep_prob=keep_prob)\n",
    "encoder_outputs,encoder_final_state=tf.nn.dynamic_rnn(cell=encoderCell,inputs=source_seq,sequence_length=source_seq_len,\n",
    "                 dtype=tf.float32)\n",
    "\n",
    "#expri\n",
    "#encoder_outputs_tiled=tf.contrib.seq2seq.tile_batch(encoder_outputs,multiplier=BEAM_WIDTH)\n",
    "#encoder ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 512) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_4:0' shape=(?, 512) dtype=float32>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#exp\n",
    "tiled_encoder_outputs = tf.contrib.seq2seq.tile_batch(\n",
    "    encoder_outputs, multiplier=BEAM_WIDTH)\n",
    "tiled_encoder_final_state = tf.contrib.seq2seq.tile_batch(\n",
    "    encoder_final_state, multiplier=BEAM_WIDTH)\n",
    "tiled_sequence_length = tf.contrib.seq2seq.tile_batch(\n",
    "    source_seq_len, multiplier=BEAM_WIDTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#exp\n",
    "attention_mechanism = tf.contrib.seq2seq.LuongAttention(lstm_units,encoder_outputs,memory_sequence_length=tiled_sequence_length)\n",
    "attention_cell = tf.contrib.seq2seq.AttentionWrapper(tf.contrib.rnn.LSTMCell(lstm_units), attention_mechanism,attention_layer_size=lstm_units)\n",
    "decoder_initial_state = attention_cell.zero_state(\n",
    "    dtype=tf.float32, batch_size=BATCH * BEAM_WIDTH)\n",
    "decoder_initial_state = decoder_initial_state.clone(\n",
    "    cell_state=tiled_encoder_final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attention\n",
    "with tf.variable_scope(\"myScope\"):\n",
    "    attention_mechanism_train = tf.contrib.seq2seq.LuongAttention(lstm_units,encoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attention\n",
    "#expri\n",
    "with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "    tiled_encoder_outputs = tf.contrib.seq2seq.tile_batch(\n",
    "        encoder_outputs, multiplier=BEAM_WIDTH)\n",
    "\n",
    "    attention_mechanism_infer = tf.contrib.seq2seq.LuongAttention(lstm_units,tiled_encoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'myScope_1/tile_batch/Reshape:0' shape=(?, 28, 512) dtype=float32>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiled_encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Projection layer and decoder cell\n",
    "with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "    output_layer = tf.layers.Dense(trainVocabSize)\n",
    "\n",
    "    decoder_cell=tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.BasicLSTMCell(lstm_units),input_keep_prob=keep_prob,\n",
    "                                          output_keep_prob=keep_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_initial_state=encoder_final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder Attention wrapper\n",
    "#expri\n",
    "with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "    decoder_cell_train = tf.contrib.seq2seq.AttentionWrapper(\n",
    "            decoder_cell, attention_mechanism_train,\n",
    "            attention_layer_size=lstm_units,alignment_history=False)\n",
    "    decoder_initial_state_train = decoder_cell_train.zero_state(BATCH, tf.float32).clone(cell_state=decoder_initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training helper and decoder\n",
    "with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "    helper = tf.contrib.seq2seq.TrainingHelper(decoder_input_embedded,target_seq_len)\n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell_train, helper, initial_state=decoder_initial_state_train,output_layer=output_layer)#,output_layer=projection_layer)\n",
    "    outputs, state, seq_len = tf.contrib.seq2seq.dynamic_decode(decoder)\n",
    "    logits = outputs.rnn_output\n",
    "    sample_ids = outputs.sample_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cheap trick\n",
    "emd_copy=tf.Variable(tf.zeros(shape=embedding_matrix_decode.shape))\n",
    "emd_copier=emd_copy.assign(embedding_matrix_decode)\n",
    "mask58=np.ones(shape=emd_copier.shape)\n",
    "mask58[58]=0\n",
    "mask58=tf.constant(mask58,dtype=tf.float32)\n",
    "emd58=emd_copier*mask58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding sentence embeddings\n",
    "sentence_ids=outputs.sample_id\n",
    "decoder_output_embedded=tf.nn.embedding_lookup(emd58,sentence_ids)\n",
    "maskMeter=seq_len\n",
    "sentence_embedding=tf.reduce_mean(decoder_output_embedded,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_embedding=tf.concat([decoder_initial_state.c,decoder_initial_state.h],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Inference helper(greedy) and decoder\n",
    "helper2 = tf.contrib.seq2seq.GreedyEmbeddingHelper(embedding_matrix_decode,tf.fill([batch_size],\n",
    "                                                    np.int32(pre_op.transform([GO])[0])),\n",
    "                                                   np.int32(pre_op.transform([STOP])[0]))\n",
    "\n",
    "\n",
    "decoder2 = tf.contrib.seq2seq.BasicDecoder(decoder_cell, helper2, decoder_initial_state,output_layer=output_layer)#,output_layer=projection_layer)\n",
    "\n",
    "outputs, state, seq_len = tf.contrib.seq2seq.dynamic_decode(decoder2,maximum_iterations=32+10)\n",
    "\n",
    "translations_logits = outputs.rnn_output\n",
    "trs=outputs.sample_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expri\n",
    "#decoder Attention wrapper\n",
    "with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "    decoder_cell_infer = tf.contrib.seq2seq.AttentionWrapper(\n",
    "            decoder_cell, attention_mechanism_infer,\n",
    "            attention_layer_size=lstm_units,alignment_history=False)\n",
    "    decoder_initial_state_infer = decoder_cell_infer.zero_state(BATCH, tf.float32).clone(cell_state=decoder_initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Beam Search decoder\n",
    "with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "    decoder_initial_state_tiled = tf.contrib.seq2seq.tile_batch(\n",
    "        decoder_initial_state_infer[0], multiplier=BEAM_WIDTH)\n",
    "\n",
    "    decoder_initial_state_tiled=decoder_cell_infer.zero_state(batch_size=BATCH*BEAM_WIDTH,dtype=tf.float32).clone(cell_state=decoder_initial_state_tiled)\n",
    "\n",
    "\n",
    "    # Define a beam-search decoder\n",
    "    decoder3 = tf.contrib.seq2seq.BeamSearchDecoder(\n",
    "            cell=decoder_cell_infer,\n",
    "            embedding=embedding_matrix_decode,\n",
    "            start_tokens=tf.fill([batch_size],np.int32(pre_op.transform([GO])[0])),\n",
    "            end_token=np.int32(pre_op.transform([STOP])[0]),\n",
    "            initial_state=decoder_initial_state_tiled,\n",
    "            beam_width=BEAM_WIDTH,\n",
    "            output_layer=output_layer,\n",
    "            length_penalty_weight=0.0)\n",
    "    outputs, state, seq_len = tf.contrib.seq2seq.dynamic_decode(decoder3,maximum_iterations=32+10)\n",
    "\n",
    "\n",
    "    trs_beam=outputs.predicted_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "jointEmb=tf.concat([sentence_embedding,end_sentence_emb],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "padID=pre_op.transform([PAD])[0]\n",
    "startID=pre_op.transform([GO])[0]\n",
    "stopID=pre_op.transform([STOP])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\noptimizer = tf.train.AdamOptimizer()\\ngradients, variables = zip(*optimizer.compute_gradients(total_loss))\\ngradients, _ = tf.clip_by_global_norm(gradients, 10.0)\\ntrain = optimizer.apply_gradients(zip(gradients, variables))\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loss and optimizer\n",
    "\n",
    "#loss1\n",
    "\n",
    "y_ = label_smoothing(tf.one_hot(no_start_target_seq, depth=trainVocabSize))\n",
    "ce = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y_)\n",
    "nonpadding = tf.to_float(tf.not_equal(no_start_target_seq,padID ))  # 0: <pad>\n",
    "loss1 = tf.reduce_sum(ce * nonpadding) / (tf.reduce_sum(nonpadding) + 1e-7)\n",
    "'''\n",
    "\n",
    "cross_entropy=tf.nn.sparse_softmax_cross_entropy_with_logits(labels=no_start_target_seq,logits=logits)\n",
    "\n",
    "target_weights = tf.sequence_mask(real_target_seq_len, target_seq_len[0], dtype=logits.dtype)\n",
    "\n",
    "loss1=tf.reduce_sum(cross_entropy*target_weights)\n",
    "'''\n",
    "#loss2\n",
    "sentence_on_video_space=end_sentence_emb#tf.layers.dense(inputs=jointEmb,units=2*lstm_units)\n",
    "\n",
    "loss2=tf.reduce_sum(tf.nn.l2_loss(sentence_on_video_space- video_embedding))\n",
    "\n",
    "total_loss = LAM * loss1 + (1-LAM) *loss2\n",
    "\n",
    "train = tf.train.AdamOptimizer().minimize(total_loss)\n",
    "\n",
    "#gradient clipping stackoverflow\n",
    "'''\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "gradients, variables = zip(*optimizer.compute_gradients(total_loss))\n",
    "gradients, _ = tf.clip_by_global_norm(gradients, 10.0)\n",
    "train = optimizer.apply_gradients(zip(gradients, variables))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont touch\n",
    "maxtlen=max(trainCapLen)\n",
    "maxvlen=max(devCapLen)\n",
    "t_newlen=[maxtlen-1 for i in range(len(trainCapLen))]\n",
    "v_newlen=[maxtlen-1 for i in range(len(devCapLen))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver=tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "SenEmb=np.squeeze(np.load('./crt_split/LMemb.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes training batch\n",
    "\n",
    "\n",
    "def getTrainBatch(indexs):\n",
    "    sourceBatch=np.array([videoFeats[trainID[i]-NEWDS] for i in indexs])\n",
    "    targetBatch=np.array([trainSeqReg[i] for i in indexs])\n",
    "    sourceBatchLen=np.array([videoFeatSize[trainID[i]-NEWDS] for i in indexs])\n",
    "    targetBatchLen=np.array([trainCapLen[i] for i in indexs])\n",
    "    targetSenEm=np.array([SenEmb[i] for i in indexs])\n",
    "    return sourceBatch,targetBatch,sourceBatchLen,targetBatchLen,targetSenEm\n",
    "\n",
    "#makes dev batch\n",
    "def getDevBatch(indexs):\n",
    "    sourceBatch=np.array([videoFeats[devID[i]-NEWDS] for i in indexs])\n",
    "    targetBatch=np.array([devSeqReg[i] for i in indexs])\n",
    "    sourceBatchLen=np.array([videoFeatSize[devID[i]-NEWDS] for i in indexs])\n",
    "    targetBatchLen=np.array([devCapLen[i] for i in indexs])\n",
    "    return sourceBatch,targetBatch,sourceBatchLen,targetBatchLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "def calBleu(ref,cap):\n",
    "    score_4 = corpus_bleu(ref,cap,weights=(0.25,0.25,0.25,0.25))\n",
    "    return score_4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#restore model\n",
    "saver.restore(sess, \"BestModel/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calValBleu():\n",
    "    data=videoFeats[1200:1300]\n",
    "    data_len=videoFeatSize[1200:1300]\n",
    "    if BATCH>100:\n",
    "        data=np.concatenate([data,videoFeats[:BATCH-100]])\n",
    "        data_len=np.concatenate([data_len,videoFeatSize[:BATCH-100]])\n",
    "    gen_sum=[]\n",
    "    for i in range(len(data)/BATCH):\n",
    "        start=i*BATCH\n",
    "        stop=(i+1)*BATCH\n",
    "\n",
    "        \n",
    "        y=sess.run(trs_beam,feed_dict={source_seq:data[start:stop],\n",
    "                                                   source_seq_len:data_len[start:stop],\n",
    "                                                  batch_size:BATCH,keep_prob:1.0\n",
    "                                                    })\n",
    "        \n",
    "        y=y[:,:,0]\n",
    "        for t in y:\n",
    "            gen_sum.append(t)\n",
    "\n",
    "    if BATCH<100:        \n",
    "        start=len(data)-BATCH\n",
    "        stop=len(data)\n",
    "        y=sess.run(trs_beam,feed_dict={source_seq:data[start:stop],\n",
    "                                                   source_seq_len:data_len[start:stop],\n",
    "                                                  batch_size:BATCH,keep_prob:1.0\n",
    "                                                    })\n",
    "        \n",
    "        y=y[:,:,0]\n",
    "        y=y[-(len(data)-len(gen_sum)):]\n",
    "        for t in y:\n",
    "            gen_sum.append(t)\n",
    "    \n",
    "    gen_sum=gen_sum[:100]\n",
    "    \n",
    "    #print gen_sum.shape\n",
    "    #processing summaries\n",
    "    summs=[]\n",
    "    for i in gen_sum:\n",
    "        summ=''\n",
    "        for j in i:\n",
    "            if j==stopID:\n",
    "                break\n",
    "            summ = summ+' '+pre_op.inverse_transform(j)\n",
    "        summs.append(summ[1:])\n",
    "    \n",
    "    \n",
    "    ref=[]\n",
    "    for i in range(100):\n",
    "        ref.append([])\n",
    "    for i in devCaptions:\n",
    "        ref[i[0]-1200-NEWDS].append(i[1][1:-1])\n",
    "\n",
    "    cap=[]\n",
    "    for i in summs:\n",
    "        cap.append(i.split())\n",
    "\n",
    "    score=calBleu(ref,cap)\n",
    "    \n",
    "    #print cap\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n",
      "saving model best\n",
      "Epoch:0 training loss:9.0931: valid loss:0.0000 valid bleu:0.0000\n",
      "saving model best\n",
      "Epoch:1 training loss:7.8219: valid loss:0.0000 valid bleu:0.4221\n",
      "Epoch:2 training loss:7.5292: valid loss:0.0000 valid bleu:0.4118\n",
      "Epoch:3 training loss:7.3135: valid loss:0.0000 valid bleu:0.3236\n",
      "Epoch:4 training loss:7.1601: valid loss:0.0000 valid bleu:0.2973\n",
      "Epoch:5 training loss:7.0657: valid loss:0.0000 valid bleu:0.3887\n",
      "Epoch:6 training loss:6.9921: valid loss:0.0000 valid bleu:0.3709\n",
      "saving model best\n",
      "Epoch:7 training loss:6.9241: valid loss:0.0000 valid bleu:0.4619\n",
      "Epoch:8 training loss:6.8625: valid loss:0.0000 valid bleu:0.4233\n",
      "Epoch:9 training loss:6.8156: valid loss:0.0000 valid bleu:0.4089\n",
      "Epoch:10 training loss:6.7842: valid loss:0.0000 valid bleu:0.4595\n",
      "Epoch:11 training loss:6.7570: valid loss:0.0000 valid bleu:0.4466\n",
      "saving model best\n",
      "Epoch:12 training loss:6.7290: valid loss:0.0000 valid bleu:0.5179\n",
      "Epoch:13 training loss:6.6995: valid loss:0.0000 valid bleu:0.4806\n",
      "Epoch:14 training loss:6.6816: valid loss:0.0000 valid bleu:0.5045\n",
      "Epoch:15 training loss:6.6573: valid loss:0.0000 valid bleu:0.4827\n",
      "Epoch:16 training loss:6.6417: valid loss:0.0000 valid bleu:0.4624\n",
      "Epoch:17 training loss:6.6266: valid loss:0.0000 valid bleu:0.4317\n",
      "Epoch:18 training loss:6.6091: valid loss:0.0000 valid bleu:0.4685\n",
      "Epoch:19 training loss:6.5974: valid loss:0.0000 valid bleu:0.4781\n",
      "Epoch:20 training loss:6.5876: valid loss:0.0000 valid bleu:0.5011\n",
      "Epoch:21 training loss:6.5776: valid loss:0.0000 valid bleu:0.4632\n",
      "Epoch:22 training loss:6.5633: valid loss:0.0000 valid bleu:0.4419\n",
      "Epoch:23 training loss:6.5521: valid loss:0.0000 valid bleu:0.4612\n",
      "Epoch:24 training loss:6.5521: valid loss:0.0000 valid bleu:0.4400\n",
      "saving model best\n",
      "Epoch:25 training loss:6.5407: valid loss:0.0000 valid bleu:0.5270\n",
      "saving model best\n",
      "Epoch:26 training loss:6.5306: valid loss:0.0000 valid bleu:0.5376\n",
      "Epoch:27 training loss:6.5231: valid loss:0.0000 valid bleu:0.4900\n",
      "Epoch:28 training loss:6.5130: valid loss:0.0000 valid bleu:0.5037\n",
      "Epoch:29 training loss:6.5117: valid loss:0.0000 valid bleu:0.4714\n",
      "Epoch:30 training loss:6.5099: valid loss:0.0000 valid bleu:0.4643\n",
      "Epoch:31 training loss:6.4900: valid loss:0.0000 valid bleu:0.4934\n",
      "Epoch:32 training loss:6.4824: valid loss:0.0000 valid bleu:0.4705\n",
      "Epoch:33 training loss:6.4717: valid loss:0.0000 valid bleu:0.5336\n",
      "Epoch:34 training loss:6.4685: valid loss:0.0000 valid bleu:0.5172\n",
      "saving model best\n",
      "Epoch:35 training loss:6.4568: valid loss:0.0000 valid bleu:0.5462\n",
      "Epoch:36 training loss:6.4497: valid loss:0.0000 valid bleu:0.4712\n",
      "Epoch:37 training loss:6.4468: valid loss:0.0000 valid bleu:0.5246\n",
      "Epoch:38 training loss:6.4450: valid loss:0.0000 valid bleu:0.5332\n",
      "Epoch:39 training loss:6.4393: valid loss:0.0000 valid bleu:0.4804\n",
      "Epoch:40 training loss:6.4324: valid loss:0.0000 valid bleu:0.5334\n",
      "Epoch:41 training loss:6.4266: valid loss:0.0000 valid bleu:0.5097\n",
      "Epoch:42 training loss:6.4182: valid loss:0.0000 valid bleu:0.5093\n",
      "Epoch:43 training loss:6.4176: valid loss:0.0000 valid bleu:0.5170\n",
      "Epoch:44 training loss:6.4135: valid loss:0.0000 valid bleu:0.4836\n",
      "Epoch:45 training loss:6.4091: valid loss:0.0000 valid bleu:0.4893\n",
      "Epoch:46 training loss:6.4038: valid loss:0.0000 valid bleu:0.4851\n",
      "Epoch:47 training loss:6.3990: valid loss:0.0000 valid bleu:0.4890\n",
      "Epoch:48 training loss:6.4035: valid loss:0.0000 valid bleu:0.4941\n",
      "Epoch:49 training loss:6.3928: valid loss:0.0000 valid bleu:0.4835\n",
      "Epoch:50 training loss:6.3832: valid loss:0.0000 valid bleu:0.4877\n",
      "Epoch:51 training loss:6.3801: valid loss:0.0000 valid bleu:0.5057\n",
      "Epoch:52 training loss:6.3814: valid loss:0.0000 valid bleu:0.4934\n",
      "Epoch:53 training loss:6.3769: valid loss:0.0000 valid bleu:0.4706\n",
      "Epoch:54 training loss:6.3702: valid loss:0.0000 valid bleu:0.5244\n",
      "Epoch:55 training loss:6.3658: valid loss:0.0000 valid bleu:0.4881\n",
      "Epoch:56 training loss:6.3585: valid loss:0.0000 valid bleu:0.4557\n",
      "Epoch:57 training loss:6.3567: valid loss:0.0000 valid bleu:0.4554\n",
      "Epoch:58 training loss:6.3543: valid loss:0.0000 valid bleu:0.5169\n",
      "Epoch:59 training loss:6.3532: valid loss:0.0000 valid bleu:0.5154\n",
      "Epoch:60 training loss:6.3506: valid loss:0.0000 valid bleu:0.5101\n",
      "Epoch:61 training loss:6.3433: valid loss:0.0000 valid bleu:0.5012\n",
      "Epoch:62 training loss:6.3354: valid loss:0.0000 valid bleu:0.4925\n",
      "Epoch:63 training loss:6.3389: valid loss:0.0000 valid bleu:0.4737\n",
      "Epoch:64 training loss:6.3334: valid loss:0.0000 valid bleu:0.5384\n",
      "Epoch:65 training loss:6.3295: valid loss:0.0000 valid bleu:0.4913\n",
      "Epoch:66 training loss:6.3287: valid loss:0.0000 valid bleu:0.4696\n",
      "Epoch:67 training loss:6.3247: valid loss:0.0000 valid bleu:0.5019\n",
      "Epoch:68 training loss:6.3217: valid loss:0.0000 valid bleu:0.4653\n",
      "Epoch:69 training loss:6.3207: valid loss:0.0000 valid bleu:0.5226\n",
      "Epoch:70 training loss:6.3183: valid loss:0.0000 valid bleu:0.5043\n",
      "Epoch:71 training loss:6.3144: valid loss:0.0000 valid bleu:0.4912\n",
      "Epoch:72 training loss:6.3134: valid loss:0.0000 valid bleu:0.5025\n",
      "Epoch:73 training loss:6.3068: valid loss:0.0000 valid bleu:0.4828\n",
      "Epoch:74 training loss:6.3039: valid loss:0.0000 valid bleu:0.4994\n",
      "Epoch:75 training loss:6.3003: valid loss:0.0000 valid bleu:0.4880\n",
      "Epoch:76 training loss:6.2979: valid loss:0.0000 valid bleu:0.4867\n",
      "Epoch:77 training loss:6.2920: valid loss:0.0000 valid bleu:0.4821\n",
      "Epoch:78 training loss:6.2860: valid loss:0.0000 valid bleu:0.4997\n",
      "Epoch:79 training loss:6.2863: valid loss:0.0000 valid bleu:0.5384\n",
      "Epoch:80 training loss:6.2811: valid loss:0.0000 valid bleu:0.5165\n",
      "Epoch:81 training loss:6.2802: valid loss:0.0000 valid bleu:0.4834\n",
      "Epoch:82 training loss:6.2763: valid loss:0.0000 valid bleu:0.4820\n",
      "Epoch:83 training loss:6.2774: valid loss:0.0000 valid bleu:0.5234\n",
      "Epoch:84 training loss:6.2788: valid loss:0.0000 valid bleu:0.5150\n"
     ]
    }
   ],
   "source": [
    "#training starts here\n",
    "bestVal=0\n",
    "patience=PATIENCE\n",
    "\n",
    "print 'starting training'\n",
    "training_losses=[]\n",
    "valid_losses=[]\n",
    "valid_bleu=[]\n",
    "tData=np.arange(len(trainSeqReg))\n",
    "dData=np.arange(len(devSeqReg))\n",
    "for j in range(EPOCHS):\n",
    "    np.random.shuffle(tData) #makes them iid\n",
    "    training_loss=0\n",
    "    for i in range(len(trainSeqReg)/BATCH):\n",
    "        start=i*BATCH\n",
    "        stop=(i+1)*BATCH\n",
    "        sourceBatch,targetBatch,sourceBatchLen,targetBatchLen,senTargetBatch=getTrainBatch(tData[start:stop])\n",
    "        \n",
    "        \n",
    "        _,lost=sess.run([train,total_loss],feed_dict={source_seq:sourceBatch,\n",
    "                                                target_seq:targetBatch,\n",
    "                                              source_seq_len:sourceBatchLen,\n",
    "                                                target_seq_len:t_newlen[start:stop],\n",
    "                                                real_target_seq_len:targetBatchLen,\n",
    "                                                no_start_target_seq:np.array(targetBatch)[:,1:],\n",
    "                                                batch_size:BATCH,keep_prob:dropout_keep_prob,\n",
    "                                                end_sentence_emb:senTargetBatch\n",
    "                                                })\n",
    "        \n",
    "        training_loss+=lost\n",
    "        #print lost,\n",
    "    #calculate t_loss\n",
    "    training_losses.append(training_loss/len(trainSeqReg))\n",
    "    \n",
    "    #calculate v_loss\n",
    "    #disabled\n",
    "    '''validation_loss=0\n",
    "    for k in range(len(devSeqReg)/BATCH):\n",
    "        start=k*BATCH\n",
    "        stop=(k+1)*BATCH\n",
    "        sourceBatch,targetBatch,sourceBatchLen,targetBatchLen=getDevBatch(dData[start:stop])\n",
    "        lost=sess.run(total_loss,feed_dict={source_seq:sourceBatch,\n",
    "                                                target_seq:targetBatch,\n",
    "                                              source_seq_len:sourceBatchLen,\n",
    "                                                target_seq_len:t_newlen[start:stop],\n",
    "                                                real_target_seq_len:targetBatchLen,\n",
    "                                                no_start_target_seq:np.array(targetBatch)[:,1:],\n",
    "                                                batch_size:BATCH,keep_prob:1.0\n",
    "                                                })\n",
    "        validation_loss += lost\n",
    "    '''\n",
    "    valBleu=calValBleu()\n",
    "    valid_bleu.append(valBleu)\n",
    "    #valid_losses.append(validation_loss/len(devSeqReg))\n",
    "    \n",
    "    if(valid_bleu[-1]>bestVal) and PATIENCE_MONITOR==True:\n",
    "        bestVal=valid_bleu[-1]\n",
    "        saver.save(sess, \"LSTM_LM_newset/bestModel.ckpt\")\n",
    "        print \"saving model best\"\n",
    "        patience=PATIENCE\n",
    "    print \"Epoch:%d training loss:%.4f: valid loss:%.4f valid bleu:%.4f\"% (j,training_losses[-1],0.0,valid_bleu[-1])\n",
    "    patience-=1\n",
    "    if patience==0 and PATIENCE_MONITOR==True:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "saver.save(sess, \"LSTM_LM_newset/resume.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from LSTM_LM_newset/bestModel.ckpt\n"
     ]
    }
   ],
   "source": [
    "if PATIENCE_MONITOR:\n",
    "    saver.restore(sess, \"LSTM_LM_newset/bestModel.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=videoFeats[1300:]\n",
    "data_len=videoFeatSize[1300:]\n",
    "if BATCH==1024:\n",
    "    data=np.concatenate([data,data[:354]])\n",
    "    data_len=np.concatenate([data_len,data_len[:354]])\n",
    "gen_sum=[]\n",
    "for i in range(len(data)/BATCH):\n",
    "    start=i*BATCH\n",
    "    stop=(i+1)*BATCH\n",
    "    \n",
    "    load_trs=trs_beam\n",
    "    y=sess.run(trs_beam,feed_dict={source_seq:data[start:stop],\n",
    "                                               source_seq_len:data_len[start:stop],\n",
    "                                              batch_size:BATCH,keep_prob:1.0\n",
    "                                                })\n",
    "    y=y[:,:,0]\n",
    "    \n",
    "    for t in y:\n",
    "        gen_sum.append(t)\n",
    "\n",
    "if BATCH<1024:        \n",
    "    start=len(data)-BATCH\n",
    "    stop=len(data)\n",
    "    y=sess.run(trs_beam,feed_dict={source_seq:data[start:stop],\n",
    "                                                   source_seq_len:data_len[start:stop],\n",
    "                                                  batch_size:BATCH,keep_prob:1.0\n",
    "                                                    })\n",
    "    y=y[:,:,0]\n",
    "\n",
    "    y=y[-(len(data)-len(gen_sum)):]\n",
    "    for t in y:\n",
    "        gen_sum.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_sum=gen_sum[:670]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data=videoFeats[1300:1364]\n",
    "data_len=videoFeatSize[1300:1364]\n",
    "gen_sum=[]\n",
    "for i in range(len(data)/BATCH):\n",
    "    start=i*BATCH\n",
    "    stop=(i+1)*BATCH\n",
    "    load_trs=trs\n",
    "    y=sess.run(load_trs,feed_dict={source_seq:data[start:stop],\n",
    "                                               source_seq_len:data_len[start:stop],\n",
    "                                              batch_size:BATCH,\n",
    "                                                keep_prob:1.0\n",
    "                                                })\n",
    "    for t in y:\n",
    "        gen_sum.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing summaries\n",
    "summs=[]\n",
    "for i in gen_sum:\n",
    "    summ=''\n",
    "    for j in i:\n",
    "        if j==stopID:\n",
    "            break\n",
    "        summ = summ+' '+pre_op.inverse_transform(j)\n",
    "    summs.append(summ[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a man is playing with a dog',\n",
       " 'a man is riding a motorcycle',\n",
       " 'a cat is playing',\n",
       " 'a man is tying his shoes',\n",
       " 'a man is walking',\n",
       " 'a man is sharpening a knife',\n",
       " 'a woman is brushing her fingers',\n",
       " 'a group of people are dancing',\n",
       " 'a woman is dancing',\n",
       " 'a woman is applying lipstick',\n",
       " 'a cat is playing',\n",
       " 'a man is dancing',\n",
       " 'a man is running',\n",
       " 'two men are running',\n",
       " 'a man is riding a motorcycle',\n",
       " 'a man is reading a newspaper',\n",
       " 'a woman is dancing',\n",
       " 'a man is running',\n",
       " 'a man is riding a skateboard',\n",
       " 'a man is dancing',\n",
       " 'a man is playing a guitar',\n",
       " 'a man is slicing a potato',\n",
       " 'a man is playing a guitar',\n",
       " 'a dog is playing',\n",
       " 'a man is driving a car',\n",
       " 'a man is driving a car',\n",
       " 'a polar bear is sliding on the snow',\n",
       " 'a person is mixing ingrediants',\n",
       " 'a dog is running',\n",
       " 'a man is talking',\n",
       " 'a man is opening a door',\n",
       " 'two men are fighting',\n",
       " 'a man opens a door',\n",
       " 'a man is slicing a carrot',\n",
       " 'a monkey is running',\n",
       " 'a polar bear is walking',\n",
       " 'a polar bear is walking',\n",
       " 'a man is playing a guitar',\n",
       " 'a dog is catching a fish',\n",
       " 'a cat is jumping over a wall',\n",
       " 'a man is shooting a gun',\n",
       " 'a man is slicing bread',\n",
       " 'a man is making pizza',\n",
       " 'a man cooking his kichen',\n",
       " 'a man is sitting on the floor',\n",
       " 'a man is driving a car',\n",
       " 'a man is lifting weights',\n",
       " 'a man is playing with a dog',\n",
       " 'a man is cutting a tree',\n",
       " 'a man cooking his kichen',\n",
       " 'a group of people are walking',\n",
       " 'a cat is eating',\n",
       " 'a man is playing a guitar',\n",
       " 'a man is singing',\n",
       " 'a man is riding a horse',\n",
       " 'a man is playing a guitar',\n",
       " 'a man is driving a car',\n",
       " 'a man is running',\n",
       " 'a dog is running',\n",
       " 'a dog is swimming',\n",
       " 'a man is holding a microwave',\n",
       " 'a man is shooting a gun',\n",
       " 'a cat is playing',\n",
       " 'a man is running',\n",
       " 'a woman is dancing',\n",
       " 'a group of people are walking',\n",
       " 'a man is lifting weights',\n",
       " 'a man is smoking',\n",
       " 'a person is playing with a rabbit',\n",
       " 'a man is drinking water',\n",
       " 'a woman is dancing',\n",
       " 'a man is walking',\n",
       " 'a man is dancing',\n",
       " 'a man cooking his kichen',\n",
       " 'a man cooking his kichen',\n",
       " 'a man cooking his kichen',\n",
       " 'a man is pouring water into a pan',\n",
       " 'a man cooking his kichen',\n",
       " 'a man is pouring water into a pan',\n",
       " 'a man cooking his kichen',\n",
       " 'a man is cooking',\n",
       " 'two women are dancing',\n",
       " 'a woman is dancing',\n",
       " 'a woman is washing her hands',\n",
       " 'a woman is dancing',\n",
       " 'a man is running',\n",
       " 'two men are fighting',\n",
       " 'a person is playing a violin',\n",
       " 'a baby is crying',\n",
       " 'a dog is playing with a ball',\n",
       " 'a man cooking his kichen',\n",
       " 'a slow loris is biting a mans hand',\n",
       " 'a man is walking',\n",
       " 'a cat is playing with a toy',\n",
       " 'a man is playing a guitar',\n",
       " 'a man is skating',\n",
       " 'a dog is running',\n",
       " 'a man is dancing',\n",
       " 'a cat is playing',\n",
       " 'a man is playing a guitar',\n",
       " 'a man is riding a horse',\n",
       " 'a man is playing a keyboard',\n",
       " 'two women are fighting',\n",
       " 'a man is running',\n",
       " 'a woman is cooking meat',\n",
       " 'a dog is looking at a bug',\n",
       " 'a cat is licking a lollipop',\n",
       " 'a man is crying',\n",
       " 'a woman is applying lipstick',\n",
       " 'a man is slicing a potato',\n",
       " 'a man is running',\n",
       " 'a man is walking',\n",
       " 'a boy is playing with a ball',\n",
       " 'a monkey is running',\n",
       " 'a man is driving a car',\n",
       " 'a tiger is running',\n",
       " 'a man is running',\n",
       " 'a cat is walking',\n",
       " 'a man is dancing',\n",
       " 'a man is cutting a cucumber',\n",
       " 'a man cooking his kichen',\n",
       " 'a cat is playing',\n",
       " 'a woman is putting on sunglasses',\n",
       " 'a man is running',\n",
       " 'a man is running',\n",
       " 'a man is cutting a cake',\n",
       " 'a man is walking',\n",
       " 'a man is cooking',\n",
       " 'a man is slicing a carrot',\n",
       " 'a man is slicing a carrot',\n",
       " 'a man is cutting a piece of paper',\n",
       " 'a dog is playing',\n",
       " 'a dog is playing',\n",
       " 'a man is playing a piano',\n",
       " 'a man is walking',\n",
       " 'a bear is walking',\n",
       " 'a man is slicing a potato',\n",
       " 'a man is playing with a dog',\n",
       " 'a man is playing a guitar',\n",
       " 'two men are jogging on the beach',\n",
       " 'a man is holding a sunflower',\n",
       " 'a man cooking his kichen',\n",
       " 'a boy is jumping',\n",
       " 'a woman is washing a bowl',\n",
       " 'a man cooking his kichen',\n",
       " 'a group of people are walking',\n",
       " 'a man is riding a skateboard',\n",
       " 'a dog is running',\n",
       " 'a woman is putting on makeup',\n",
       " 'a man is opening a door',\n",
       " 'a man is shooting a gun',\n",
       " 'men are playing football',\n",
       " 'two men are fighting',\n",
       " 'a man is running',\n",
       " 'a man is running',\n",
       " 'a man is running',\n",
       " 'a man jumps off a roof',\n",
       " 'a man cooking his kichen',\n",
       " 'a man is kneading dough',\n",
       " 'a man is playing a guitar',\n",
       " 'a baby is playing with a ball',\n",
       " 'a dog is playing',\n",
       " 'a man is riding a bike',\n",
       " 'a dolphin jumps into the water',\n",
       " 'a band is performing on stage',\n",
       " 'two men are fighting',\n",
       " 'a man is shooting a gun',\n",
       " 'a man is cutting a potato',\n",
       " 'a man cooking his kichen',\n",
       " 'a man is slicing a potato',\n",
       " 'two men are playing chess',\n",
       " 'a man is slicing an onion',\n",
       " 'a baby is playing',\n",
       " 'a man is singing',\n",
       " 'a man is eating',\n",
       " 'a man is running',\n",
       " 'a man is driving a car',\n",
       " 'a woman is cutting meat',\n",
       " 'a woman is peeling shrimp',\n",
       " 'a woman is cutting meat',\n",
       " 'a person is cutting a vegetable',\n",
       " 'a woman is cutting meat',\n",
       " 'a man is slicing a carrot',\n",
       " 'a man is cutting meat',\n",
       " 'a person is mixing flour',\n",
       " 'a man cooking his kichen',\n",
       " 'a man cooking his kichen',\n",
       " 'a man cooking his kichen',\n",
       " 'a man is slicing a carrot',\n",
       " 'a man cooking his kichen',\n",
       " 'a man is slicing a carrot',\n",
       " 'a man cooking his kichen',\n",
       " 'a man is slicing a carrot',\n",
       " 'a man is slicing a vegetable',\n",
       " 'a woman is slicing a carrot',\n",
       " 'a man cooking his kichen',\n",
       " 'a person is cooking',\n",
       " 'a man is slicing a potato',\n",
       " 'a man is slicing a potato',\n",
       " 'a man cooking his kichen',\n",
       " 'a man is dancing',\n",
       " 'a man is playing a guitar',\n",
       " 'a woman is slicing a cucumber',\n",
       " 'a woman is slicing meat',\n",
       " 'a woman is slicing a piece of meat',\n",
       " 'a woman is breading meat',\n",
       " 'a woman is cutting meat',\n",
       " 'a man cooking his kichen',\n",
       " 'a man is riding a motorcycle',\n",
       " 'a woman is pouring ingredients into a bowl',\n",
       " 'a man is pouring water into a container',\n",
       " 'a man is eating',\n",
       " 'a man is eating',\n",
       " 'a man is breaking a flaming board',\n",
       " 'a man is tying a sock',\n",
       " 'a man is playing a guitar',\n",
       " 'a dog is eating',\n",
       " 'a woman is picking up a watering can',\n",
       " 'a man is running',\n",
       " 'a woman is laying on a bed',\n",
       " 'a woman is dancing',\n",
       " 'a man is running',\n",
       " 'a man is running',\n",
       " 'two men are fighting',\n",
       " 'a cat is playing',\n",
       " 'a man is riding a skateboard',\n",
       " 'a man is playing a trumpet',\n",
       " 'a man is playing a guitar',\n",
       " 'a man is dancing',\n",
       " 'a man cooking his kichen',\n",
       " 'a man is running',\n",
       " 'a cat jumps into a wall',\n",
       " 'a man is talking',\n",
       " 'a man is pouring water into a container',\n",
       " 'a man is putting butter into a bag',\n",
       " 'a man is pouring water into a container',\n",
       " 'a man is shooting a gun',\n",
       " 'a man is running',\n",
       " 'two women are dancing',\n",
       " 'a man is walking',\n",
       " 'a boy is riding a skateboard',\n",
       " 'a woman is cutting a sock',\n",
       " 'a man is riding a bike',\n",
       " 'a man is playing a guitar',\n",
       " 'a man is riding a horse',\n",
       " 'a man is cooking',\n",
       " 'a man is slicing a potato',\n",
       " 'a man is slicing a potato',\n",
       " 'a man is slicing a carrot',\n",
       " 'a woman is slicing a carrot',\n",
       " 'a man is slicing a potato',\n",
       " 'a man is slicing a carrot',\n",
       " 'a man is slicing a potato',\n",
       " 'a man is slicing an onion',\n",
       " 'a man is slicing a potato',\n",
       " 'a man is lifting weights',\n",
       " 'a woman is holding a kangaroo',\n",
       " 'a woman is pouring water into a bowl',\n",
       " 'a soccer player scores a goal',\n",
       " 'a dog is playing',\n",
       " 'a man is peeling a potato',\n",
       " 'a man is slicing a potato',\n",
       " 'a dog is playing with a ball',\n",
       " 'two men are fighting',\n",
       " 'a man is walking',\n",
       " 'a man is playing a guitar',\n",
       " 'a woman is riding a horse',\n",
       " 'a man is cooking',\n",
       " 'the person is cutting the something',\n",
       " 'a tiger is walking',\n",
       " 'two women are dancing',\n",
       " 'a man is running',\n",
       " 'a man is riding a motorcycle',\n",
       " 'a man is riding a motorcycle',\n",
       " 'a man is slicing a carrot',\n",
       " 'a man is running',\n",
       " 'a man is drinking water',\n",
       " 'a man is cutting a piece of paper',\n",
       " 'a man is playing a violin',\n",
       " 'a man is playing a guitar',\n",
       " 'a woman is dancing',\n",
       " 'a woman is dancing',\n",
       " 'a man is cutting a vegetable',\n",
       " 'a man is riding a bike',\n",
       " 'a man cooking his kichen',\n",
       " 'a man is holding a fish',\n",
       " 'a woman is holding a baby kitten',\n",
       " 'a man is singing',\n",
       " 'a dog is walking',\n",
       " 'a man is playing a trumpet',\n",
       " 'a man is dancing',\n",
       " 'a man is dancing',\n",
       " 'a cat is playing',\n",
       " 'a kitten is playing with a toy',\n",
       " 'a cat is playing',\n",
       " 'a man cooking his kichen',\n",
       " 'a man is slicing bread',\n",
       " 'a man is cutting meat',\n",
       " 'a man is cutting a piece of bread',\n",
       " 'two men are fighting',\n",
       " 'a man is running',\n",
       " 'a man is skateboarding',\n",
       " 'a man is dancing',\n",
       " 'a woman is sitting on bed',\n",
       " 'a man is slicing a potato',\n",
       " 'a loris is eating',\n",
       " 'a man is cutting a sock',\n",
       " 'a man is riding a bicycle',\n",
       " 'two men are playing football',\n",
       " 'a woman is brushing her hair',\n",
       " 'two women are dancing',\n",
       " 'a woman is riding a motorcycle',\n",
       " 'a man is cutting a sock',\n",
       " 'a man cooking his kichen',\n",
       " 'a man is slicing a potato',\n",
       " 'a woman is slicing a carrot',\n",
       " 'a man cooking his kichen',\n",
       " 'a dog is running',\n",
       " 'a man is riding a horse',\n",
       " 'a man is running',\n",
       " 'a man is lifting a log',\n",
       " 'a man is eating food',\n",
       " 'a man is riding a bike',\n",
       " 'a man is riding a bike',\n",
       " 'a woman is dancing',\n",
       " 'a man is slicing an onion',\n",
       " 'a man is slicing a potato',\n",
       " 'a woman is dancing',\n",
       " 'a man is riding a motorcycle',\n",
       " 'a man is playing a guitar',\n",
       " 'a woman is applying makeup',\n",
       " 'a man is dancing',\n",
       " 'a man is riding a bike',\n",
       " 'a woman is putting on sunglasses',\n",
       " 'people are dancing',\n",
       " 'a man cooking his kichen',\n",
       " 'a man cooking his kichen',\n",
       " 'a man cooking his kichen',\n",
       " 'a woman is dancing',\n",
       " 'a man is running',\n",
       " 'a man is riding a horse',\n",
       " 'a dog is riding a skateboard',\n",
       " 'a man is skiing',\n",
       " 'a man is singing',\n",
       " 'a man is cutting a vegetable',\n",
       " 'a cat is playing',\n",
       " 'a man is driving a car',\n",
       " 'a woman is plucking her eyebrows',\n",
       " 'a woman is feeding a kangaroo',\n",
       " 'a dog is running',\n",
       " 'a man is riding a horse',\n",
       " 'a lemur is sitting on the ground',\n",
       " 'a dog is playing',\n",
       " 'a man is playing with a dog',\n",
       " 'a man is riding a bike',\n",
       " 'a dog is playing with a ball',\n",
       " 'a man is slicing meat',\n",
       " 'a man is singing',\n",
       " 'a man is running',\n",
       " 'two women are dancing',\n",
       " 'a man is riding a skateboard',\n",
       " 'a man is playing with a dog',\n",
       " 'a man is dancing',\n",
       " 'a man is stirring a car',\n",
       " 'a man is peeling a potato',\n",
       " 'a man is peeling a potato',\n",
       " 'a man is slicing a potato',\n",
       " 'a boy is playing',\n",
       " 'a man is playing a piano',\n",
       " 'a man is pouring sauce into a bowl',\n",
       " 'a man is running',\n",
       " 'a man is riding a skateboard',\n",
       " 'a man is playing a flute',\n",
       " 'a cat is playing',\n",
       " 'two women are dancing',\n",
       " 'a man is crying',\n",
       " 'a man is playing with a man',\n",
       " 'a panda is cleaning itself',\n",
       " 'a man is running',\n",
       " 'a woman is brushing her hair',\n",
       " 'a man is talking',\n",
       " 'a man is smoking',\n",
       " 'a baby is laughing',\n",
       " 'a cat is drinking milk',\n",
       " 'a man is smoking',\n",
       " 'a man is dancing',\n",
       " 'a man is skateboarding',\n",
       " 'a dog is running',\n",
       " 'a man is skating',\n",
       " 'a man is stirring a bowl of soup',\n",
       " 'two men are fighting',\n",
       " 'a little girl is dancing',\n",
       " 'a man is running',\n",
       " 'two men are fighting',\n",
       " 'a man cooking his kichen',\n",
       " 'a dog is playing',\n",
       " 'a dog is playing with a dog',\n",
       " 'a cat is playing with a toy',\n",
       " 'a man cooking his kichen',\n",
       " 'a person is mixing ingredients in a bowl',\n",
       " 'a woman is cutting meat',\n",
       " 'a man cooking his kichen',\n",
       " 'a woman is peeling a carrot',\n",
       " 'a man is cutting a vegetable',\n",
       " 'a woman is slicing a carrot',\n",
       " 'a woman is slicing a cucumber',\n",
       " 'a man is running',\n",
       " 'a man is cutting a rope',\n",
       " 'a woman is putting her hair',\n",
       " 'a dog is swimming',\n",
       " 'a man is driving a car',\n",
       " 'a man is lifting a car',\n",
       " 'a monkey is pulling a dead deer',\n",
       " 'a man is eating',\n",
       " 'a slow loris is biting a persons finger',\n",
       " 'a woman is applying lipstick',\n",
       " 'a man is cutting flowers',\n",
       " 'a panda is walking',\n",
       " 'a boy is playing with a rope',\n",
       " 'a man is cutting a vegetable',\n",
       " 'a man is running',\n",
       " 'a man cooking his kichen',\n",
       " 'a man is running',\n",
       " 'a man is dancing',\n",
       " 'a man is running',\n",
       " 'a man is doing exercise',\n",
       " 'a man is running',\n",
       " 'a man is shooting',\n",
       " 'a man is dancing',\n",
       " 'a man is doing exercise',\n",
       " 'a man is riding a bike',\n",
       " 'people are dancing',\n",
       " 'a man is doing karate',\n",
       " 'a man is playing a guitar',\n",
       " 'a man is running',\n",
       " 'two women are eating',\n",
       " 'a man is dancing',\n",
       " 'a man is running',\n",
       " 'two men are playing chess',\n",
       " 'a woman is dancing',\n",
       " 'a man is riding a bike',\n",
       " 'a man is cutting meat',\n",
       " 'a man is cutting some bread',\n",
       " 'a man is playing a piano',\n",
       " 'a man is running',\n",
       " 'a man is slicing a potato',\n",
       " 'a woman is exercising',\n",
       " 'a woman is playing with a dog',\n",
       " 'two men are talking',\n",
       " 'people are fighting',\n",
       " 'a man is peeling a potato',\n",
       " 'a man is slicing a potato',\n",
       " 'a man is driving a car',\n",
       " 'a man is dancing',\n",
       " 'a man is talking on the phone',\n",
       " 'a man is cutting a sock',\n",
       " 'a man is opening a door',\n",
       " 'a man is running',\n",
       " 'a woman is dancing',\n",
       " 'a monkey is running',\n",
       " 'a man is riding a bike',\n",
       " 'a car is running',\n",
       " 'a man is breaking a stick',\n",
       " 'people are dancing',\n",
       " 'a man is slicing a carrot',\n",
       " 'a man is playing with a dog',\n",
       " 'a man is lifting weights',\n",
       " 'a man is singing',\n",
       " 'a man is singing',\n",
       " 'a man is pouring water into a bowl',\n",
       " 'a monkey is running',\n",
       " 'a woman is picking up a watering can',\n",
       " 'a cat is playing',\n",
       " 'a man is walking',\n",
       " 'a man is slicing a potato',\n",
       " 'a man is riding a horse',\n",
       " 'a man is dancing',\n",
       " 'a cat is playing',\n",
       " 'a man is cooking',\n",
       " 'a monkey is pulling a dogs tail',\n",
       " 'a woman is petting a lemur',\n",
       " 'a man is dancing',\n",
       " 'a monkey is catching a fish',\n",
       " 'a man is lifting weights',\n",
       " 'a woman is cutting a sock',\n",
       " 'a man is cooking',\n",
       " 'a man is slicing a carrot',\n",
       " 'a man is playing a guitar',\n",
       " 'a man is eating food',\n",
       " 'a man is playing a guitar',\n",
       " 'two men are fighting',\n",
       " 'a man is riding a bike',\n",
       " 'a cat is playing',\n",
       " 'a man is pouring water into a bowl',\n",
       " 'a woman is exercising',\n",
       " 'a man is playing a guitar',\n",
       " 'a man is cleaning the floor',\n",
       " 'a girl is dancing',\n",
       " 'a cat is playing',\n",
       " 'a man is running',\n",
       " 'a woman is riding a horse',\n",
       " 'a man cooking his kichen',\n",
       " 'a man is holding a gun',\n",
       " 'a man is climbing a rope',\n",
       " 'a man is shooting a gun',\n",
       " 'a man is dancing',\n",
       " 'a monkey is walking',\n",
       " 'a man is driving a car',\n",
       " 'two women are talking',\n",
       " 'a person is peeling a toad',\n",
       " 'a man is riding a motorcycle',\n",
       " 'a man is riding a skateboard',\n",
       " 'a man is driving a car',\n",
       " 'a man is riding a bike',\n",
       " 'a monkey is running',\n",
       " 'a woman is swimming',\n",
       " 'a panda is dancing',\n",
       " 'a bird is eating',\n",
       " 'two men are fighting',\n",
       " 'a man is running',\n",
       " 'a man is walking',\n",
       " 'a cat is playing',\n",
       " 'a man is playing a guitar',\n",
       " 'a man is cutting a piece of bread',\n",
       " 'a cat is playing',\n",
       " 'a man is riding a bike',\n",
       " 'a man cooking his kichen',\n",
       " 'a woman is laying on the bed',\n",
       " 'a man is running',\n",
       " 'a man is riding a bike',\n",
       " 'a woman is riding a horse',\n",
       " 'two men are fighting',\n",
       " 'a group of people are walking',\n",
       " 'a man is playing a piano',\n",
       " 'a panda is laying on the ground',\n",
       " 'a man is drinking water',\n",
       " 'a woman is dancing',\n",
       " 'a frog is eating',\n",
       " 'a man is jumping',\n",
       " 'a woman is dancing',\n",
       " 'a man is slicing a carrot',\n",
       " 'a man is riding a motorcycle',\n",
       " 'a man is shooting a gun',\n",
       " 'a man is walking on the floor',\n",
       " 'two zebras are fighting',\n",
       " 'a man is running',\n",
       " 'a man is running',\n",
       " 'a plane is flying',\n",
       " 'a man is slicing a potato',\n",
       " 'a woman is exercising',\n",
       " 'a woman is riding a horse',\n",
       " 'a man is breaking a stick',\n",
       " 'a shark is swimming',\n",
       " 'a dog is playing',\n",
       " 'a man is slicing a potato',\n",
       " 'a woman is picking a piece of butter',\n",
       " 'a woman is plucking her eyebrows',\n",
       " 'a man is playing a guitar',\n",
       " 'a man is playing a guitar',\n",
       " 'a man is riding a bike',\n",
       " 'a man is running',\n",
       " 'a man is playing a guitar',\n",
       " 'a cat is playing with a toy',\n",
       " 'a man is slicing a potato',\n",
       " 'a boy is walking on a chair',\n",
       " 'a shark is swimming',\n",
       " 'a woman is riding a motorcycle',\n",
       " 'a man is running',\n",
       " 'a woman is exercising',\n",
       " 'a woman is riding a horse',\n",
       " 'a man is running',\n",
       " 'a man is breaking pots',\n",
       " 'a monkey is running',\n",
       " 'a man is walking',\n",
       " 'a man is slicing a cucumber',\n",
       " 'a man is slicing a potato',\n",
       " 'two women are dancing',\n",
       " 'a man is skating',\n",
       " 'a woman is exercising',\n",
       " 'a girl is picking up a watering can',\n",
       " 'two men are kissing',\n",
       " 'a turtle is walking',\n",
       " 'a man is singing',\n",
       " 'a man is erasing a chalkboard',\n",
       " 'a man is cutting a stick',\n",
       " 'a man is running',\n",
       " 'a man is running',\n",
       " 'a man is running',\n",
       " 'a man is playing a guitar',\n",
       " 'a man is slicing a carrot',\n",
       " 'a woman is mixing ingrediants',\n",
       " 'a man is lifting weights',\n",
       " 'a man is running',\n",
       " 'a man is dancing',\n",
       " 'a man is dancing',\n",
       " 'a man is riding a bicycle',\n",
       " 'a man is breaking pots',\n",
       " 'a man is running',\n",
       " 'a man is breaking pots',\n",
       " 'a man is running',\n",
       " 'a man is walking',\n",
       " 'a man is walking',\n",
       " 'a man is dancing',\n",
       " 'a man is tying his cloths',\n",
       " 'a man is running',\n",
       " 'a man is dancing',\n",
       " 'a person is playing with a toy',\n",
       " 'a person is slicing a carrot',\n",
       " 'a cat is playing',\n",
       " 'a man is sharpening a knife',\n",
       " 'a cat is playing',\n",
       " 'a man cooking his kichen',\n",
       " 'a woman is dancing',\n",
       " 'a man is riding a horse',\n",
       " 'a cat is playing',\n",
       " 'a man is riding a motorcycle',\n",
       " 'a man cooking his kichen',\n",
       " 'a woman is riding a horse',\n",
       " 'a man is doing push ups',\n",
       " 'a man is riding a skateboard',\n",
       " 'a man is driving a car',\n",
       " 'a man is climbing a wall',\n",
       " 'a man is playing with a dog',\n",
       " 'a man is talking',\n",
       " 'a cat is playing',\n",
       " 'a man is breaking bricks',\n",
       " 'a man is dancing',\n",
       " 'a man cooking his kichen',\n",
       " 'a man is slicing a carrot',\n",
       " 'a man is slicing a carrot',\n",
       " 'a man is slicing bread',\n",
       " 'a dog is playing with a dog',\n",
       " 'a man is making a pizza',\n",
       " 'a man is playing a flute',\n",
       " 'men are playing soccer',\n",
       " 'the person is cutting the something',\n",
       " 'people are dancing',\n",
       " 'a cat is playing',\n",
       " 'a person is holding a toad',\n",
       " 'a man is playing a piano',\n",
       " 'a man is riding a bike',\n",
       " 'a man cooking his kichen',\n",
       " 'a man cooking his kichen',\n",
       " 'a man is making a dish',\n",
       " 'two men are swimming',\n",
       " 'a woman is dancing',\n",
       " 'a man is riding a bike',\n",
       " 'a man is riding a bike',\n",
       " 'a plane is flying',\n",
       " 'a man is riding a horse',\n",
       " 'a man is riding a horse',\n",
       " 'a man is cooking',\n",
       " 'a woman is dancing',\n",
       " 'a baby is eating',\n",
       " 'a man is talking',\n",
       " 'a man is dancing',\n",
       " 'a woman is dancing',\n",
       " 'a woman is riding a horse',\n",
       " 'a man is using a camera',\n",
       " 'a group of people are dancing',\n",
       " 'a man is dancing',\n",
       " 'a panda is playing',\n",
       " 'a man is kicking a basketball',\n",
       " 'a woman is picking tomatoes',\n",
       " 'a cat is playing with a ball',\n",
       " 'a man is riding a motorcycle',\n",
       " 'a man is dancing',\n",
       " 'a man and woman are walking',\n",
       " 'a man is riding a bike',\n",
       " 'a man is walking']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(len(summs)):\n",
    "    print i,summs[i],vops[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vops=np.load('../MSVD/clip_index/testIndex.npy')[:64]\n",
    "ref_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#real shit\n",
    "with open('ref_dev.txt','w+') as fle:\n",
    "    for i in devCaptions:\n",
    "        fle.write('vid'+str(i[0])+'\\t'+' '.join(i[1][1:-1]))\n",
    "        fle.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdo=1301\n",
    "with open('genNewDS.txt','w+') as fle:\n",
    "    for i in summs:\n",
    "        fle.write('beam_size_5'+'\\tvid'+str(vdo)+'\\t'+i)\n",
    "        fle.write('\\n')\n",
    "        vdo+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4665536514241951"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ref=[]\n",
    "for i in range(670):\n",
    "    ref.append([])\n",
    "for i in testCaptions:\n",
    "    ref[i[0]-1300-NEWDS].append(i[1][1:-1])\n",
    "\n",
    "cap=[]\n",
    "for i in summs:\n",
    "    cap.append(i.split())\n",
    "    \n",
    "calBleu(ref,cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
