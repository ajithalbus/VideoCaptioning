{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from sklearn import preprocessing as pre\n",
    "#from pathos.pools import ProcessPool as Pool\n",
    "tf.set_random_seed(4321)\n",
    "np.random.seed(4321)\n",
    "\n",
    "#from xmlrpc import client\n",
    "#import xmlrpclib\n",
    "NEWDS=1\n",
    "#s = xmlrpclib.ServerProxy('http://10.21.230.64:8778')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some hypers\n",
    "GO='<START>'\n",
    "STOP='<END>'\n",
    "PAD='<PAD>'\n",
    "unknown='<UNKNOWN>'\n",
    "BATCH=128\n",
    "BEAM_WIDTH=9\n",
    "EPOCHS=100\n",
    "LAM=0.9\n",
    "embedding_size=512\n",
    "lstm_units=2048\n",
    "dropout_keep_prob=0.8\n",
    "PATIENCE=30\n",
    "PATIENCE_MONITOR=True\n",
    "GLOVE=False #if true embedding size will reset to 300\n",
    "CONSTGLOVE=False\n",
    "MAX_LEN=33\n",
    "#new\n",
    "\n",
    "SIN=True\n",
    "NUM_BLOCKS=3\n",
    "NUM_HEADS = 8\n",
    "FEAT_DIM=2048\n",
    "NUM_UNITS=512\n",
    "FRAMES=28\n",
    "WARMUP=4000\n",
    "TRUE_BATCH=1024\n",
    "GRAD_APPLY=TRUE_BATCH/BATCH\n",
    "LR=0.0001#*GRAD_APPLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile):\n",
    "    print \"Loading Glove Model\"\n",
    "    f = open(gloveFile,'r')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print \"Done.\",len(model),\" words loaded!\"\n",
    "    return model\n",
    "if GLOVE:\n",
    "    embedding_size=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "with open('./crt_split/token_train.pkl') as f:\n",
    "    trainCaptions=pkl.load(f)\n",
    "with open('./crt_split/token_dev.pkl') as f:\n",
    "    devCaptions=pkl.load(f)\n",
    "with open('./crt_split/token_test.pkl') as f:\n",
    "    testCaptions=pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processToken(caps):\n",
    "    nk=[]\n",
    "    \n",
    "    for i in caps:\n",
    "        t=[GO]+list(i[1])+[STOP]\n",
    "        empty=33-len(t)\n",
    "        \n",
    "        #t=t+[pad]*empty\n",
    "        nk.append([i[0],t])\n",
    "    return nk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainCaptions=processToken(trainCaptions)\n",
    "devCaptions=processToken(devCaptions)\n",
    "testCaptions=processToken(testCaptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listofwords(data):\n",
    "    '''takes a list of sentences nd returns vocab'''\n",
    "    a=[]\n",
    "    for i in data:\n",
    "        for j in i[1]:\n",
    "            if j not in a:\n",
    "                a.append(j)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the vocab and size\n",
    "trainVocab=listofwords(trainCaptions+devCaptions)\n",
    "trainVocabSize=len(trainVocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find cap len\n",
    "trainCapLen=[len(i[1]) for i in trainCaptions]\n",
    "devCapLen=[len(i[1]) for i in devCaptions]\n",
    "testCapLen=[len(i[1]) for i in testCaptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoder for output transform\n",
    "pre_op=pre.LabelEncoder()\n",
    "pre_op.fit(trainVocab+[PAD])\n",
    "onehoter=np.identity(len(pre_op.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word to int\n",
    "trainSeq=[pre_op.transform(i[1]) for i in trainCaptions]\n",
    "devSeq=[pre_op.transform(i[1]) for i in devCaptions]\n",
    "trainID=[i[0] for i in trainCaptions]\n",
    "devID=[i[0] for i in devCaptions]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#word to int with pool\n",
    "p=Pool(8)\n",
    "\n",
    "\n",
    "trainSeq=p.map(pre_op.transform,[i[1] for i in trainCaptions])\n",
    "devSeq=p.map(pre_op.transform,[i[1] for i in devCaptions])\n",
    "trainID=[i[0] for i in trainCaptions]\n",
    "devID=[i[0] for i in devCaptions]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appending stops\n",
    "\n",
    "\n",
    "trainSeqReg=[np.pad(i,(0,MAX_LEN-len(i)),'constant',constant_values=pre_op.transform([PAD])) for i in trainSeq]\n",
    "devSeqReg=[np.pad(i,(0,MAX_LEN-len(i)),'constant',constant_values=pre_op.transform([PAD])) for i in devSeq]\n",
    "trainSeqReg=np.array(trainSeqReg)\n",
    "devSeqReg=np.array(devSeqReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading video features\n",
    "videoFeats=np.load(file='./crt_split/consilidated_feats.npy')\n",
    "videoFeatSize=np.array([len(i) for i in videoFeats])\n",
    "#making the shape regular\n",
    "videoFeats=np.array([np.pad(i,mode='constant',pad_width=[(0,28-len(i)),(0,0)]) for i in videoFeats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glove\n",
    "if GLOVE:\n",
    "    gloveModel=loadGloveModel('./glove/glove.6B.300d.txt')\n",
    "    gloveEmbedding=[]\n",
    "    for i in pre_op.classes_:\n",
    "        if gloveModel.has_key(i):\n",
    "            gloveEmbedding.append(gloveModel[i])\n",
    "        else:\n",
    "            gloveEmbedding.append(np.random.normal(size=(300)))\n",
    "    gloveEmbedding=np.array(gloveEmbedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "def calBleu(ref,cap):\n",
    "    score_4 = corpus_bleu(ref,cap,weights=(0.25,0.25,0.25,0.25))\n",
    "    return score_4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets build the graph\n",
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "padID=pre_op.transform([PAD])[0]\n",
    "startID=pre_op.transform([GO])[0]\n",
    "stopID=pre_op.transform([STOP])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ny_ph = tf.placeholder('int32',(BATCH,None))\\ny_len_ph=tf.placeholder('int32',(BATCH))\\nminiB=tf.placeholder('int32')\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dummys\n",
    "enc_ph = tf.placeholder(tf.float32,(BATCH,FRAMES,2048))\n",
    "enc_len_ph = tf.placeholder(tf.float32,(BATCH))\n",
    "'''\n",
    "y_ph = tf.placeholder('int32',(BATCH,None))\n",
    "y_len_ph=tf.placeholder('int32',(BATCH))\n",
    "miniB=tf.placeholder('int32')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_seq = tf.placeholder(shape=(None,28,2048),dtype=tf.float32)\n",
    "target_seq = tf.placeholder(shape=(None,33),dtype=tf.int32)\n",
    "source_seq_len = tf.placeholder(shape=(None,), dtype=tf.int32)\n",
    "target_seq_len = tf.placeholder(shape=(None,), dtype=tf.int32)\n",
    "no_start_target_seq = tf.placeholder(shape=(None,32),dtype=tf.int32)\n",
    "batch_size = tf.placeholder(shape=(None),dtype=tf.int32)\n",
    "real_target_seq_len= tf.placeholder(shape=(None,), dtype=tf.int32)\n",
    "keep_prob= tf.placeholder(dtype=tf.float32)\n",
    "end_sentence_emb= tf.placeholder(shape=(None,1024),dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class Transformer:\n",
    "'''\n",
    "    xs: tuple of\n",
    "        x: int32 tensor. (N, T1)\n",
    "        x_seqlens: int32 tensor. (N,)\n",
    "        sents1: str tensor. (N,)\n",
    "    ys: tuple of\n",
    "        decoder_input: int32 tensor. (N, T2)\n",
    "        y: int32 tensor. (N, T2)\n",
    "        y_seqlen: int32 tensor. (N, )\n",
    "        sents2: str tensor. (N,)\n",
    "    training: boolean.\n",
    "    \n",
    "def __init__(self, hp):\n",
    "    #self.hp = hp\n",
    "    #self.token2idx, self.idx2token = load_vocab(hp.vocab)\n",
    "'''\n",
    "embeddings = get_token_embeddings(trainVocabSize, embedding_size, zero_pad=True)\n",
    "\n",
    "def encode(xs, training=True):\n",
    "    '''\n",
    "    Returns\n",
    "    memory: encoder outputs. (N, T1, d_model)\n",
    "    '''\n",
    "    #return xs[0]\n",
    "    with tf.variable_scope(\"encoder\", reuse=tf.AUTO_REUSE):\n",
    "        x, seqlens  = xs\n",
    "\n",
    "        # embedding\n",
    "        enc = x # (N, T1, d_model)\n",
    "        enc *= FEAT_DIM**0.5 # scale\n",
    "\n",
    "        enc += positional_encoding(enc, FRAMES)\n",
    "        enc = tf.layers.dropout(enc, 1-dropout_keep_prob, training=training)\n",
    "\n",
    "        ## Blocks\n",
    "        for i in range(NUM_BLOCKS):\n",
    "            with tf.variable_scope(\"num_blocks_{}\".format(i), reuse=tf.AUTO_REUSE):\n",
    "                # self-attention\n",
    "                enc = multihead_attention(queries=enc,\n",
    "                                          keys=enc,\n",
    "                                          values=enc,\n",
    "                                          num_heads=NUM_HEADS,\n",
    "                                          dropout_rate=1-dropout_keep_prob,\n",
    "                                          training=training,\n",
    "                                          causality=False)\n",
    "                # feed forward\n",
    "                enc = ff(enc, num_units=[FEAT_DIM, FEAT_DIM])\n",
    "    memory = enc\n",
    "    return memory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=encode((enc_ph,enc_len_ph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(ys, memory, training=True):\n",
    "    '''\n",
    "    memory: encoder outputs. (N, T1, d_model)\n",
    "    Returns\n",
    "    logits: (N, T2, V). float32.\n",
    "    y_hat: (N, T2). int32\n",
    "    y: (N, T2). int32\n",
    "    sents2: (N,). string.\n",
    "    '''\n",
    "    if training:\n",
    "        keep_prob=dropout_keep_prob\n",
    "    else:\n",
    "        keep_prob=1.0\n",
    "    #embeddings\n",
    "    with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "        embedding_matrix_decode = tf.get_variable(\n",
    "        name=\"embedding_matrix_de\",\n",
    "        shape=[trainVocabSize, embedding_size],\n",
    "        dtype=tf.float32)\n",
    "        decoder_input_embedded = tf.nn.embedding_lookup(embedding_matrix_decode, target_seq) \n",
    "\n",
    "    \n",
    "    #memory=tf.random_normal(dtype=tf.float32,shape=(BATCH,32,2048))\n",
    "    encoder_outputs=memory\n",
    "    enc_mean=tf.reduce_mean(memory,axis=1)\n",
    "    decoder_initial_state=tf.contrib.rnn.LSTMStateTuple(enc_mean,enc_mean)\n",
    "    \n",
    "    #Projection layer and decoder cell\n",
    "    with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "        output_layer = tf.layers.Dense(trainVocabSize)\n",
    "\n",
    "        decoder_cell=tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.BasicLSTMCell(lstm_units),input_keep_prob=keep_prob,\n",
    "                                              output_keep_prob=keep_prob)\n",
    "\n",
    "    \n",
    "    #attention\n",
    "    with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "        attention_mechanism_train = tf.contrib.seq2seq.LuongAttention(lstm_units,encoder_outputs)\n",
    "    \n",
    "    #attention\n",
    "    #expri\n",
    "    with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "        tiled_encoder_outputs = tf.contrib.seq2seq.tile_batch(\n",
    "            encoder_outputs, multiplier=BEAM_WIDTH)\n",
    "\n",
    "        attention_mechanism_infer = tf.contrib.seq2seq.LuongAttention(lstm_units,tiled_encoder_outputs)\n",
    "    \n",
    "    #decoder Attention wrapper\n",
    "    #expri\n",
    "    with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "        decoder_cell_train = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                decoder_cell, attention_mechanism_train,\n",
    "                attention_layer_size=lstm_units,alignment_history=False)\n",
    "        decoder_initial_state_train = decoder_cell_train.zero_state(BATCH, tf.float32).clone(cell_state=decoder_initial_state)\n",
    "    \n",
    "\n",
    "        #Training helper and decoder\n",
    "    with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "        helper = tf.contrib.seq2seq.TrainingHelper(decoder_input_embedded,target_seq_len)\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell_train, helper, initial_state=decoder_initial_state_train,output_layer=output_layer)#,output_layer=projection_layer)\n",
    "        outputs, state, seq_len = tf.contrib.seq2seq.dynamic_decode(decoder)\n",
    "        logits = outputs.rnn_output\n",
    "        sample_ids = outputs.sample_id\n",
    "    '''\n",
    "    cross_entropy=tf.nn.sparse_softmax_cross_entropy_with_logits(labels=no_start_target_seq,logits=logits)\n",
    "\n",
    "    target_weights = tf.sequence_mask(real_target_seq_len, target_seq_len[0], dtype=logits.dtype)\n",
    "\n",
    "    loss1=tf.reduce_mean(cross_entropy*target_weights)\n",
    "    '''\n",
    "    y_ = label_smoothing(tf.one_hot(no_start_target_seq, depth=trainVocabSize))\n",
    "    ce = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y_)\n",
    "    nonpadding = tf.to_float(tf.not_equal(no_start_target_seq,padID ))  # 0: <pad>\n",
    "    loss1 = tf.reduce_sum(ce * nonpadding) / (tf.reduce_sum(nonpadding) + 1e-7)\n",
    "    \n",
    "    tiled_decoder_initial_state=tf.contrib.seq2seq.tile_batch(decoder_initial_state, multiplier=BEAM_WIDTH)\n",
    "    #inference\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "        decoder_cell_infer = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                decoder_cell, attention_mechanism_infer,\n",
    "                attention_layer_size=lstm_units,alignment_history=False)\n",
    "        decoder_initial_state_infer = decoder_cell_infer.zero_state(BATCH*BEAM_WIDTH, tf.float32).clone(cell_state=tiled_decoder_initial_state)\n",
    "    \n",
    "    decoder_initial_state_infer = decoder_cell_infer.zero_state(BATCH*BEAM_WIDTH, tf.float32).clone(cell_state=tiled_decoder_initial_state)\n",
    "        #Beam Search decoder\n",
    "    with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "\n",
    "        decoder_initial_state_tiled=decoder_cell_infer.zero_state(batch_size=BATCH*BEAM_WIDTH,dtype=tf.float32).clone(cell_state=tiled_decoder_initial_state)\n",
    "\n",
    "\n",
    "        # Define a beam-search decoder\n",
    "        decoder3 = tf.contrib.seq2seq.BeamSearchDecoder(\n",
    "                cell=decoder_cell_infer,\n",
    "                embedding=embedding_matrix_decode,\n",
    "                start_tokens=tf.fill([BATCH],np.int32(pre_op.transform([GO])[0])),\n",
    "                end_token=np.int32(pre_op.transform([STOP])[0]),\n",
    "                initial_state=decoder_initial_state_tiled,\n",
    "                beam_width=BEAM_WIDTH,\n",
    "                output_layer=output_layer,\n",
    "                length_penalty_weight=0.0)\n",
    "        outputs, state, seq_len = tf.contrib.seq2seq.dynamic_decode(decoder3,maximum_iterations=32+10)\n",
    "\n",
    "\n",
    "        trs_beam=outputs.predicted_ids\n",
    "    \n",
    "    '''\n",
    "    #expri\n",
    "    #decoder Attention wrapper\n",
    "    with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "        decoder_cell_infer = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                decoder_cell, attention_mechanism_infer,\n",
    "                attention_layer_size=lstm_units,alignment_history=False)\n",
    "        decoder_initial_state_infer = decoder_cell_infer.zero_state(BATCH*BEAM_WIDTH, tf.float32).clone(cell_state=tiled_decoder_initial_state)\n",
    "    \n",
    "    \n",
    "    #Beam Search decoder\n",
    "    with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "        decoder_initial_state_tiled = tf.contrib.seq2seq.tile_batch(\n",
    "            decoder_initial_state_infer[0], multiplier=BEAM_WIDTH)\n",
    "\n",
    "        decoder_initial_state_tiled=decoder_cell_infer.zero_state(batch_size=BATCH*BEAM_WIDTH,dtype=tf.float32).clone(cell_state=decoder_initial_state_tiled)\n",
    "\n",
    "\n",
    "        # Define a beam-search decoder\n",
    "        decoder3 = tf.contrib.seq2seq.BeamSearchDecoder(\n",
    "                cell=decoder_cell_infer,\n",
    "                embedding=embedding_matrix_decode,\n",
    "                start_tokens=tf.fill([batch_size],np.int32(pre_op.transform([GO])[0])),\n",
    "                end_token=np.int32(pre_op.transform([STOP])[0]),\n",
    "                initial_state=decoder_initial_state_tiled,\n",
    "                beam_width=BEAM_WIDTH,\n",
    "                output_layer=output_layer,\n",
    "                length_penalty_weight=0.0)\n",
    "        outputs, state, seq_len = tf.contrib.seq2seq.dynamic_decode(decoder3,maximum_iterations=32+10)\n",
    "\n",
    "\n",
    "        trs_beam=outputs.predicted_ids\n",
    "    '''\n",
    "    \n",
    "    return logits, loss1 , trs_beam,logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t=decode(0,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def decode(ys, memory, training=True):\n",
    "    '''\n",
    "    memory: encoder outputs. (N, T1, d_model)\n",
    "    Returns\n",
    "    logits: (N, T2, V). float32.\n",
    "    y_hat: (N, T2). int32\n",
    "    y: (N, T2). int32\n",
    "    sents2: (N,). string.\n",
    "    '''\n",
    "    if training:\n",
    "        keep_prob=dropout_keep_prob\n",
    "    else:\n",
    "        keep_prob=1.0\n",
    "    #embeddings\n",
    "    with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "        embedding_matrix_decode = tf.get_variable(\n",
    "        name=\"embedding_matrix_de\",\n",
    "        shape=[trainVocabSize, embedding_size],\n",
    "        dtype=tf.float32)\n",
    "    decoder_input_embedded = tf.nn.embedding_lookup(embedding_matrix_decode, ys[0]) \n",
    "    \n",
    "    with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "    #attention\n",
    "    \n",
    "        attention_mechanism_train = tf.contrib.seq2seq.LuongAttention(lstm_units,memory)\n",
    "    \n",
    "    \n",
    "    #attention\n",
    "    #expri\n",
    "    \n",
    "        tiled_encoder_outputs = tf.contrib.seq2seq.tile_batch(memory, multiplier=BEAM_WIDTH)\n",
    "\n",
    "        attention_mechanism_infer = tf.contrib.seq2seq.LuongAttention(lstm_units,tiled_encoder_outputs)\n",
    "    \n",
    "    #print tiled_encoder_outputs,attention_mechanism_infer\n",
    "    \n",
    "    #projection layer & decoder cell\n",
    "    with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "        output_layer = tf.layers.Dense(trainVocabSize)\n",
    "\n",
    "        decoder_cell=tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.BasicLSTMCell(lstm_units),input_keep_prob=keep_prob,\n",
    "                                              output_keep_prob=keep_prob)\n",
    "    mean_mem=tf.reduce_mean(memory,axis=1)\n",
    "    decoder_initial_state=tf.contrib.rnn.LSTMStateTuple(mean_mem,mean_mem)\n",
    "    \n",
    "    tiled_decoder_initial_state=tf.contrib.seq2seq.tile_batch(decoder_initial_state, multiplier=BEAM_WIDTH)\n",
    "    \n",
    "    decoder_initial_state=tf.contrib.rnn.LSTMStateTuple(tf.random_normal((BATCH,2048),stddev=0.1),tf.random_normal((BATCH,2048),stddev=0.1))\n",
    "    #print tiled_decoder_initial_state\n",
    "    #decoder Attention wrapper\n",
    "    #expri\n",
    "    with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "        decoder_cell_train = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                decoder_cell, attention_mechanism_train,\n",
    "                attention_layer_size=lstm_units,alignment_history=False)\n",
    "        decoder_initial_state_train = decoder_cell_train.zero_state(BATCH, tf.float32).clone(cell_state=decoder_initial_state)\n",
    "    \n",
    "    #Training helper and decoder\n",
    "    with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "        helper = tf.contrib.seq2seq.TrainingHelper(decoder_input_embedded,ys[2])\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell_train, helper, initial_state=decoder_initial_state_train,output_layer=output_layer)#,output_layer=projection_layer)\n",
    "        outputs, state, seq_len = tf.contrib.seq2seq.dynamic_decode(decoder,maximum_iterations=33)\n",
    "        logits = outputs.rnn_output\n",
    "        sample_ids = outputs.sample_id\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #expri\n",
    "#decoder Attention wrapper\n",
    "    with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "        decoder_cell_infer = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                decoder_cell, attention_mechanism_infer,\n",
    "                attention_layer_size=lstm_units,alignment_history=False)\n",
    "        \n",
    "        decoder_initial_state_infer = decoder_cell_infer.zero_state(BATCH*BEAM_WIDTH, tf.float32).clone(cell_state=tiled_decoder_initial_state)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        #Beam Search decoder\n",
    "    with tf.variable_scope(\"myScope\",reuse=tf.AUTO_REUSE):\n",
    "        \n",
    "        decoder_initial_state_tiled=decoder_cell_infer.zero_state(batch_size=BATCH*BEAM_WIDTH,dtype=tf.float32).clone(cell_state=tiled_decoder_initial_state)\n",
    "\n",
    "    \n",
    "        # Define a beam-search decoder\n",
    "        decoder3 = tf.contrib.seq2seq.BeamSearchDecoder(\n",
    "                cell=decoder_cell_infer,\n",
    "                embedding=embedding_matrix_decode,\n",
    "                start_tokens=tf.fill([BATCH],np.int32(pre_op.transform([GO])[0])),\n",
    "                end_token=np.int32(pre_op.transform([STOP])[0]),\n",
    "                initial_state=decoder_initial_state_tiled,\n",
    "                beam_width=BEAM_WIDTH,\n",
    "                output_layer=output_layer,\n",
    "                length_penalty_weight=0.0)\n",
    "        outputs, state, seq_len = tf.contrib.seq2seq.dynamic_decode(decoder3,maximum_iterations=33)\n",
    "\n",
    "\n",
    "        trs_beam=outputs.predicted_ids\n",
    "    '''\n",
    "    \n",
    "    #loss1\n",
    "    #tmp=tf.zeros((128, 32, 10329))\n",
    "    #tmp[:,:,:]=logits\n",
    "    cross_entropy=tf.nn.sparse_softmax_cross_entropy_with_logits(labels=ys[1],logits=logits)\n",
    "    #print cross_entropy.shape[1]\n",
    "    target_weights = tf.sequence_mask(ys[2], miniB, dtype=logits.dtype)\n",
    "\n",
    "    loss1=tf.reduce_mean(cross_entropy*target_weights)\n",
    "\n",
    "\n",
    "    return logits, loss1 , target_weights,logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def decode(ys, memory, training=True):\n",
    "    '''\n",
    "    memory: encoder outputs. (N, T1, d_model)\n",
    "    Returns\n",
    "    logits: (N, T2, V). float32.\n",
    "    y_hat: (N, T2). int32\n",
    "    y: (N, T2). int32\n",
    "    sents2: (N,). string.\n",
    "    '''\n",
    "    with tf.variable_scope(\"decoder\", reuse=tf.AUTO_REUSE):\n",
    "        decoder_inputs, y, seqlens = ys\n",
    "\n",
    "        # embedding\n",
    "        dec = tf.nn.embedding_lookup(embeddings, decoder_inputs)  # (N, T2, d_model)\n",
    "        dec *= NUM_UNITS ** 0.5  # scale\n",
    "\n",
    "        dec += positional_encoding(dec, MAX_LEN-1)\n",
    "        dec = tf.layers.dropout(dec, 1-dropout_keep_prob, training=training)\n",
    "\n",
    "        # Blocks\n",
    "        for i in range(NUM_BLOCKS):\n",
    "            with tf.variable_scope(\"num_blocks_{}\".format(i), reuse=tf.AUTO_REUSE):\n",
    "                # Masked self-attention (Note that causality is True at this time)\n",
    "                dec = multihead_attention(queries=dec,\n",
    "                                          keys=dec,\n",
    "                                          values=dec,\n",
    "                                          num_heads=NUM_HEADS,\n",
    "                                          dropout_rate=1-dropout_keep_prob,\n",
    "                                          training=training,\n",
    "                                          causality=True,\n",
    "                                          scope=\"self_attention\")\n",
    "\n",
    "                # Vanilla attention\n",
    "                dec = multihead_attention(queries=dec,\n",
    "                                          keys=memory,\n",
    "                                          values=memory,\n",
    "                                          num_heads=NUM_HEADS,\n",
    "                                          dropout_rate=1-dropout_keep_prob,\n",
    "                                          training=training,\n",
    "                                          causality=False,\n",
    "                                          scope=\"vanilla_attention\")\n",
    "                ### Feed Forward\n",
    "                dec = ff(dec, num_units=[NUM_UNITS*4,embedding_size])\n",
    "\n",
    "    # Final linear projection (embedding weights are shared)\n",
    "    weights = tf.transpose(embeddings) # (d_model, vocab_size)\n",
    "    logits = tf.einsum('ntd,dk->ntk', dec, weights) # (N, T2, vocab_size)\n",
    "    y_hat = tf.to_int32(tf.argmax(logits, axis=-1))\n",
    "\n",
    "    return logits, y_hat, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train( xs, ys):\n",
    "    '''\n",
    "    Returns\n",
    "    loss: scalar.\n",
    "    train_op: training operation\n",
    "    global_step: scalar.\n",
    "    summaries: training summary node\n",
    "    '''\n",
    "    # forward\n",
    "    memory = encode(xs)\n",
    "    logits, loss, preds,sample_ids= decode(ys,memory)\n",
    "\n",
    "    # train scheme\n",
    "    '''\n",
    "    y_ = label_smoothing(tf.one_hot(y, depth=trainVocabSize))\n",
    "    ce = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y_)\n",
    "    nonpadding = tf.to_float(tf.not_equal(y,padID ))  # 0: <pad>\n",
    "    loss = tf.reduce_sum(ce * nonpadding) / (tf.reduce_sum(nonpadding) + 1e-7)\n",
    "    \n",
    "    varss   = tf.trainable_variables() \n",
    "    lossL2 = tf.add_n([ tf.nn.l2_loss(v) for v in varss if 'bias' not in v.name ]) * 0.001\n",
    "    '''\n",
    "    \n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    lr = noam_scheme(LR, global_step, WARMUP)\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "    '''\n",
    "    #https://stackoverflow.com/questions/45987156/tensorflow-average-gradients-over-several-batches \n",
    "    t_vars = tf.trainable_variables()\n",
    "    # create a copy of all trainable variables with `0` as initial values\n",
    "    accum_tvars = [tf.Variable(tf.zeros_like(t_var.initialized_value()),trainable=False) for t_var in t_vars]                                        \n",
    "    # create a op to initialize all accums vars\n",
    "    zero_ops = [tv.assign(tf.zeros_like(tv)) for tv in accum_tvars]\n",
    "\n",
    "    # compute gradients for a batch\n",
    "    batch_grads_vars = optimizer.compute_gradients(loss, t_vars)\n",
    "    # collect the batch gradient into accumulated vars\n",
    "    accum_ops = [accum_tvars[i].assign_add(batch_grad_var[0]) for i, batch_grad_var in enumerate(batch_grads_vars)]\n",
    "\n",
    "    # apply accums gradients \n",
    "    train_op = optimizer.apply_gradients([(accum_tvars[i], batch_grad_var[1]) for i, batch_grad_var in enumerate(batch_grads_vars)])\n",
    "    # train_step = opt.apply_gradients(zip(accum_tvars, zip(*batch_grads_vars)[1])\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    gradients, variables = zip(*optimizer.compute_gradients(loss))\n",
    "    gradients, _ = tf.clip_by_global_norm(gradients, 10.0)\n",
    "    train_op = optimizer.apply_gradients(zip(gradients, variables))\n",
    "    '''\n",
    "    tf.summary.scalar('lr', lr)\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "    #tf.summary.scalar(\"global_step\", global_step)\n",
    "    #global_step = tf.train.get_or_create_global_step()\n",
    "    summaries = tf.summary.merge_all()\n",
    "    \n",
    "    \n",
    "    return loss, train_op,logits, global_step, summaries,loss#gradients#,accum_ops,zero_ops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evalr(xs, ys):\n",
    "    '''Predicts autoregressively\n",
    "    At inference, input ys is ignored.\n",
    "    Returns\n",
    "    y_hat: (N, T2)\n",
    "    \n",
    "    decoder_inputs, y, y_seqlen = ys\n",
    "\n",
    "    decoder_inputs = tf.ones((tf.shape(xs[0])[0], 1), tf.int32) * startID\n",
    "    ys = (decoder_inputs, y, y_seqlen)\n",
    "    '''\n",
    "    memory = encode(xs, False)\n",
    "    logits, loss, preds,extra= decode(ys, memory,False)\n",
    "\n",
    "    return preds#, summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, train_op ,logits,global_step, summaries,extra= train((enc_ph,enc_len_ph),0)#(y_ph[:,:-1],y_ph[:,1:],y_len_ph))\n",
    "y_hat = evalr((enc_ph,enc_len_ph),0)#(y_ph[:,:-1],y_ph[:,1:],y_len_ph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes training batch\n",
    "\n",
    "SenEmb=np.squeeze(np.load('./LmEmb.npy'))\n",
    "\n",
    "def getTrainBatch(indexs):\n",
    "    sourceBatch=np.array([videoFeats[trainID[i]-NEWDS] for i in indexs])\n",
    "    targetBatch=np.array([trainSeqReg[i] for i in indexs])\n",
    "    sourceBatchLen=np.array([videoFeatSize[trainID[i]-NEWDS] for i in indexs])\n",
    "    targetBatchLen=np.array([trainCapLen[i] for i in indexs])\n",
    "    targetSenEm=np.array([SenEmb[i] for i in indexs])\n",
    "    return sourceBatch,targetBatch,sourceBatchLen,targetBatchLen,targetSenEm\n",
    "\n",
    "#makes dev batch\n",
    "def getDevBatch(indexs):\n",
    "    sourceBatch=np.array([videoFeats[devID[i]-NEWDS] for i in indexs])\n",
    "    targetBatch=np.array([devSeqReg[i] for i in indexs])\n",
    "    sourceBatchLen=np.array([videoFeatSize[devID[i]-NEWDS] for i in indexs])\n",
    "    targetBatchLen=np.array([devCapLen[i] for i in indexs])\n",
    "    return sourceBatch,targetBatch,sourceBatchLen,targetBatchLen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def calValBleu():\n",
    "    data=videoFeats[1200:1300]\n",
    "    data_len=videoFeatSize[1200:1300]\n",
    "    if BATCH>100:\n",
    "        data=np.concatenate([data,videoFeats[:BATCH-100]])\n",
    "        data_len=np.concatenate([data_len,videoFeatSize[:BATCH-100]])\n",
    "    gen_sum=[]\n",
    "    for i in range(len(data)/BATCH):\n",
    "        start=i*BATCH\n",
    "        stop=(i+1)*BATCH\n",
    "\n",
    "        \n",
    "        y=sess.run(y_hat,feed_dict={enc_ph:data[start:stop],y_ph:np.zeros((BATCH,MAX_LEN)),\n",
    "                                              enc_len_ph:data_len[start:stop],\n",
    "                                                y_len_ph:np.zeros((BATCH))})\n",
    "        \n",
    "        \n",
    "        for t in y:\n",
    "            gen_sum.append(t)\n",
    "\n",
    "    if BATCH<100:        \n",
    "        start=len(data)-BATCH\n",
    "        stop=len(data)\n",
    "        y=sess.run(y_hat,feed_dict={enc_ph:data[start:stop],y_ph:np.zeros((BATCH,MAX_LEN)),\n",
    "                                              enc_len_ph:data_len[start:stop],\n",
    "                                                y_len_ph:np.zeros((BATCH))})\n",
    "                        \n",
    "        \n",
    "\n",
    "        y=y[-(len(data)-len(gen_sum)):]\n",
    "        for t in y:\n",
    "            gen_sum.append(t)\n",
    "    \n",
    "    gen_sum=gen_sum[:100]\n",
    "    #processing summaries\n",
    "    summs=[]\n",
    "    for i in gen_sum:\n",
    "        summ=''\n",
    "        for j in i:\n",
    "            if j==stopID:\n",
    "                break\n",
    "            summ = summ+' '+pre_op.inverse_transform(j)\n",
    "        summs.append(summ[1:])\n",
    "    vdo=1200\n",
    "    with open('gen_dev.txt','w+') as fle:\n",
    "        for i in summs:\n",
    "            fle.write('beam_size_5'+'\\tvid'+str(vdo)+'\\t'+i)\n",
    "            fle.write('\\n')\n",
    "            vdo+=1\n",
    "    with open('gen_dev.txt','r') as fle:\n",
    "        pred=fle.read()\n",
    "    return s.calcScore(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calValBleu():\n",
    "    data=videoFeats[1200:1300]\n",
    "    data_len=videoFeatSize[1200:1300]\n",
    "    if BATCH>100:\n",
    "        data=np.concatenate([data,videoFeats[:BATCH-100]])\n",
    "        data_len=np.concatenate([data_len,videoFeatSize[:BATCH-100]])\n",
    "    gen_sum=[]\n",
    "    for i in range(len(data)/BATCH):\n",
    "        start=i*BATCH\n",
    "        stop=(i+1)*BATCH\n",
    "\n",
    "        \n",
    "        y=sess.run(y_hat,feed_dict={enc_ph:data[start:stop],\n",
    "                                              enc_len_ph:data_len[start:stop],\n",
    "                                                })\n",
    "        \n",
    "        y=y[:,:,0]\n",
    "        for t in y:\n",
    "            gen_sum.append(t)\n",
    "\n",
    "    if BATCH<100:        \n",
    "        start=len(data)-BATCH\n",
    "        stop=len(data)\n",
    "        y=sess.run(y_hat,feed_dict={enc_ph:data[start:stop],\n",
    "                                              enc_len_ph:data_len[start:stop],\n",
    "                                                })\n",
    "                        \n",
    "        \n",
    "        y=y[:,:,0]\n",
    "        y=y[-(len(data)-len(gen_sum)):]\n",
    "        for t in y:\n",
    "            gen_sum.append(t)\n",
    "    \n",
    "    gen_sum=gen_sum[:100]\n",
    "    \n",
    "    #print gen_sum.shape\n",
    "    #processing summaries\n",
    "    summs=[]\n",
    "    for i in gen_sum:\n",
    "        summ=''\n",
    "        for j in i:\n",
    "            if j==stopID:\n",
    "                break\n",
    "            summ = summ+' '+pre_op.inverse_transform(j)\n",
    "        summs.append(summ[1:])\n",
    "    \n",
    "    \n",
    "    ref=[]\n",
    "    for i in range(100):\n",
    "        ref.append([])\n",
    "    for i in devCaptions:\n",
    "        ref[i[0]-1200-NEWDS].append(i[1][1:-1])\n",
    "\n",
    "    cap=[]\n",
    "    for i in summs:\n",
    "        cap.append(i.split())\n",
    "\n",
    "    score=calBleu(ref,cap)\n",
    "    \n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver=tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_writer = tf.summary.FileWriter('./log/', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont touch\n",
    "maxtlen=max(trainCapLen)\n",
    "maxvlen=max(devCapLen)\n",
    "t_newlen=[maxtlen-1 for i in range(len(trainCapLen))]\n",
    "v_newlen=[maxtlen-1 for i in range(len(devCapLen))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n",
      "saving model best\n",
      "Epoch:0 training loss:6.3838: valid loss:0.0000 valid bleu:0.0000\n",
      "saving model best\n",
      "Epoch:1 training loss:4.9238: valid loss:0.0000 valid bleu:0.4358\n",
      "saving model best\n",
      "Epoch:2 training loss:4.3477: valid loss:0.0000 valid bleu:0.5187\n",
      "saving model best\n",
      "Epoch:3 training loss:3.8294: valid loss:0.0000 valid bleu:0.5276\n",
      "saving model best\n",
      "Epoch:4 training loss:3.5164: valid loss:0.0000 valid bleu:0.5655\n",
      "Epoch:5 training loss:3.3515: valid loss:0.0000 valid bleu:0.4960\n",
      "saving model best\n",
      "Epoch:6 training loss:3.2490: valid loss:0.0000 valid bleu:0.5876\n",
      "Epoch:7 training loss:3.1675: valid loss:0.0000 valid bleu:0.5444\n",
      "Epoch:8 training loss:3.0987: valid loss:0.0000 valid bleu:0.5073\n",
      "Epoch:9 training loss:3.0403: valid loss:0.0000 valid bleu:0.5052\n",
      "Epoch:10 training loss:2.9839: valid loss:0.0000 valid bleu:0.5121\n",
      "Epoch:11 training loss:2.9165: valid loss:0.0000 valid bleu:0.5040\n",
      "Epoch:12 training loss:2.8518: valid loss:0.0000 valid bleu:0.5451\n",
      "Epoch:13 training loss:2.7966: valid loss:0.0000 valid bleu:0.5690\n",
      "Epoch:14 training loss:2.7441: valid loss:0.0000 valid bleu:0.5457\n",
      "Epoch:15 training loss:2.6981: valid loss:0.0000 valid bleu:0.5739\n",
      "Epoch:16 training loss:2.6534: valid loss:0.0000 valid bleu:0.5628\n",
      "saving model best\n",
      "Epoch:17 training loss:2.6113: valid loss:0.0000 valid bleu:0.5884\n",
      "Epoch:18 training loss:2.5742: valid loss:0.0000 valid bleu:0.5577\n",
      "Epoch:19 training loss:2.5362: valid loss:0.0000 valid bleu:0.5610\n",
      "Epoch:20 training loss:2.5007: valid loss:0.0000 valid bleu:0.5358\n",
      "Epoch:21 training loss:2.4650: valid loss:0.0000 valid bleu:0.5463\n",
      "Epoch:22 training loss:2.4335: valid loss:0.0000 valid bleu:0.5439\n",
      "Epoch:23 training loss:2.4037: valid loss:0.0000 valid bleu:0.5697\n",
      "Epoch:24 training loss:2.3740: valid loss:0.0000 valid bleu:0.5285\n",
      "Epoch:25 training loss:2.3479: valid loss:0.0000 valid bleu:0.5636\n",
      "Epoch:26 training loss:2.3217: valid loss:0.0000 valid bleu:0.5493\n",
      "Epoch:27 training loss:2.2987: valid loss:0.0000 valid bleu:0.5791\n",
      "Epoch:28 training loss:2.2779: valid loss:0.0000 valid bleu:0.5377\n",
      "Epoch:29 training loss:2.2557: valid loss:0.0000 valid bleu:0.5786\n",
      "Epoch:30 training loss:2.2363: valid loss:0.0000 valid bleu:0.5478\n",
      "Epoch:31 training loss:2.2152: valid loss:0.0000 valid bleu:0.5341\n",
      "Epoch:32 training loss:2.1985: valid loss:0.0000 valid bleu:0.5266\n",
      "Epoch:33 training loss:2.1824: valid loss:0.0000 valid bleu:0.5739\n",
      "Epoch:34 training loss:2.1665: valid loss:0.0000 valid bleu:0.5503\n",
      "Epoch:35 training loss:2.1531: valid loss:0.0000 valid bleu:0.5455\n",
      "Epoch:36 training loss:2.1405: valid loss:0.0000 valid bleu:0.5409\n",
      "Epoch:37 training loss:2.1264: valid loss:0.0000 valid bleu:0.5195\n",
      "Epoch:38 training loss:2.1145: valid loss:0.0000 valid bleu:0.5457\n",
      "Epoch:39 training loss:2.1027: valid loss:0.0000 valid bleu:0.5448\n",
      "Epoch:40 training loss:2.0928: valid loss:0.0000 valid bleu:0.5527\n",
      "Epoch:41 training loss:2.0822: valid loss:0.0000 valid bleu:0.5336\n",
      "Epoch:42 training loss:2.0721: valid loss:0.0000 valid bleu:0.5459\n",
      "Epoch:43 training loss:2.0630: valid loss:0.0000 valid bleu:0.5255\n",
      "Epoch:44 training loss:2.0547: valid loss:0.0000 valid bleu:0.5606\n",
      "Epoch:45 training loss:2.0463: valid loss:0.0000 valid bleu:0.5330\n",
      "Epoch:46 training loss:2.0388: valid loss:0.0000 valid bleu:0.5330\n"
     ]
    }
   ],
   "source": [
    "#training starts here\n",
    "bestVal=0\n",
    "patience=PATIENCE\n",
    "\n",
    "print 'starting training'\n",
    "training_losses=[]\n",
    "valid_losses=[]\n",
    "valid_bleu=[]\n",
    "tData=np.arange(len(trainSeqReg))\n",
    "dData=np.arange(len(devSeqReg))\n",
    "steps=0\n",
    "#sess.run(zero_ops)\n",
    "for j in range(EPOCHS):\n",
    "    np.random.shuffle(tData) #makes them iid\n",
    "    training_loss=0\n",
    "    for i in range(len(trainSeqReg)/BATCH):\n",
    "        start=i*BATCH\n",
    "        stop=(i+1)*BATCH\n",
    "        sourceBatch,targetBatch,sourceBatchLen,targetBatchLen,senTargetBatch=getTrainBatch(tData[start:stop])\n",
    "        \n",
    "        '''\n",
    "        _,lost,_s,_gs=sess.run([accum_ops,loss,summaries,global_step],feed_dict={enc_ph:sourceBatch,y_ph:targetBatch,enc_len_ph:sourceBatchLen,\n",
    "                                                y_len_ph:targetBatchLen})\n",
    "        \n",
    "        summary_writer.add_summary(_s, _gs)\n",
    "        steps+=1\n",
    "        \n",
    "        if steps%GRAD_APPLY==0:\n",
    "            sess.run(train_op)\n",
    "            sess.run(zero_ops)\n",
    "        '''\n",
    "        maxpossible=max(targetBatchLen)+1\n",
    "        '''\n",
    "        print maxpossible\n",
    "        \n",
    "        \n",
    "        l=sess.run(extra[1],feed_dict={enc_ph:sourceBatch,enc_len_ph:sourceBatchLen,\n",
    "                                                target_seq:targetBatch,\n",
    "                                                target_seq_len:t_newlen[start:stop],\n",
    "                                                real_target_seq_len:targetBatchLen,\n",
    "                                                no_start_target_seq:np.array(targetBatch)[:,1:],\n",
    "                                                batch_size:BATCH,keep_prob:dropout_keep_prob,\n",
    "                                                end_sentence_emb:senTargetBatch\n",
    "                                                })\n",
    "        print l[0]\n",
    "        '''\n",
    "        #break\n",
    "        #print targetBatch[0],targetBatchLen[0],sourceBatch[0],sourceBatchLen[0]\n",
    "        '''\n",
    "        if maxpossible>=34:\n",
    "            continue\n",
    "        _,lost,_s,_gs=sess.run([train_op,loss,summaries,global_step],feed_dict={enc_ph:sourceBatch,y_ph:targetBatch[:,:maxpossible],enc_len_ph:sourceBatchLen,\n",
    "                                                y_len_ph:targetBatchLen,miniB:maxpossible-1})\n",
    "        print lost\n",
    "        '''\n",
    "        \n",
    "        _,lost,_s,_gs=sess.run([train_op,loss,summaries,global_step],feed_dict={enc_ph:sourceBatch,enc_len_ph:sourceBatchLen,\n",
    "                                                target_seq:targetBatch,\n",
    "                                                target_seq_len:t_newlen[start:stop],\n",
    "                                                real_target_seq_len:targetBatchLen,\n",
    "                                                no_start_target_seq:np.array(targetBatch)[:,1:],\n",
    "                                                batch_size:BATCH,keep_prob:dropout_keep_prob,\n",
    "                                                end_sentence_emb:senTargetBatch\n",
    "                                                })\n",
    "        \n",
    "        summary_writer.add_summary(_s, _gs)\n",
    "        training_loss+=lost\n",
    "        #print lost\n",
    "    #calculate t_loss\n",
    "    training_losses.append(training_loss/(len(trainSeqReg)/BATCH))\n",
    "    \n",
    "    #calculate v_loss\n",
    "    #disabled\n",
    "    '''\n",
    "    validation_loss=0\n",
    "    for k in range(len(devSeqReg)/BATCH):\n",
    "        start=k*BATCH\n",
    "        stop=(k+1)*BATCH\n",
    "        sourceBatch,targetBatch,sourceBatchLen,targetBatchLen=getDevBatch(dData[start:stop])\n",
    "        lost=sess.run(loss,feed_dict={enc_ph:sourceBatch,y_ph:targetBatch,enc_len_ph:sourceBatchLen,\n",
    "                                                y_len_ph:targetBatchLen})\n",
    "        validation_loss += lost\n",
    "    \n",
    "    \n",
    "    valid_losses.append(validation_loss/len(devSeqReg))\n",
    "    '''\n",
    "    \n",
    "    valBleu=calValBleu()\n",
    "    valid_bleu.append(valBleu)\n",
    "    \n",
    "    \n",
    "    if(valid_bleu[-1]>bestVal) and PATIENCE_MONITOR==True:\n",
    "        bestVal=valid_bleu[-1]\n",
    "        saver.save(sess, \"transModels/best.ckpt\")\n",
    "        print \"saving model best\"\n",
    "        patience=PATIENCE\n",
    "    \n",
    "    print \"Epoch:%d training loss:%.4f: valid loss:%.4f valid bleu:%.4f\"% (j,training_losses[-1],0.0,valid_bleu[-1])\n",
    "    patience-=1\n",
    "    if patience==0 and PATIENCE_MONITOR==True:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#restore model\n",
    "saver.restore(sess, \"BestModel/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BestTrans/resume.ckpt'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "saver.save(sess, \"BestTrans/resume.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from transModels/best.ckpt\n"
     ]
    }
   ],
   "source": [
    "if PATIENCE_MONITOR:\n",
    "    saver.restore(sess, \"transModels/best.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.225113061299963e-78,\n",
       " 0.4358031727409411,\n",
       " 0.5187017703902669,\n",
       " 0.5276458224667989,\n",
       " 0.5655438635216826,\n",
       " 0.4959940418096737,\n",
       " 0.5876046610067263,\n",
       " 0.5443763615326478,\n",
       " 0.5073216606659753,\n",
       " 0.5052007952978532,\n",
       " 0.5121034220380604,\n",
       " 0.5039886410536626,\n",
       " 0.5450657639451099,\n",
       " 0.5690041109923824,\n",
       " 0.5457212175281723,\n",
       " 0.5739125050114697,\n",
       " 0.5627802793830623,\n",
       " 0.5883805068342941,\n",
       " 0.5577031339207043,\n",
       " 0.5610012311959837,\n",
       " 0.5357527352256197,\n",
       " 0.546266224333698,\n",
       " 0.5438831750862665,\n",
       " 0.5696619614539277,\n",
       " 0.528504846958879,\n",
       " 0.5635960145221541,\n",
       " 0.5492538476826754,\n",
       " 0.579128717035524,\n",
       " 0.5377479106636786,\n",
       " 0.5786135121756347,\n",
       " 0.5478406472213724,\n",
       " 0.5341032008606288,\n",
       " 0.5265546960467371,\n",
       " 0.5739277503125324,\n",
       " 0.5502817942794727,\n",
       " 0.5454871635500864,\n",
       " 0.5409306001138258,\n",
       " 0.5195234725282566,\n",
       " 0.5456664508540165,\n",
       " 0.5447908990188346,\n",
       " 0.5526759359218706,\n",
       " 0.533608104082931,\n",
       " 0.5459429128814148,\n",
       " 0.5254939039775095,\n",
       " 0.5606402398592442,\n",
       " 0.5330164101149911,\n",
       " 0.5330147582908316]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=videoFeats[1300:]\n",
    "data_len=videoFeatSize[1300:]\n",
    "if BATCH==1024:\n",
    "    data=np.concatenate([data,data[:354]])\n",
    "    data_len=np.concatenate([data_len,data_len[:354]])\n",
    "gen_sum=[]\n",
    "for i in range(len(data)/BATCH):\n",
    "    start=i*BATCH\n",
    "    stop=(i+1)*BATCH\n",
    "    \n",
    "    y=sess.run(y_hat,feed_dict={enc_ph:data[start:stop],enc_len_ph:data_len[start:stop],\n",
    "                                              batch_size:BATCH,keep_prob:1.0})\n",
    "        \n",
    "    y=y[:,:,0]\n",
    "    for t in y:\n",
    "        gen_sum.append(t)\n",
    "\n",
    "if BATCH<1024:        \n",
    "    start=len(data)-BATCH\n",
    "    stop=len(data)\n",
    "    y=sess.run(y_hat,feed_dict={enc_ph:data[start:stop],enc_len_ph:data_len[start:stop],\n",
    "                                              batch_size:BATCH,keep_prob:1.0})\n",
    "    \n",
    "    y=y[:,:,0]\n",
    "    y=y[-(len(data)-len(gen_sum)):]\n",
    "    for t in y:\n",
    "        gen_sum.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_sum=gen_sum[:670]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data=videoFeats[1300:1364]\n",
    "data_len=videoFeatSize[1300:1364]\n",
    "gen_sum=[]\n",
    "for i in range(len(data)/BATCH):\n",
    "    start=i*BATCH\n",
    "    stop=(i+1)*BATCH\n",
    "    load_trs=trs\n",
    "    y=sess.run(load_trs,feed_dict={source_seq:data[start:stop],\n",
    "                                               source_seq_len:data_len[start:stop],\n",
    "                                              batch_size:BATCH,\n",
    "                                                keep_prob:1.0\n",
    "                                                })\n",
    "    for t in y:\n",
    "        gen_sum.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing summaries\n",
    "summs=[]\n",
    "for i in gen_sum:\n",
    "    summ=''\n",
    "    for j in i:\n",
    "        if j==stopID:\n",
    "            break\n",
    "        summ = summ+' '+pre_op.inverse_transform(j)\n",
    "    summs.append(summ[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(len(summs)):\n",
    "    print i,summs[i],vops[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vops=np.load('../MSVD/clip_index/testIndex.npy')[:64]\n",
    "ref_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#real shit\n",
    "with open('ref_dev.txt','w+') as fle:\n",
    "    for i in devCaptions:\n",
    "        fle.write('vid'+str(i[0])+'\\t'+' '.join(i[1][1:-1]))\n",
    "        fle.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdo=1301\n",
    "with open('genTrans_LSTM_newDS.txt','w+') as fle:\n",
    "    for i in summs:\n",
    "        fle.write('beam_size_1'+'\\tvid'+str(vdo)+'\\t'+i+'.')\n",
    "        fle.write('\\n')\n",
    "        vdo+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37013"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "37013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5261747834362036"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ref=[]\n",
    "for i in range(670):\n",
    "    ref.append([])\n",
    "for i in testCaptions:\n",
    "    ref[i[0]-1300-NEWDS].append(i[1][1:-1])\n",
    "\n",
    "cap=[]\n",
    "for i in summs:\n",
    "    cap.append(i.split())\n",
    "    \n",
    "calBleu(ref,cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5883805068342941"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calValBleu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10209"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainVocabSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
